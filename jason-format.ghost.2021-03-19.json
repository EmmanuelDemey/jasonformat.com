{"db":[{"meta":{"exported_on":1616188022574,"version":"004"},"data":{"permissions":[{"id":1,"uuid":"5d4520c7-ffb0-4e1e-9d0b-b81a3d772730","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2015-07-07T13:12:45.339Z","created_by":1,"updated_at":"2015-07-07T13:12:45.339Z","updated_by":1},{"id":2,"uuid":"923edccf-25cd-453d-b917-7b580bf834d4","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2015-07-07T13:12:45.350Z","created_by":1,"updated_at":"2015-07-07T13:12:45.350Z","updated_by":1},{"id":3,"uuid":"dadd6344-566a-4059-9d4e-c6b6e11509c4","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2015-07-07T13:12:45.358Z","created_by":1,"updated_at":"2015-07-07T13:12:45.358Z","updated_by":1},{"id":4,"uuid":"3f511675-4833-45cd-91be-d8cb81ba478c","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2015-07-07T13:12:45.364Z","created_by":1,"updated_at":"2015-07-07T13:12:45.364Z","updated_by":1},{"id":5,"uuid":"34b2ec96-6e1c-4e86-be91-596046639fe0","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.371Z","created_by":1,"updated_at":"2015-07-07T13:12:45.371Z","updated_by":1},{"id":6,"uuid":"074ee336-df28-45b8-9503-d9e34543609e","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2015-07-07T13:12:45.378Z","created_by":1,"updated_at":"2015-07-07T13:12:45.378Z","updated_by":1},{"id":7,"uuid":"a155612c-fbd4-480d-b503-1652edaa80d4","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2015-07-07T13:12:45.386Z","created_by":1,"updated_at":"2015-07-07T13:12:45.386Z","updated_by":1},{"id":8,"uuid":"5c759161-41a7-4689-9134-5d336c6d3f38","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.393Z","created_by":1,"updated_at":"2015-07-07T13:12:45.393Z","updated_by":1},{"id":9,"uuid":"fa2a4a5a-299a-4d80-9e4f-928350fc9449","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2015-07-07T13:12:45.400Z","created_by":1,"updated_at":"2015-07-07T13:12:45.400Z","updated_by":1},{"id":10,"uuid":"95e9618a-3d64-460d-ba84-93517b4a0f3c","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2015-07-07T13:12:45.406Z","created_by":1,"updated_at":"2015-07-07T13:12:45.406Z","updated_by":1},{"id":11,"uuid":"13e3e4cb-0305-47f1-9eb6-1e7b70418037","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2015-07-07T13:12:45.412Z","created_by":1,"updated_at":"2015-07-07T13:12:45.412Z","updated_by":1},{"id":12,"uuid":"ac3dd7a9-5b8c-457f-ab90-f9152adfdd9d","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2015-07-07T13:12:45.420Z","created_by":1,"updated_at":"2015-07-07T13:12:45.420Z","updated_by":1},{"id":13,"uuid":"b1f9bccb-7c37-4eec-8186-bc8f84c66550","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.426Z","created_by":1,"updated_at":"2015-07-07T13:12:45.426Z","updated_by":1},{"id":14,"uuid":"04385b61-6ba1-45fd-9668-202b94a08ea7","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2015-07-07T13:12:45.436Z","created_by":1,"updated_at":"2015-07-07T13:12:45.436Z","updated_by":1},{"id":15,"uuid":"cdfb9d11-c415-4a7e-94d7-5b790a4ac69e","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2015-07-07T13:12:45.440Z","created_by":1,"updated_at":"2015-07-07T13:12:45.440Z","updated_by":1},{"id":16,"uuid":"5daf0abb-030b-46b0-8df3-9186a5aa4cd3","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2015-07-07T13:12:45.447Z","created_by":1,"updated_at":"2015-07-07T13:12:45.447Z","updated_by":1},{"id":17,"uuid":"adf2c953-529d-4a1f-92e7-467b7bbd91d6","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.454Z","created_by":1,"updated_at":"2015-07-07T13:12:45.454Z","updated_by":1},{"id":18,"uuid":"a1bdb845-eb01-4b98-b608-01197bd91f5c","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2015-07-07T13:12:45.459Z","created_by":1,"updated_at":"2015-07-07T13:12:45.459Z","updated_by":1},{"id":19,"uuid":"6df0a7dc-2fdf-45da-98d5-129809d1cbee","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2015-07-07T13:12:45.465Z","created_by":1,"updated_at":"2015-07-07T13:12:45.465Z","updated_by":1},{"id":20,"uuid":"14e1066e-d0da-444b-9336-bfb4eb6c71f8","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2015-07-07T13:12:45.469Z","created_by":1,"updated_at":"2015-07-07T13:12:45.469Z","updated_by":1},{"id":21,"uuid":"e3bad6a4-c05c-4c29-9250-7723ce4fc36a","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2015-07-07T13:12:45.473Z","created_by":1,"updated_at":"2015-07-07T13:12:45.473Z","updated_by":1},{"id":22,"uuid":"c32c90f9-1a1d-49f5-aa68-ede37e9cff42","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.478Z","created_by":1,"updated_at":"2015-07-07T13:12:45.478Z","updated_by":1},{"id":23,"uuid":"11d35921-2656-412e-b1e4-ba3926bbdb5e","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2015-07-07T13:12:45.483Z","created_by":1,"updated_at":"2015-07-07T13:12:45.483Z","updated_by":1},{"id":24,"uuid":"3f9b645a-347e-466b-81bf-818f9aae697d","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.488Z","created_by":1,"updated_at":"2015-07-07T13:12:45.488Z","updated_by":1},{"id":25,"uuid":"cec44356-165f-4315-8bcf-504c0c6dc7aa","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2015-07-07T13:12:45.496Z","created_by":1,"updated_at":"2015-07-07T13:12:45.496Z","updated_by":1},{"id":26,"uuid":"9c4a2546-b41f-45a2-aaea-416f2bb888e6","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2015-07-07T13:12:45.501Z","created_by":1,"updated_at":"2015-07-07T13:12:45.501Z","updated_by":1},{"id":27,"uuid":"d8915717-7bb9-4d1b-92b9-260cdde32644","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2015-07-07T13:12:45.507Z","created_by":1,"updated_at":"2015-07-07T13:12:45.507Z","updated_by":1},{"id":28,"uuid":"9292f30d-1d52-4ad9-9310-fd2d9daa45fe","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2015-07-07T13:12:45.512Z","created_by":1,"updated_at":"2015-07-07T13:12:45.512Z","updated_by":1},{"id":29,"uuid":"d837fcdf-f0ab-48f0-a5ad-8d2a1011b771","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2015-07-07T13:12:45.516Z","created_by":1,"updated_at":"2015-07-07T13:12:45.516Z","updated_by":1},{"id":30,"uuid":"3ca133a3-3c6b-499b-b572-006e95626487","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2015-07-07T13:12:45.523Z","created_by":1,"updated_at":"2015-07-07T13:12:45.523Z","updated_by":1}],"permissions_apps":[],"permissions_roles":[{"id":1,"role_id":1,"permission_id":1},{"id":2,"role_id":1,"permission_id":2},{"id":3,"role_id":1,"permission_id":3},{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":27},{"id":27,"role_id":1,"permission_id":26},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":2,"permission_id":8},{"id":32,"role_id":2,"permission_id":9},{"id":33,"role_id":2,"permission_id":10},{"id":34,"role_id":2,"permission_id":11},{"id":35,"role_id":2,"permission_id":13},{"id":36,"role_id":2,"permission_id":14},{"id":38,"role_id":2,"permission_id":16},{"id":37,"role_id":2,"permission_id":12},{"id":39,"role_id":2,"permission_id":17},{"id":40,"role_id":2,"permission_id":18},{"id":41,"role_id":2,"permission_id":19},{"id":42,"role_id":2,"permission_id":20},{"id":43,"role_id":2,"permission_id":21},{"id":44,"role_id":2,"permission_id":24},{"id":45,"role_id":2,"permission_id":25},{"id":46,"role_id":2,"permission_id":26},{"id":47,"role_id":2,"permission_id":27},{"id":48,"role_id":2,"permission_id":28},{"id":49,"role_id":2,"permission_id":29},{"id":50,"role_id":2,"permission_id":30},{"id":51,"role_id":3,"permission_id":8},{"id":52,"role_id":3,"permission_id":9},{"id":53,"role_id":3,"permission_id":11},{"id":54,"role_id":3,"permission_id":13},{"id":55,"role_id":3,"permission_id":14},{"id":56,"role_id":3,"permission_id":16},{"id":57,"role_id":3,"permission_id":17},{"id":58,"role_id":3,"permission_id":18},{"id":59,"role_id":3,"permission_id":20},{"id":60,"role_id":3,"permission_id":24},{"id":61,"role_id":3,"permission_id":25},{"id":62,"role_id":3,"permission_id":30}],"permissions_users":[],"posts":[{"id":4,"uuid":"506773aa-159f-4eda-a449-685041e8bf38","title":"My ES2015 + LESS Webpack Setup","slug":"my-webpack-boilerplate","markdown":"> **Foreword:** I generally do these things as Gists, but I figured this one is such a common question it would be worthwhile posting here.\n\nLet's talk about Webpack for a sec. It's great and I think there comes a point in many projects where you step slightly beyond what Browserify and its plugin ecosystem are able to do (ancient non-npm dependencies, etc).  Often times the best solution is still Browserify, just with some tweaking - maybe you need to fork that module and refactor it a bit to properly export things.\n\nWhat if there was a way to make Webpack behave as simply as Browserify, right out of the box?  That's where I'm at. It's annoying to switch back and forth depending on the project, when I'm generally using these two tools to accomplish the same task.\n\nHere's what I now use when starting a new Webpack-based app project _(not for libraries, for just use Browserify)_:\n\n##### Install Webpack & Friends\n\n```sh\nnpm i -D webpack webpack-dev-server babel babel-loader less-loader css-loader style-loader autoprefixer-loader\n```\n\n##### Add NPM-Scripts\n\n```js\n\"scripts\": {\n  \"dev\": \"WEBPACK=webpack-dev-server npm run build -s\",\n  \"build\": \"${webpack:-webpack} src/index.js --output-path build --output-file bundle.js -d --module-bind 'js=babel' --module-bind 'less=style!css!autoprefer!less'\"\n}\n```\n\n... then run them via `npm run dev` and `npm run build`.\n\n\n---\n\n\n## Full Webpack Setup\n\nThis is a basic Webpack project template for a web app written in ES6 & LESS.\n\nThis assumes you have a directory structure as follows:\n\n```\npackage.json\nwebpack.config.js\nsrc/\n  index.js\n  static/\n    index.html\n```\n\n---\n\n#### Installation\n\n**1. Clone the repo and start your own:**\n\n```sh\ngit clone git@gist.github.com:3c83db422f03ef66ea36.git\nrm -rf .git\ngit init\n```\n\n**2. Install dependencies:**\n\n```sh\nnpm install\n```\n\nThat's it.\n\n#### Development Workflow\n\n**Start the live-reload dev server:**\n\n```sh\nPORT=8080 npm run dev\n```\n\nOpen up http://localhost:8080/webpack-dev-server/ to see your app.\nThe app gets reloaded as files change.\n\n#### Deployment Workflow\n\nTo deploy your static app, upload the contents of `build/` to a web server.\n\nOr, push this repo to heroku. `http-server` is used to serve the files in `build/`.\n\nOr, and like the best option, deploy this to Firebase. Use this [firebase.json](https://gist.github.com/developit/b27ad8af7eacf92d2ef9).\n\n#### `package.json`\n\n<script src=\"https://gist.github.com/developit/042c6c87f34c4f211072.js\"></script>\n\n#### `webpack.config.js`\n\n<script src=\"https://gist.github.com/developit/83fca68d58cc3dbad909.js\"></script>","html":"<blockquote>\n  <p><strong>Foreword:</strong> I generally do these things as Gists, but I figured this one is such a common question it would be worthwhile posting here.</p>\n</blockquote>\n\n<p>Let's talk about Webpack for a sec. It's great and I think there comes a point in many projects where you step slightly beyond what Browserify and its plugin ecosystem are able to do (ancient non-npm dependencies, etc).  Often times the best solution is still Browserify, just with some tweaking - maybe you need to fork that module and refactor it a bit to properly export things.</p>\n\n<p>What if there was a way to make Webpack behave as simply as Browserify, right out of the box?  That's where I'm at. It's annoying to switch back and forth depending on the project, when I'm generally using these two tools to accomplish the same task.</p>\n\n<p>Here's what I now use when starting a new Webpack-based app project <em>(not for libraries, for just use Browserify)</em>:</p>\n\n<h5 id=\"installwebpackfriends\">Install Webpack &amp; Friends</h5>\n\n<pre><code class=\"language-sh\">npm i -D webpack webpack-dev-server babel babel-loader less-loader css-loader style-loader autoprefixer-loader  \n</code></pre>\n\n<h5 id=\"addnpmscripts\">Add NPM-Scripts</h5>\n\n<pre><code class=\"language-js\">\"scripts\": {\n  \"dev\": \"WEBPACK=webpack-dev-server npm run build -s\",\n  \"build\": \"${webpack:-webpack} src/index.js --output-path build --output-file bundle.js -d --module-bind 'js=babel' --module-bind 'less=style!css!autoprefer!less'\"\n}\n</code></pre>\n\n<p>... then run them via <code>npm run dev</code> and <code>npm run build</code>.</p>\n\n<hr />\n\n<h2 id=\"fullwebpacksetup\">Full Webpack Setup</h2>\n\n<p>This is a basic Webpack project template for a web app written in ES6 &amp; LESS.</p>\n\n<p>This assumes you have a directory structure as follows:</p>\n\n<pre><code>package.json  \nwebpack.config.js  \nsrc/  \n  index.js\n  static/\n    index.html\n</code></pre>\n\n<hr />\n\n<h4 id=\"installation\">Installation</h4>\n\n<p><strong>1. Clone the repo and start your own:</strong></p>\n\n<pre><code class=\"language-sh\">git clone git@gist.github.com:3c83db422f03ef66ea36.git  \nrm -rf .git  \ngit init  \n</code></pre>\n\n<p><strong>2. Install dependencies:</strong></p>\n\n<pre><code class=\"language-sh\">npm install  \n</code></pre>\n\n<p>That's it.</p>\n\n<h4 id=\"developmentworkflow\">Development Workflow</h4>\n\n<p><strong>Start the live-reload dev server:</strong></p>\n\n<pre><code class=\"language-sh\">PORT=8080 npm run dev  \n</code></pre>\n\n<p>Open up <a href=\"http://localhost:8080/webpack-dev-server/\">http://localhost:8080/webpack-dev-server/</a> to see your app. <br />\nThe app gets reloaded as files change.</p>\n\n<h4 id=\"deploymentworkflow\">Deployment Workflow</h4>\n\n<p>To deploy your static app, upload the contents of <code>build/</code> to a web server.</p>\n\n<p>Or, push this repo to heroku. <code>http-server</code> is used to serve the files in <code>build/</code>.</p>\n\n<p>Or, and like the best option, deploy this to Firebase. Use this <a href=\"https://gist.github.com/developit/b27ad8af7eacf92d2ef9\">firebase.json</a>.</p>\n\n<h4 id=\"packagejson\"><code>package.json</code></h4>\n\n<script src=\"https://gist.github.com/developit/042c6c87f34c4f211072.js\"></script>\n\n<h4 id=\"webpackconfigjs\"><code>webpack.config.js</code></h4>\n\n<script src=\"https://gist.github.com/developit/83fca68d58cc3dbad909.js\"></script>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2015-10-29T03:00:05.790Z","created_by":1,"updated_at":"2015-10-29T03:36:29.049Z","updated_by":1,"published_at":"2015-10-29T03:00:00.000Z","published_by":1},{"id":14,"uuid":"96050679-2b0e-4dc7-8a02-c1d4d8ccd867","title":"Selective SSR Today","slug":"selective-ssr-today","markdown":"<img src=\"https://i.imgur.com/o1HjFX8.png\" width=\"450\">\n\nThe term \"SSR\" (Server-Side Rendering) is used colloquially to refer to the popular technique of prerendering an app on the server in response to navigation requests, then booting that app on the client to \"upgrade\" to a Single Page Application.\n\nThis technique has seen widespread adoption in recent years as a result of frameworks gaining the ability to render in non-browser environments like Node.js. There are a plethora of tools available for implementing SSR, offering novel solutions to data sharing between the server and client in order to make the development experience seamless. However, these impressive engineering efforts are battling some pretty difficult challenges and tradeoffs.\n\nIn the best case, a setup for doing [SSR with CSR Hydration](https://developers.google.com/web/updates/2019/02/rendering-on-the-web#rehydration) can deliver optimal loading performance since it sends content to the browser prior to JavaScript being executed. It can be difficult to find this outcome in the wild though, since teams focused on delivering features often end up deviating from the prescribed loading patterns that make SSR effective.\n\nThe result is similar to a Single Page Application with limited or no SSR/prerendering, but where the cost for SSR is still paid on each request. The performance of applications grown this way is constrained by the time it takes to server-render a page _in addition_ to a long TTI while waiting for client boot-up and hydration.\n\n## Partial Hydration: A ray of hope\n\nWhile searching for SSR examples that have scaled well in production, I've struggled to find anyone using the Partial Hydration technique. \n\nWhat I'm looking for is sites that use novel techniques for rendering pages partially on the server (or at build time) and partially on the client. During server/build-time rendering, static portions of the DOM tree are identified, and their backing/owning (p)react components are _removed_ from the browser bundle(s). The dynamic portions of the DOM are then matched up to their corresponding components, and the DOM is annotated with a unique component name and data the component used to render:\n\n```html\n<div data-component=\"nav\"\n     data-props=\"{props-from-prerender}\">\n  <!-- server-rendered/prerendered HTML -->\n</div>\n```\n\n## Can we build on this?\n\nBuilding on the approach above, we can conceptualize a meta-framework that would decompose arbitrary (p)react applications into isolated render roots, even when components are heavily nested. The output would be a series of module imports to guarantee execution order and avoid blocking script load/exec, and component roots identified as Custom Elements.\n\nEach dynamic component would be compiled into a Custom Element wrapper that would obtain server-rendered (or prerendered) props/data from a `<template>` included its first child. This avoids the unnecessary parser overhead of data embedded as JS, and avoids the loading implications associated with using inline scripts for that serialized hydration data.\n\n```html\n<head>\n  <script type=module src=main.js></script>\n  <script type=module src=nav.component.js></script>\n</head>\n<body>\n  <div class=\"app\">\n    <p>some static part of the tree identified\n       based on developer hints or a heuristic</p>\n\n    <lazy-component component=\"nav\">\n      <script type=\"text/props\">\n        {\"items\":[{\"url\":\"/\",\"name\":\"Home\"}]}\n      </script>\n\n      <!-- the component’s snapshot HTML: -->\n      <nav class=\"nav-1234\">\n        <a href=\"/\">Home</a>\n      </nav>\n    </lazy-component>\n\n    <p>more static bits</p>\n  </div>\n</body>\n```\n\nThis technique can be achieved in many different ways. What follows is a few variants that may provide different performance characteristics or potential points of optimization.\n\n### **Option 1:** Generated JS Modules for Hydration Data\n\nAn option could also be provided to externalize the data for each rendered component into a hashed JavaScript module. This would lose some of the repetition benefits of gzip/brotli compression, but would decrease the size of \nthe HTML document to be parsed. In effect, this would essentially prioritize rendering the entire rerendered/snapshotted HTML DOM tree over the loading of \ncomponents and their associated hydration data. It would also make better use of parallelism, as module scripts are parsed off the main thread.\n\n```html\n<script type=module src=main.js></script>\n<div class=\"app\">\n  <p>...</p>\n  <script type=module src=/data/nav-1234.js></script>\n  <script type=module src=nav.component.js></script>\n  <lazy-component component=\"nav\">\n    <nav class=\"nav-1234\">\n      <a href=\"/\">Home</a>\n    </nav>\n  </lazy-component>\n  <p>...</p>\n</div>\n```\n\n### **Option 2:** JS Modules for data loading\n\nAnother interesting option would be to inline script tags where their components occur in the tree, leveraging the fact that module scripts are never loaded twice. This could even perform \"chunking\" similar to what Webpack does for its code-splitting optimizations, allowing small component data objects to be merged into a single module dependency and loaded as in one hop.\n\n```html\n<script type=module src=common.js></script>\n<div class=\"app\">\n  <p>...</p>\n  <script type=module src=nav.component.js></script>\n  <lazy-component component=\"nav\">\n    <nav class=\"nav-1234\">\n      <a href=\"/\">Home</a>\n    </nav>\n    <script type=\"text/props\">\n      {\"items\":[{\"url\":\"/\",\"name\":\"Home\"}]}\n    </script>\n  </lazy-component>\n  <p>...</p>\n</div>\n```\n\n### **Option 3:** Prerender Data API\n\nFinally, another optimization could be to remove the inlined data entirely, and instead expose an API for loading component data programmatically. This would allow the client to determine data \"chunking\" boundaries dynamically, based on which components have their scripting loaded and are ready to render. Similar to optimizations in GraphQL and related technologies, the server could deposit a rendering GUID into the HTML document, allowing a simple data fetching solution to be exposed for components to request their pre-warmed page data.\n\nThe Server API for requesting this data could serve from an in-memory cache, since clients would request the data within a very short window after SSR. Beyond that window, or for unanticipated requests to the prerender data API, the server could return an error - this would cause data to be fetched on the client, either from a persistent fallback cache or directly from the data source.\n\n```html\n<script type=module src=main.js></script>\n<html data-render=\"2f982\">\n  <div class=\"app\">\n    <p>...</p>\n    <script type=module src=nav.component.js></script>\n    <!-- ^ does fetch('/__data/nav?r=2f982') -->\n    <lazy-component component=\"nav\">\n      <nav class=\"nav-1234\">\n        <a href=\"/\">Home</a>\n      </nav>\n    </lazy-component>\n    <p>...</p>\n  </div>\n</html>\n```\n\n## Why? Trade-offs\n\nProducing output of this form would provide exemplary performance characteristics. While it doesn't solve the TTFB issue inherent to all server rendering solutions, it addresses nearly everything else. The TTFB concern can be independently addressed by being selective about the nature of components allowed to render on the server, based primarily on cacheability and reuse estimation.\n\n<table>\n<tr>\n<td>⇣Solution | Metric⇢</td>\n<td>TTFB</td>\n<td>FP</td>\n<td>FCP</td>\n<td>TTI</td>\n<td>JS Size</td>\n<td>Scaling</td>\n</tr>\n<tr>\n<td>Server Rendering</td>\n<td>☔*</td>\n<td>⭐</td>\n<td>💯</td>\n<td>💯</td>\n<td>💯</td>\n<td>💯</td>\n</tr>\n<tr>\n<td>Static SSR</td>\n<td>💯</td>\n<td>⭐</td>\n<td>💯</td>\n<td>🌟</td>\n<td>🌟</td>\n<td>🌟</td>\n</tr>\n<tr>\n<td>SSR + Hydration</td>\n<td>☔*</td>\n<td>⭐</td>\n<td>⭐</td>\n<td>☔</td>\n<td>☔</td>\n<td>☔</td>\n</tr>\n<tr>\n<td>CSR + Prerendering</td>\n<td>💯</td>\n<td>💯</td>\n<td>⭐</td>\n<td>☔</td>\n<td>☔</td>\n<td>☔</td>\n</tr>\n<tr>\n<td>Full CSR</td>\n<td>💯</td>\n<td>💯</td>\n<td>☔</td>\n<td>☔</td>\n<td>☔</td>\n<td>☔</td>\n</tr>\n<tr>\n<td>Selective Hydration</td>\n<td>☔*</td>\n<td>⭐</td>\n<td>💯</td>\n<td>💯</td>\n<td>🌟</td>\n<td>🌟</td>\n</tr>\n</table>\n\n<small>_* TTFB **can** be improved in certain cases through careful caching._</small>\n\n\n>☔ = problematic / difficult to address  \n>⭐ = decent  \n>🌟 = good  \n>💯 = ideal\n\n\nThe trade-offs illustrated in the chart above show that Selective Hydration offers similar performance outcomes to those of Server Rendering and Static SSR. However, one important factor not shown here is that neither of the first two techniques follow the prevailing JavaScript-first authoring approach, and neither provide a seamless mechanism for mixing interactive and static portions of a page without context or language switching.\n\n## Could This Work Today?\n\nThe question remains: can this be done using a heuristic?  Perhaps it's worth exploring the option of making render roots explicit. One approach that could be used to efficiently denote the location of isolated components that allow rendering as a separate root would be to have developers inherit an alternative Component class when authoring.\n\nA solution for the React community might look something like the following code sample. Note: the use of [Hooks](https://reactjs.org/docs/hooks-intro.html) here could easily be replaced with a specific custom API like Next.js' [async getInitialProps()](https://nextjs.org/learn/basics/fetching-data-for-pages).\n\n\n**sidebar.js**:\n\n```js\nimport { createResource, useResource } from 'hydrator';\n\nconst getPages = createResource(url =>\n fetch('/api/pages').then(r => r.json())\n);\n\nconst Sidebar = ({ url }) => {\n  const pages = useResource(getPages(url));\n\n  return (\n    <aside class=\"sidebar\">\n      {pages.map(({ url, name }) =>\n        <a href={url}>{name}</a>\n      )}\n    </aside>\n  );\n}\n```\n\n**index.js**:\n\n```js\nimport hydrator from 'hydrator';\n\nconst Sidebar = hydrator(() => import('./sidebar'));\n\nconst App = ({ url }) => (\n  <div class=\"app\">\n    <h1>Hello World</h1>\n    <Sidebar url={url} />\n    <p>some content here</p>\n  </div>\n);\n\n// server-side rendering:\nconst ssr = req => renderToString(<App {...req} />);\n\n// client-side rendering:\nconst csr = data => render(<App {...data} />, root);\n```\n\nThis solves the \"multiple render roots\" problem for Selective Hydration, since each Component annotated via hydrator can be loaded independently of its surrounding application when booting on the client. Once the parent tree is hydrated (in full or selectively itself), the Virtual DOM tree and its associated hydrated DOM tree are stitched into it and allowed to re-render such that any new props can flow down the tree.\n\nThis approach may still leave a potential difficult case for large applications, where the root of the component hierarchy can become heavy as complexity increases. A centralized store mechanism with provisions for late injection of behaviours and partial states (redux, mobx, unstated, unistore, etc) could be used.\n\n\n## Nothing is New\n\nSolutions have existed for producing outputs like these for some time. In particular, the communities around server-rendered application frameworks like Rails have built adaptors to allow React components to be rendered on the server, then individually loaded and hydrated with data on the client.\n\nThe common area where existing solutions fall over is that they don't provide developers with a single Component model that transcends rendering location. This breaks one of the fundamental value propositions of React, which is that idiomatic React applications can be rendered in any JavaScript environment.\n\n## Next Steps\n\nPrototype an implementation of the hydrator library + example + server shown above, and demonstrate the performance outcomes. Demonstrate that, as an application grows in size and complexity, the amount of JavaScript required to get any single part of the application interactive remains a function of the size of that part of the application, not of the application as a whole.\n","html":"<p><img src=\"https://i.imgur.com/o1HjFX8.png\" width=\"450\"></p>\n\n<p>The term \"SSR\" (Server-Side Rendering) is used colloquially to refer to the popular technique of prerendering an app on the server in response to navigation requests, then booting that app on the client to \"upgrade\" to a Single Page Application.</p>\n\n<p>This technique has seen widespread adoption in recent years as a result of frameworks gaining the ability to render in non-browser environments like Node.js. There are a plethora of tools available for implementing SSR, offering novel solutions to data sharing between the server and client in order to make the development experience seamless. However, these impressive engineering efforts are battling some pretty difficult challenges and tradeoffs.</p>\n\n<p>In the best case, a setup for doing <a href=\"https://developers.google.com/web/updates/2019/02/rendering-on-the-web#rehydration\">SSR with CSR Hydration</a> can deliver optimal loading performance since it sends content to the browser prior to JavaScript being executed. It can be difficult to find this outcome in the wild though, since teams focused on delivering features often end up deviating from the prescribed loading patterns that make SSR effective.</p>\n\n<p>The result is similar to a Single Page Application with limited or no SSR/prerendering, but where the cost for SSR is still paid on each request. The performance of applications grown this way is constrained by the time it takes to server-render a page <em>in addition</em> to a long TTI while waiting for client boot-up and hydration.</p>\n\n<h2 id=\"partialhydrationarayofhope\">Partial Hydration: A ray of hope</h2>\n\n<p>While searching for SSR examples that have scaled well in production, I've struggled to find anyone using the Partial Hydration technique. </p>\n\n<p>What I'm looking for is sites that use novel techniques for rendering pages partially on the server (or at build time) and partially on the client. During server/build-time rendering, static portions of the DOM tree are identified, and their backing/owning (p)react components are <em>removed</em> from the browser bundle(s). The dynamic portions of the DOM are then matched up to their corresponding components, and the DOM is annotated with a unique component name and data the component used to render:</p>\n\n<pre><code class=\"language-html\">&lt;div data-component=\"nav\"  \n     data-props=\"{props-from-prerender}\"&gt;\n  &lt;!-- server-rendered/prerendered HTML --&gt;\n&lt;/div&gt;  \n</code></pre>\n\n<h2 id=\"canwebuildonthis\">Can we build on this?</h2>\n\n<p>Building on the approach above, we can conceptualize a meta-framework that would decompose arbitrary (p)react applications into isolated render roots, even when components are heavily nested. The output would be a series of module imports to guarantee execution order and avoid blocking script load/exec, and component roots identified as Custom Elements.</p>\n\n<p>Each dynamic component would be compiled into a Custom Element wrapper that would obtain server-rendered (or prerendered) props/data from a <code>&lt;template&gt;</code> included its first child. This avoids the unnecessary parser overhead of data embedded as JS, and avoids the loading implications associated with using inline scripts for that serialized hydration data.</p>\n\n<pre><code class=\"language-html\">&lt;head&gt;  \n  &lt;script type=module src=main.js&gt;&lt;/script&gt;\n  &lt;script type=module src=nav.component.js&gt;&lt;/script&gt;\n&lt;/head&gt;  \n&lt;body&gt;  \n  &lt;div class=\"app\"&gt;\n    &lt;p&gt;some static part of the tree identified\n       based on developer hints or a heuristic&lt;/p&gt;\n\n    &lt;lazy-component component=\"nav\"&gt;\n      &lt;script type=\"text/props\"&gt;\n        {\"items\":[{\"url\":\"/\",\"name\":\"Home\"}]}\n      &lt;/script&gt;\n\n      &lt;!-- the component’s snapshot HTML: --&gt;\n      &lt;nav class=\"nav-1234\"&gt;\n        &lt;a href=\"/\"&gt;Home&lt;/a&gt;\n      &lt;/nav&gt;\n    &lt;/lazy-component&gt;\n\n    &lt;p&gt;more static bits&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/body&gt;  \n</code></pre>\n\n<p>This technique can be achieved in many different ways. What follows is a few variants that may provide different performance characteristics or potential points of optimization.</p>\n\n<h3 id=\"option1generatedjsmodulesforhydrationdata\"><strong>Option 1:</strong> Generated JS Modules for Hydration Data</h3>\n\n<p>An option could also be provided to externalize the data for each rendered component into a hashed JavaScript module. This would lose some of the repetition benefits of gzip/brotli compression, but would decrease the size of <br />\nthe HTML document to be parsed. In effect, this would essentially prioritize rendering the entire rerendered/snapshotted HTML DOM tree over the loading of <br />\ncomponents and their associated hydration data. It would also make better use of parallelism, as module scripts are parsed off the main thread.</p>\n\n<pre><code class=\"language-html\">&lt;script type=module src=main.js&gt;&lt;/script&gt;  \n&lt;div class=\"app\"&gt;  \n  &lt;p&gt;...&lt;/p&gt;\n  &lt;script type=module src=/data/nav-1234.js&gt;&lt;/script&gt;\n  &lt;script type=module src=nav.component.js&gt;&lt;/script&gt;\n  &lt;lazy-component component=\"nav\"&gt;\n    &lt;nav class=\"nav-1234\"&gt;\n      &lt;a href=\"/\"&gt;Home&lt;/a&gt;\n    &lt;/nav&gt;\n  &lt;/lazy-component&gt;\n  &lt;p&gt;...&lt;/p&gt;\n&lt;/div&gt;  \n</code></pre>\n\n<h3 id=\"option2jsmodulesfordataloading\"><strong>Option 2:</strong> JS Modules for data loading</h3>\n\n<p>Another interesting option would be to inline script tags where their components occur in the tree, leveraging the fact that module scripts are never loaded twice. This could even perform \"chunking\" similar to what Webpack does for its code-splitting optimizations, allowing small component data objects to be merged into a single module dependency and loaded as in one hop.</p>\n\n<pre><code class=\"language-html\">&lt;script type=module src=common.js&gt;&lt;/script&gt;  \n&lt;div class=\"app\"&gt;  \n  &lt;p&gt;...&lt;/p&gt;\n  &lt;script type=module src=nav.component.js&gt;&lt;/script&gt;\n  &lt;lazy-component component=\"nav\"&gt;\n    &lt;nav class=\"nav-1234\"&gt;\n      &lt;a href=\"/\"&gt;Home&lt;/a&gt;\n    &lt;/nav&gt;\n    &lt;script type=\"text/props\"&gt;\n      {\"items\":[{\"url\":\"/\",\"name\":\"Home\"}]}\n    &lt;/script&gt;\n  &lt;/lazy-component&gt;\n  &lt;p&gt;...&lt;/p&gt;\n&lt;/div&gt;  \n</code></pre>\n\n<h3 id=\"option3prerenderdataapi\"><strong>Option 3:</strong> Prerender Data API</h3>\n\n<p>Finally, another optimization could be to remove the inlined data entirely, and instead expose an API for loading component data programmatically. This would allow the client to determine data \"chunking\" boundaries dynamically, based on which components have their scripting loaded and are ready to render. Similar to optimizations in GraphQL and related technologies, the server could deposit a rendering GUID into the HTML document, allowing a simple data fetching solution to be exposed for components to request their pre-warmed page data.</p>\n\n<p>The Server API for requesting this data could serve from an in-memory cache, since clients would request the data within a very short window after SSR. Beyond that window, or for unanticipated requests to the prerender data API, the server could return an error - this would cause data to be fetched on the client, either from a persistent fallback cache or directly from the data source.</p>\n\n<pre><code class=\"language-html\">&lt;script type=module src=main.js&gt;&lt;/script&gt;  \n&lt;html data-render=\"2f982\"&gt;  \n  &lt;div class=\"app\"&gt;\n    &lt;p&gt;...&lt;/p&gt;\n    &lt;script type=module src=nav.component.js&gt;&lt;/script&gt;\n    &lt;!-- ^ does fetch('/__data/nav?r=2f982') --&gt;\n    &lt;lazy-component component=\"nav\"&gt;\n      &lt;nav class=\"nav-1234\"&gt;\n        &lt;a href=\"/\"&gt;Home&lt;/a&gt;\n      &lt;/nav&gt;\n    &lt;/lazy-component&gt;\n    &lt;p&gt;...&lt;/p&gt;\n  &lt;/div&gt;\n&lt;/html&gt;  \n</code></pre>\n\n<h2 id=\"whytradeoffs\">Why? Trade-offs</h2>\n\n<p>Producing output of this form would provide exemplary performance characteristics. While it doesn't solve the TTFB issue inherent to all server rendering solutions, it addresses nearly everything else. The TTFB concern can be independently addressed by being selective about the nature of components allowed to render on the server, based primarily on cacheability and reuse estimation.</p>\n\n<table>  \n<tr>  \n<td>⇣Solution | Metric⇢</td>  \n<td>TTFB</td>  \n<td>FP</td>  \n<td>FCP</td>  \n<td>TTI</td>  \n<td>JS Size</td>  \n<td>Scaling</td>  \n</tr>  \n<tr>  \n<td>Server Rendering</td>  \n<td>☔*</td>  \n<td>⭐</td>  \n<td>💯</td>  \n<td>💯</td>  \n<td>💯</td>  \n<td>💯</td>  \n</tr>  \n<tr>  \n<td>Static SSR</td>  \n<td>💯</td>  \n<td>⭐</td>  \n<td>💯</td>  \n<td>🌟</td>  \n<td>🌟</td>  \n<td>🌟</td>  \n</tr>  \n<tr>  \n<td>SSR + Hydration</td>  \n<td>☔*</td>  \n<td>⭐</td>  \n<td>⭐</td>  \n<td>☔</td>  \n<td>☔</td>  \n<td>☔</td>  \n</tr>  \n<tr>  \n<td>CSR + Prerendering</td>  \n<td>💯</td>  \n<td>💯</td>  \n<td>⭐</td>  \n<td>☔</td>  \n<td>☔</td>  \n<td>☔</td>  \n</tr>  \n<tr>  \n<td>Full CSR</td>  \n<td>💯</td>  \n<td>💯</td>  \n<td>☔</td>  \n<td>☔</td>  \n<td>☔</td>  \n<td>☔</td>  \n</tr>  \n<tr>  \n<td>Selective Hydration</td>  \n<td>☔*</td>  \n<td>⭐</td>  \n<td>💯</td>  \n<td>💯</td>  \n<td>🌟</td>  \n<td>🌟</td>  \n</tr>  \n</table>\n\n<p><small><em>* TTFB <strong>can</strong> be improved in certain cases through careful caching.</em></small></p>\n\n<blockquote>\n  <p>☔ = problematic / difficult to address <br />\n  ⭐ = decent <br />\n  🌟 = good <br />\n  💯 = ideal</p>\n</blockquote>\n\n<p>The trade-offs illustrated in the chart above show that Selective Hydration offers similar performance outcomes to those of Server Rendering and Static SSR. However, one important factor not shown here is that neither of the first two techniques follow the prevailing JavaScript-first authoring approach, and neither provide a seamless mechanism for mixing interactive and static portions of a page without context or language switching.</p>\n\n<h2 id=\"couldthisworktoday\">Could This Work Today?</h2>\n\n<p>The question remains: can this be done using a heuristic?  Perhaps it's worth exploring the option of making render roots explicit. One approach that could be used to efficiently denote the location of isolated components that allow rendering as a separate root would be to have developers inherit an alternative Component class when authoring.</p>\n\n<p>A solution for the React community might look something like the following code sample. Note: the use of <a href=\"https://reactjs.org/docs/hooks-intro.html\">Hooks</a> here could easily be replaced with a specific custom API like Next.js' <a href=\"https://nextjs.org/learn/basics/fetching-data-for-pages\">async getInitialProps()</a>.</p>\n\n<p><strong>sidebar.js</strong>:</p>\n\n<pre><code class=\"language-js\">import { createResource, useResource } from 'hydrator';\n\nconst getPages = createResource(url =&gt;  \n fetch('/api/pages').then(r =&gt; r.json())\n);\n\nconst Sidebar = ({ url }) =&gt; {  \n  const pages = useResource(getPages(url));\n\n  return (\n    &lt;aside class=\"sidebar\"&gt;\n      {pages.map(({ url, name }) =&gt;\n        &lt;a href={url}&gt;{name}&lt;/a&gt;\n      )}\n    &lt;/aside&gt;\n  );\n}\n</code></pre>\n\n<p><strong>index.js</strong>:</p>\n\n<pre><code class=\"language-js\">import hydrator from 'hydrator';\n\nconst Sidebar = hydrator(() =&gt; import('./sidebar'));\n\nconst App = ({ url }) =&gt; (  \n  &lt;div class=\"app\"&gt;\n    &lt;h1&gt;Hello World&lt;/h1&gt;\n    &lt;Sidebar url={url} /&gt;\n    &lt;p&gt;some content here&lt;/p&gt;\n  &lt;/div&gt;\n);\n\n// server-side rendering:\nconst ssr = req =&gt; renderToString(&lt;App {...req} /&gt;);\n\n// client-side rendering:\nconst csr = data =&gt; render(&lt;App {...data} /&gt;, root);  \n</code></pre>\n\n<p>This solves the \"multiple render roots\" problem for Selective Hydration, since each Component annotated via hydrator can be loaded independently of its surrounding application when booting on the client. Once the parent tree is hydrated (in full or selectively itself), the Virtual DOM tree and its associated hydrated DOM tree are stitched into it and allowed to re-render such that any new props can flow down the tree.</p>\n\n<p>This approach may still leave a potential difficult case for large applications, where the root of the component hierarchy can become heavy as complexity increases. A centralized store mechanism with provisions for late injection of behaviours and partial states (redux, mobx, unstated, unistore, etc) could be used.</p>\n\n<h2 id=\"nothingisnew\">Nothing is New</h2>\n\n<p>Solutions have existed for producing outputs like these for some time. In particular, the communities around server-rendered application frameworks like Rails have built adaptors to allow React components to be rendered on the server, then individually loaded and hydrated with data on the client.</p>\n\n<p>The common area where existing solutions fall over is that they don't provide developers with a single Component model that transcends rendering location. This breaks one of the fundamental value propositions of React, which is that idiomatic React applications can be rendered in any JavaScript environment.</p>\n\n<h2 id=\"nextsteps\">Next Steps</h2>\n\n<p>Prototype an implementation of the hydrator library + example + server shown above, and demonstrate the performance outcomes. Demonstrate that, as an application grows in size and complexity, the amount of JavaScript required to get any single part of the application interactive remains a function of the size of that part of the application, not of the application as a whole.</p>","image":null,"featured":false,"page":false,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2019-02-14T00:50:49.460Z","created_by":1,"updated_at":"2021-01-21T16:00:02.313Z","updated_by":1,"published_at":null,"published_by":null},{"id":19,"uuid":"bb67e37f-78ea-4c38-bbe5-37e7f6ed1173","title":"Islands Architecture","slug":"islands-architecture","markdown":"<img src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095361/krzysztof-grech-6orUY98fw9s-unsplash_r6wjnf.jpg\">\n\n<div style=\"text-align:right;position:relative;top:-2em;right:5px;opacity:0.5;\">\n<a style=\"font-size:60%;color:#aaa;text-decoration:none;\" href=\"https://unsplash.com/photos/6orUY98fw9s\" target=\"_blank\">Photo by Krzysztof Grech</a>\n</div>\n\nI’ve struggled to find references to this online, but heard the name used multiple times this year when describing the approach outlined here.\n\nThe general idea of an “Islands” architecture is deceptively simple: render HTML pages on the server, and inject placeholders or slots around highly dynamic regions. These placeholders/slots contain the server-rendered HTML output from their corresponding widget. They denote regions that can then be \"hydrated\" on the client into small self-contained widgets, reusing their server-rendered initial HTML.\n\nYou can think of this like a static HTML document that contains multiple separate embedded applications:\n\n<p align=\"center\">\n<img width=\"600\" src=\"https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-1.png\">\n</p>\n\nThis may seem similar to \"micro-frontends\" at first glance. Both approaches share the idea of breaking applications up into independent units, however \"micro-frontends\" do not typically imply that composition of those units is achieved using HTML.\n\nA closer analog to the \"islands\" approach would be progressive enhancement, to which we're essentially adding SSR hydration and a consistent metaphor for adding interactivity to a region of the page. In traditional progressive enhancement, we might have a `<script>` that looks for an image carousel in the page and instantiates a jQuery plugin on it. Instead, that image carousel would be rendered on the server and a dedicated `<script>` emitted for it that loads the image carousel implementation and in-place upgrades it to be interactive.\n\n\n### Why does this matter?\n\nAs it turns out, there are a number of benefits to the group of approaches described here when compared to typical Single Page Application architectures.\n\n\n##### \"Progressive Hydration\" for free\n\nI’ve touted the performance benefits of [Progressive Hydration](https://www.youtube.com/watch?v=k-A2VfuUROg) techniques for frameworks like React, Angular, Preact and Vue. With these architectures, individual widgets on a page are loaded and initialized over time. This can be done using a simple scheduling approach via requestIdleCallback, or can take additional factors into account like viewport visibility, interaction likelihood, product value, etc.\n\nSimilar to Progressive Hydration, rendering pages using an islands architecture results in the heavier dynamic portions of the page being initialized not just progressively, but _separately_. This means individual regions of the page become interactive without anything else on the page needing to be loaded first.\n\nUnlike Progressive Hydration, the approaches that fall out of building around an islands architecture do not require top-down rendering. This is a distinct advantage, since there are no outer “root” components that must be initialized before their descendants. Each part of the page is an isolated unit, and a performance issue in one unit doesn't affect the others.\n\n\n##### SEO and UX aren’t a tradeoff\n\nThe status quo for SSR as used by Single Page Applications is that it’s often cited as a necessity for SEO reasons. However, SSR can actually have a net _negative_ impact on User Experience - visitors are left waiting for the actual functionality of a page to arrive while staring at a frustratingly fake version of that page.\n\nMany applications also suffer from silent SSR performance pitfalls without realizing it. In virtual DOM libraries, it's easy (and common) to accidentally construct a situation where first render destroys the server-rendered HTML DOM, only to recreate it again from scratch (often synchronously). This is the result of some common misconceptions, which may stem from documentation giving an idealized view of hydration while passing over tricky caveats and footguns.\n\nEven in cases where SSR hydration is functioning as designed, the status quo leaves a lot to be desired. The amount of JavaScript work being performed during page load is still many orders of magnitude more than what might be considered \"efficient\".\n\n<figure>\n<img width=\"500\" src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_1000/v1597095374/dave-hoefler-NYVc84Gh78I-unsplash_oqyquc.jpg\">\n<figcaption><a href=\"https://unsplash.com/photos/NYVc84Gh78I\" target=\"_blank\">Photo by Dave Hoefler</a></figcaption>\n</figure>\n\n\nIn an \"islands\" model, server rendering is not a bolt-on optimization aimed at improving SEO or UX. Instead, it is a fundamental part of how pages are delivered to the browser. The HTML returned in response to navigation contains a meaningful and immediately renderable representation of the content the user requested.\n\nSections of that HTML may be missing their client-side interactivity, but the document should at least contain the most essential content. For example: a news page’s HTML would contain the article body, and a product page would contain that product’s description.\n\nAll of the other content is secondary to this information, and its inclusion in the HTML becomes a product decision. How vital is this bit of information to a user visiting the page? How important is that widget to the business model? A \"buy now\" button that directly relates to revenue should be easily prioritized over a site feedback survey button that relates to information gathering.\n\n\n##### Better for accessibility and discoverability\n\nA website that uses standard HTML links for navigation is easier for assistive technologies and web crawlers to use. This is true regardless of whether links or forms are intercepted by JavaScript and rerouted to client-side logic, because the underlying assumptions remain true: clicking a link navigates to the given page.\n\nAnecdotally, think of the number of times you’ve been sent a “link” to what the sender assumed was the page they were viewing, only to realize the link contained none of the necessary information:\n\n<p style=\"text-align:center;\">\n<img width=\"350\" style=\"box-shadow:0 3px 9px rgba(0,0,0,0.2);\" src=\"https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-3.png\">\n</p>\n\n\nBuilding page-based applications doesn't completely prevent these types of strange experiences, it only makes the decision to do so more direct. It makes the default outcome the accessible one.\n\n<hr>\n\nWhen it comes down to it, shipping an architecture that requires less code to do something is the type of long-term benefit your future self (or coworkers) will thank you for. It's possible — likely, even — that adopting a model like this requires more up-front design thinking. There are far few batteries-included options available for decomposing apps into independently deliverable widgets. Who knows, maybe we can fix that.\n\n<figure>\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095373/max-hermansson-3AsAVTBIw5I-unsplash_t7bmip.jpg\">\n<figcaption><a href=\"https://unsplash.com/photos/3AsAVTBIw5I\" target=\"_blank\">Photo by Max Hermansson</a></figcaption>\n</figure>\n\n<style>\n  figure { text-align:center; }\n  figure > img { padding-bottom:0 !important; }\n  figure > figcaption { max-width:600px; text-align:right; position:relative; top:-.5em; }\n  figure a { font-size:70%; color:#aaa; text-decoration:none; }\n</style>","html":"<p><img src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095361/krzysztof-grech-6orUY98fw9s-unsplash_r6wjnf.jpg\"></p>\n\n<div style=\"text-align:right;position:relative;top:-2em;right:5px;opacity:0.5;\">  \n<a style=\"font-size:60%;color:#aaa;text-decoration:none;\" href=\"https://unsplash.com/photos/6orUY98fw9s\" target=\"_blank\">Photo by Krzysztof Grech</a>  \n</div>\n\n<p>I’ve struggled to find references to this online, but heard the name used multiple times this year when describing the approach outlined here.</p>\n\n<p>The general idea of an “Islands” architecture is deceptively simple: render HTML pages on the server, and inject placeholders or slots around highly dynamic regions. These placeholders/slots contain the server-rendered HTML output from their corresponding widget. They denote regions that can then be \"hydrated\" on the client into small self-contained widgets, reusing their server-rendered initial HTML.</p>\n\n<p>You can think of this like a static HTML document that contains multiple separate embedded applications:</p>\n\n<p align=\"center\">  \n<img width=\"600\" src=\"https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-1.png\">  \n</p>\n\n<p>This may seem similar to \"micro-frontends\" at first glance. Both approaches share the idea of breaking applications up into independent units, however \"micro-frontends\" do not typically imply that composition of those units is achieved using HTML.</p>\n\n<p>A closer analog to the \"islands\" approach would be progressive enhancement, to which we're essentially adding SSR hydration and a consistent metaphor for adding interactivity to a region of the page. In traditional progressive enhancement, we might have a <code>&lt;script&gt;</code> that looks for an image carousel in the page and instantiates a jQuery plugin on it. Instead, that image carousel would be rendered on the server and a dedicated <code>&lt;script&gt;</code> emitted for it that loads the image carousel implementation and in-place upgrades it to be interactive.</p>\n\n<h3 id=\"whydoesthismatter\">Why does this matter?</h3>\n\n<p>As it turns out, there are a number of benefits to the group of approaches described here when compared to typical Single Page Application architectures.</p>\n\n<h5 id=\"progressivehydrationforfree\">\"Progressive Hydration\" for free</h5>\n\n<p>I’ve touted the performance benefits of <a href=\"https://www.youtube.com/watch?v=k-A2VfuUROg\">Progressive Hydration</a> techniques for frameworks like React, Angular, Preact and Vue. With these architectures, individual widgets on a page are loaded and initialized over time. This can be done using a simple scheduling approach via requestIdleCallback, or can take additional factors into account like viewport visibility, interaction likelihood, product value, etc.</p>\n\n<p>Similar to Progressive Hydration, rendering pages using an islands architecture results in the heavier dynamic portions of the page being initialized not just progressively, but <em>separately</em>. This means individual regions of the page become interactive without anything else on the page needing to be loaded first.</p>\n\n<p>Unlike Progressive Hydration, the approaches that fall out of building around an islands architecture do not require top-down rendering. This is a distinct advantage, since there are no outer “root” components that must be initialized before their descendants. Each part of the page is an isolated unit, and a performance issue in one unit doesn't affect the others.</p>\n\n<h5 id=\"seoanduxarentatradeoff\">SEO and UX aren’t a tradeoff</h5>\n\n<p>The status quo for SSR as used by Single Page Applications is that it’s often cited as a necessity for SEO reasons. However, SSR can actually have a net <em>negative</em> impact on User Experience - visitors are left waiting for the actual functionality of a page to arrive while staring at a frustratingly fake version of that page.</p>\n\n<p>Many applications also suffer from silent SSR performance pitfalls without realizing it. In virtual DOM libraries, it's easy (and common) to accidentally construct a situation where first render destroys the server-rendered HTML DOM, only to recreate it again from scratch (often synchronously). This is the result of some common misconceptions, which may stem from documentation giving an idealized view of hydration while passing over tricky caveats and footguns.</p>\n\n<p>Even in cases where SSR hydration is functioning as designed, the status quo leaves a lot to be desired. The amount of JavaScript work being performed during page load is still many orders of magnitude more than what might be considered \"efficient\".</p>\n\n<figure>  \n<img width=\"500\" src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_1000/v1597095374/dave-hoefler-NYVc84Gh78I-unsplash_oqyquc.jpg\">  \n<figcaption><a href=\"https://unsplash.com/photos/NYVc84Gh78I\" target=\"_blank\">Photo by Dave Hoefler</a></figcaption>  \n</figure>\n\n<p>In an \"islands\" model, server rendering is not a bolt-on optimization aimed at improving SEO or UX. Instead, it is a fundamental part of how pages are delivered to the browser. The HTML returned in response to navigation contains a meaningful and immediately renderable representation of the content the user requested.</p>\n\n<p>Sections of that HTML may be missing their client-side interactivity, but the document should at least contain the most essential content. For example: a news page’s HTML would contain the article body, and a product page would contain that product’s description.</p>\n\n<p>All of the other content is secondary to this information, and its inclusion in the HTML becomes a product decision. How vital is this bit of information to a user visiting the page? How important is that widget to the business model? A \"buy now\" button that directly relates to revenue should be easily prioritized over a site feedback survey button that relates to information gathering.</p>\n\n<h5 id=\"betterforaccessibilityanddiscoverability\">Better for accessibility and discoverability</h5>\n\n<p>A website that uses standard HTML links for navigation is easier for assistive technologies and web crawlers to use. This is true regardless of whether links or forms are intercepted by JavaScript and rerouted to client-side logic, because the underlying assumptions remain true: clicking a link navigates to the given page.</p>\n\n<p>Anecdotally, think of the number of times you’ve been sent a “link” to what the sender assumed was the page they were viewing, only to realize the link contained none of the necessary information:</p>\n\n<p style=\"text-align:center;\">  \n<img width=\"350\" style=\"box-shadow:0 3px 9px rgba(0,0,0,0.2);\" src=\"https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-3.png\">  \n</p>\n\n<p>Building page-based applications doesn't completely prevent these types of strange experiences, it only makes the decision to do so more direct. It makes the default outcome the accessible one.</p>\n\n<hr>\n\n<p>When it comes down to it, shipping an architecture that requires less code to do something is the type of long-term benefit your future self (or coworkers) will thank you for. It's possible — likely, even — that adopting a model like this requires more up-front design thinking. There are far few batteries-included options available for decomposing apps into independently deliverable widgets. Who knows, maybe we can fix that.</p>\n\n<figure>  \n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095373/max-hermansson-3AsAVTBIw5I-unsplash_t7bmip.jpg\">  \n<figcaption><a href=\"https://unsplash.com/photos/3AsAVTBIw5I\" target=\"_blank\">Photo by Max Hermansson</a></figcaption>  \n</figure>\n\n<style>  \n  figure { text-align:center; }\n  figure > img { padding-bottom:0 !important; }\n  figure > figcaption { max-width:600px; text-align:right; position:relative; top:-.5em; }\n  figure a { font-size:70%; color:#aaa; text-decoration:none; }\n</style>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2020-08-07T01:39:51.218Z","created_by":1,"updated_at":"2020-08-11T14:03:24.668Z","updated_by":1,"published_at":"2020-08-11T14:01:17.288Z","published_by":1},{"id":6,"uuid":"6ec5bf8f-fe20-472f-8dd7-ceaf71cb8eeb","title":"Props Down, Events Up","slug":"props-down-events-up","markdown":"> Let's assume you're using some component-based Virtual DOM rendering library like [Preact](https://git.io/preact).\n>\n> Let's also assume you understand JSX - if you don't, check out my post, [WTF is JSX](/wtf-is-jsx).\n\nComponents are great, and they help us compose complex User Interfaces using an understandable hierarchy of independent, re-usable blocks of functionality.\n\nHowever, in choosing to build these distinct pieces of our User Interface in isolation from eachother, any communication between components must be done through a defined API. This is important for retaining proper encapsulation, which is how we keep everything as independent as possible.  This has an implication that can be a little tricky when getting started, particularly for those coming from frameworks where you can \"reach\" between arbitrary areas of an application.\n\nComponent-based rendering has to a \"golden rule\" to enforce this separation: ==Don't access a component's state from outside of that component==. State is transient, and intended to be private to a component.\n\nSo... how do we share data between components?\n\nIt's simple: **Props Down, Events Up.**\n\n\n---\n\n\n## Props Down\n\n> `props` are how data is passed **into** a Component.\n\nThis is exactly the same as how we pass props to elements in JSX:\n\n```js\nclass Foo extends Component {\n  render(props) {\n    return <div data-a={ props.a } />;\n  }\n}\n\n// Render Foo with an \"a\" value of \"ehh\":\nrender(<Foo a=\"ehh\" />, document.body);\n```\n\nOf course, this works much the same for _Pure Functions_:\n\n```js\nconst Foo = (props) => (\n  <div data-a={ props.a } />\n};\n\nrender(<Foo a=\"ehh\" />, document.body);\n```\n\nYou're not limited to just String `props`, JSX allows arbitrary JavaScript expressions as attribute values:\n\n```js\n<Foo a={ true } />\n<Foo a={ [1, 2] } />\n\nlet someValue = 42;\n<Foo a={ someValue } />\n```\n\n\n---\n\n\n## Events Up\n\n> `Events` are how data is passed **out of** a Component.\n\nEvents are just `props` where the value is a function, and the name _(generally)_ begins with `on*`.\n\nEvent handlers passed into a Component as `props` can be called whenever it suits, since they are just function references.\n\n\n---\n\n\n## Some Examples\n\nYou can proxy the handlers directly into the DOM as event listeners:\n\n```js\nclass A extends Component {\n  render({ onClick }) {\n    return <button onClick={onClick}>Proxied</button>\n  }\n}\n```\n\nOr, hold on to them and call them later in response to something happening:\n\n```js\nclass A extends Component {\n  // whichever bind() mechanism you prefer:\n  @bind\n  handleClick(e) {\n    let event = {\n      x: e.pageX,  // you can pass anything to event handlers\n      y: e.pageY   // though generally events are objects\n    };\n    this.props.onClick(event);\n  }\n  render() {\n    return <button onClick={this.handleClick}>Manual</button>\n  }\n}\n```\n\n\n---\n\n\n## Real-World Example\n\nLet's create a component that shows a wrapped HTML input element, perhaps in order to apply some fancy styling.  We want to proxy the events from the HTML element to whichever Component invokes our wrapper component.\n\n\n```js\nclass Child extends Component {\n  constructor({ text }) {\n    super();\n    // copy text into state\n    this.state = { text };\n  }\n  @bind\n  handleInput(e) {\n    // new value from the input\n    let text = e.target.value;\n\n    // update state to re-render\n    this.setState({ text });\n\n    // invoke the event handler we got passed as a prop:\n    this.props.onInput({ text });\n  }\n  render({ }, { text }) {\n    return <input value={text} onInput={this.handleInput} />;\n  }\n}\n\nclass Parent extends Component {\n  @bind\n  handleInput(e) {\n    // e is whatever WrappedInput passed up\n    let value = e.text;\n    this.setState({ value });\n  }\n  render({ }, { value }) {\n    return (\n      <div>\n        <Child text={value} onInput={this.handleInput} />\n      </div>\n    );\n  }\n}\n```\n\n\n---\n\n\n## Linked State & Custom Events\n\nYou probably noticed that `handleInput()` method seems to just be doing what Preact's built-in [Linked State][1] feature does automatically for us.\n\nIn fact, we can absolutely use [linkState][1] to capture values from Custom Events passed up from Components. All we need to do is tell `linkState()` to look for the right property on the event object being passed up from the child Component.\n\nIf you're not familiar with [linkState()][1], it's a function that creates an event handler that, when called, updates a given property in state with a new value from the event.\n\nThe first parameter to `linkState()` is a keypath to assign to within the state object. The optional second parameter is a keypath at which to find the new state value within Event. When omitted, linkState tries to detect the value for you.\n\n> `<a onClick={ linkState('foo', 'bar') }>`\n>\n> is roughly equivalent to:\n>\n> `<a onClick={ e => this.setState({ foo: e.bar }) }>`\n\n\nUsing `linkState()`, we can further simplify the parent component from the example to remove that verbose event handler altogether!\n\n```js\nclass Parent extends Component {\n  render({ }, { value }) {\n    return (\n      <div>\n        <Child\n          text={value}\n          onInput={this.linkState('value', 'text')}\n        />\n      </div>\n    );\n  }\n}\n```\n\n\n---\n\n\n## Who Does #2 Work For\n\nLastly, observe that the `text` state value in `<WrappedInput>` is duplicated as `value` within `<Parent>`.\n\n> This is often a clue that a component is trying to hold things in state that it realistically doesn't own.\n\nLet's see if we can let the Parent component retain full control over that state - doing so will make our Child component simpler and more [deterministic][2].\n\nInstead of managing state in the child component, we can just use whatever is passed to it as the `text` prop.\n\n```js\nclass Parent extends Component {\n  // parent owns its state:\n  state = {\n    value: 'Hello, World!'\n  };\n  render({ }, { value }) {\n    return (\n      <div>\n        <Child\n          text={value}\n          onInput={this.linkState('value', 'text')}\n        />\n      </div>\n    );\n  }\n}\n\nclass Child extends Component {\n  @bind\n  handleInput(e) {\n    let text = e.target.value;\n    this.props.onInput({ text });\n  }\n  render({ text }) {\n    return <input value={text} onInput={this.handleInput} />;\n  }\n}\n```\n\nHere's a working version of that [on JSFiddle](https://jsfiddle.net/developit/vuj2yu6y/):\n\n<iframe src=\"http://jsfiddle.net/developit/vuj2yu6y/embedded/result%2Cjs/\" style=\"border:2px solid #CCC;width:100%;height:400px;\"></iframe>\n\n\n---\n\n## Wrapping Things Up\n*(bad pun)*\n\nThis is a reasonable example of the concept of Smart and Dumb Components. \"Dumb\" components like `<Child>` in our example are highly reusable because they contain little or no logic, and don't include side effects like fetching data. \"Smart\" components are a place to organize collections of \"Dumb\" components to meet your needs.\n\n\n[1]: https://github.com/developit/preact/wiki/Linked-State\n[2]: https://en.wikipedia.org/wiki/Deterministic_system","html":"<blockquote>\n  <p>Let's assume you're using some component-based Virtual DOM rendering library like <a href=\"https://git.io/preact\">Preact</a>.</p>\n  \n  <p>Let's also assume you understand JSX - if you don't, check out my post, <a href=\"/wtf-is-jsx\">WTF is JSX</a>.</p>\n</blockquote>\n\n<p>Components are great, and they help us compose complex User Interfaces using an understandable hierarchy of independent, re-usable blocks of functionality.</p>\n\n<p>However, in choosing to build these distinct pieces of our User Interface in isolation from eachother, any communication between components must be done through a defined API. This is important for retaining proper encapsulation, which is how we keep everything as independent as possible.  This has an implication that can be a little tricky when getting started, particularly for those coming from frameworks where you can \"reach\" between arbitrary areas of an application.</p>\n\n<p>Component-based rendering has to a \"golden rule\" to enforce this separation: <mark>Don't access a component's state from outside of that component</mark>. State is transient, and intended to be private to a component.</p>\n\n<p>So... how do we share data between components?</p>\n\n<p>It's simple: <strong>Props Down, Events Up.</strong></p>\n\n<hr />\n\n<h2 id=\"propsdown\">Props Down</h2>\n\n<blockquote>\n  <p><code>props</code> are how data is passed <strong>into</strong> a Component.</p>\n</blockquote>\n\n<p>This is exactly the same as how we pass props to elements in JSX:</p>\n\n<pre><code class=\"language-js\">class Foo extends Component {  \n  render(props) {\n    return &lt;div data-a={ props.a } /&gt;;\n  }\n}\n\n// Render Foo with an \"a\" value of \"ehh\":\nrender(&lt;Foo a=\"ehh\" /&gt;, document.body);  \n</code></pre>\n\n<p>Of course, this works much the same for <em>Pure Functions</em>:</p>\n\n<pre><code class=\"language-js\">const Foo = (props) =&gt; (  \n  &lt;div data-a={ props.a } /&gt;\n};\n\nrender(&lt;Foo a=\"ehh\" /&gt;, document.body);  \n</code></pre>\n\n<p>You're not limited to just String <code>props</code>, JSX allows arbitrary JavaScript expressions as attribute values:</p>\n\n<pre><code class=\"language-js\">&lt;Foo a={ true } /&gt;  \n&lt;Foo a={ [1, 2] } /&gt;\n\nlet someValue = 42;  \n&lt;Foo a={ someValue } /&gt;  \n</code></pre>\n\n<hr />\n\n<h2 id=\"eventsup\">Events Up</h2>\n\n<blockquote>\n  <p><code>Events</code> are how data is passed <strong>out of</strong> a Component.</p>\n</blockquote>\n\n<p>Events are just <code>props</code> where the value is a function, and the name <em>(generally)</em> begins with <code>on*</code>.</p>\n\n<p>Event handlers passed into a Component as <code>props</code> can be called whenever it suits, since they are just function references.</p>\n\n<hr />\n\n<h2 id=\"someexamples\">Some Examples</h2>\n\n<p>You can proxy the handlers directly into the DOM as event listeners:</p>\n\n<pre><code class=\"language-js\">class A extends Component {  \n  render({ onClick }) {\n    return &lt;button onClick={onClick}&gt;Proxied&lt;/button&gt;\n  }\n}\n</code></pre>\n\n<p>Or, hold on to them and call them later in response to something happening:</p>\n\n<pre><code class=\"language-js\">class A extends Component {  \n  // whichever bind() mechanism you prefer:\n  @bind\n  handleClick(e) {\n    let event = {\n      x: e.pageX,  // you can pass anything to event handlers\n      y: e.pageY   // though generally events are objects\n    };\n    this.props.onClick(event);\n  }\n  render() {\n    return &lt;button onClick={this.handleClick}&gt;Manual&lt;/button&gt;\n  }\n}\n</code></pre>\n\n<hr />\n\n<h2 id=\"realworldexample\">Real-World Example</h2>\n\n<p>Let's create a component that shows a wrapped HTML input element, perhaps in order to apply some fancy styling.  We want to proxy the events from the HTML element to whichever Component invokes our wrapper component.</p>\n\n<pre><code class=\"language-js\">class Child extends Component {  \n  constructor({ text }) {\n    super();\n    // copy text into state\n    this.state = { text };\n  }\n  @bind\n  handleInput(e) {\n    // new value from the input\n    let text = e.target.value;\n\n    // update state to re-render\n    this.setState({ text });\n\n    // invoke the event handler we got passed as a prop:\n    this.props.onInput({ text });\n  }\n  render({ }, { text }) {\n    return &lt;input value={text} onInput={this.handleInput} /&gt;;\n  }\n}\n\nclass Parent extends Component {  \n  @bind\n  handleInput(e) {\n    // e is whatever WrappedInput passed up\n    let value = e.text;\n    this.setState({ value });\n  }\n  render({ }, { value }) {\n    return (\n      &lt;div&gt;\n        &lt;Child text={value} onInput={this.handleInput} /&gt;\n      &lt;/div&gt;\n    );\n  }\n}\n</code></pre>\n\n<hr />\n\n<h2 id=\"linkedstatecustomevents\">Linked State &amp; Custom Events</h2>\n\n<p>You probably noticed that <code>handleInput()</code> method seems to just be doing what Preact's built-in <a href=\"https://github.com/developit/preact/wiki/Linked-State\">Linked State</a> feature does automatically for us.</p>\n\n<p>In fact, we can absolutely use <a href=\"https://github.com/developit/preact/wiki/Linked-State\">linkState</a> to capture values from Custom Events passed up from Components. All we need to do is tell <code>linkState()</code> to look for the right property on the event object being passed up from the child Component.</p>\n\n<p>If you're not familiar with <a href=\"https://github.com/developit/preact/wiki/Linked-State\">linkState()</a>, it's a function that creates an event handler that, when called, updates a given property in state with a new value from the event.</p>\n\n<p>The first parameter to <code>linkState()</code> is a keypath to assign to within the state object. The optional second parameter is a keypath at which to find the new state value within Event. When omitted, linkState tries to detect the value for you.</p>\n\n<blockquote>\n  <p><code>&lt;a onClick={ linkState('foo', 'bar') }&gt;</code></p>\n  \n  <p>is roughly equivalent to:</p>\n  \n  <p><code>&lt;a onClick={ e =&gt; this.setState({ foo: e.bar }) }&gt;</code></p>\n</blockquote>\n\n<p>Using <code>linkState()</code>, we can further simplify the parent component from the example to remove that verbose event handler altogether!</p>\n\n<pre><code class=\"language-js\">class Parent extends Component {  \n  render({ }, { value }) {\n    return (\n      &lt;div&gt;\n        &lt;Child\n          text={value}\n          onInput={this.linkState('value', 'text')}\n        /&gt;\n      &lt;/div&gt;\n    );\n  }\n}\n</code></pre>\n\n<hr />\n\n<h2 id=\"whodoes2workfor\">Who Does #2 Work For</h2>\n\n<p>Lastly, observe that the <code>text</code> state value in <code>&lt;WrappedInput&gt;</code> is duplicated as <code>value</code> within <code>&lt;Parent&gt;</code>.</p>\n\n<blockquote>\n  <p>This is often a clue that a component is trying to hold things in state that it realistically doesn't own.</p>\n</blockquote>\n\n<p>Let's see if we can let the Parent component retain full control over that state - doing so will make our Child component simpler and more <a href=\"https://en.wikipedia.org/wiki/Deterministic_system\">deterministic</a>.</p>\n\n<p>Instead of managing state in the child component, we can just use whatever is passed to it as the <code>text</code> prop.</p>\n\n<pre><code class=\"language-js\">class Parent extends Component {  \n  // parent owns its state:\n  state = {\n    value: 'Hello, World!'\n  };\n  render({ }, { value }) {\n    return (\n      &lt;div&gt;\n        &lt;Child\n          text={value}\n          onInput={this.linkState('value', 'text')}\n        /&gt;\n      &lt;/div&gt;\n    );\n  }\n}\n\nclass Child extends Component {  \n  @bind\n  handleInput(e) {\n    let text = e.target.value;\n    this.props.onInput({ text });\n  }\n  render({ text }) {\n    return &lt;input value={text} onInput={this.handleInput} /&gt;;\n  }\n}\n</code></pre>\n\n<p>Here's a working version of that <a href=\"https://jsfiddle.net/developit/vuj2yu6y/\">on JSFiddle</a>:</p>\n\n<iframe src=\"http://jsfiddle.net/developit/vuj2yu6y/embedded/result%2Cjs/\" style=\"border:2px solid #CCC;width:100%;height:400px;\"></iframe>\n\n<hr />\n\n<h2 id=\"wrappingthingsup\">Wrapping Things Up</h2>\n\n<p><em>(bad pun)</em></p>\n\n<p>This is a reasonable example of the concept of Smart and Dumb Components. \"Dumb\" components like <code>&lt;Child&gt;</code> in our example are highly reusable because they contain little or no logic, and don't include side effects like fetching data. \"Smart\" components are a place to organize collections of \"Dumb\" components to meet your needs.</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2016-02-20T17:37:14.766Z","created_by":1,"updated_at":"2019-02-17T20:11:31.938Z","updated_by":1,"published_at":"2016-02-20T22:18:23.529Z","published_by":1},{"id":5,"uuid":"8f176238-ca56-4b34-a446-1d0cb935ef30","title":"How CSS Modules Work (today)","slug":"how-css-modules-work-today","markdown":"Here's a quick intro to how you can make use of [CSS Modules] today, using Webpack's awesome [css-loader].\n\nFirst off, let's make sure we're on the same page.  We want to colocate our CSS styles with our components, because they are already coupled anyway.  I'll be using `less` today, but this applies to raw CSS, LESS, SCSS, etc.\n\n### Folder Structure\n\n```\ncomponents/\n  foo/\n    index.js\n    style.less\n```\n\n\n### The Styles\n\nFirst off, let's write some LESS:\n\n```css\n.foo {\n    padding: 10px;\n\n    header.bar {\n        color: black;\n        font-size: 200%;\n    }\n}\n```\n\n... pretty standard LESS. The classNames are super generic, which is normally a horrible idea, but CSS modules are going to namespace everything so that collisions are extremely unlikely.\n\n\n### Importing CSS Modules\n\nIn order to use modular CSS, we need to \"import\" the styles.  This process transforms the CSS rules, namespacing all classes. As with normal imports, [css-loader] then injects your stylesheet into the document.  The big difference here is that there is an actual value returned from our import, which is an object mapping of *local* CSS class names to their *namespaced* versions.\n\n\n```js\nimport style from './style.less';\n\nexport default class Foo extends Component {\n    render() {\n        return (\n            <div class={ style.foo }>\n                <header class={ style.bar }>Sup</header>\n                etc\n            </div>\n        );\n    }\n}\n```\n\nIf you were to `console.log(style)`, you would see that in addition to \"injecting\" your CSS into the document, the import actually returns a mapping of class names to local class names:\n\n```js\nconsole.log(style);\n{ foo:\"foo_foo_abcde\", bar:\"foo_bar_abcde\" }\n```\n\n> **How this works:**  When you `import` the less/css/scss file, it gets added as a stylesheet _(somewhere, handled internally by [css-loader])_.  Your classnames will be transformed to \"local\" (namespaced) classnames.  You can control how this works, but the most common way is to transform `.class` into `filename_class_[hash:0:5]`.  This keeps things namespaced _(by file)_, versioned _(via the truncated hash)_, and readable _(the original class name is still there)_.\n\n\nAll of this means that when you set `class={style.foo}` in your JSX _(or any other form of markup)_, you're setting it to the _local_ version of that named class, `class=\"foo_foo_abcde\"`.\n\n---\n\nIn order for all of this to work, you need to tell [css-loader] that you want to use [CSS Modules]:\n\n```js\nmodule: {\n  loaders: [\n    {\n      test: /\\.(less|css)$/,\n      loader: [\n        'style',\n        'css?modules&importLoaders=1',\n        'less'   // if you want .less support\n      ].join('!')\n    }\n  ]\n}\n```\n\nIf you want to customize the imported \"local\" names, you can supply a simple template string for the `localIdentName` option:\n\n```js\ncss?modules&importLoaders=1&localIdentName=[local]_[hash:base64:5]\n```\n\nThink this seems worth it?\n\n[CSS Modules]: https://github.com/css-modules/css-modules\n[css-loader]: https://github.com/webpack/css-loader\n","html":"<p>Here's a quick intro to how you can make use of <a href=\"https://github.com/css-modules/css-modules\">CSS Modules</a> today, using Webpack's awesome <a href=\"https://github.com/webpack/css-loader\">css-loader</a>.</p>\n\n<p>First off, let's make sure we're on the same page.  We want to colocate our CSS styles with our components, because they are already coupled anyway.  I'll be using <code>less</code> today, but this applies to raw CSS, LESS, SCSS, etc.</p>\n\n<h3 id=\"folderstructure\">Folder Structure</h3>\n\n<pre><code>components/  \n  foo/\n    index.js\n    style.less\n</code></pre>\n\n<h3 id=\"thestyles\">The Styles</h3>\n\n<p>First off, let's write some LESS:</p>\n\n<pre><code class=\"language-css\">.foo {\n    padding: 10px;\n\n    header.bar {\n        color: black;\n        font-size: 200%;\n    }\n}\n</code></pre>\n\n<p>... pretty standard LESS. The classNames are super generic, which is normally a horrible idea, but CSS modules are going to namespace everything so that collisions are extremely unlikely.</p>\n\n<h3 id=\"importingcssmodules\">Importing CSS Modules</h3>\n\n<p>In order to use modular CSS, we need to \"import\" the styles.  This process transforms the CSS rules, namespacing all classes. As with normal imports, <a href=\"https://github.com/webpack/css-loader\">css-loader</a> then injects your stylesheet into the document.  The big difference here is that there is an actual value returned from our import, which is an object mapping of <em>local</em> CSS class names to their <em>namespaced</em> versions.</p>\n\n<pre><code class=\"language-js\">import style from './style.less';\n\nexport default class Foo extends Component {  \n    render() {\n        return (\n            &lt;div class={ style.foo }&gt;\n                &lt;header class={ style.bar }&gt;Sup&lt;/header&gt;\n                etc\n            &lt;/div&gt;\n        );\n    }\n}\n</code></pre>\n\n<p>If you were to <code>console.log(style)</code>, you would see that in addition to \"injecting\" your CSS into the document, the import actually returns a mapping of class names to local class names:</p>\n\n<pre><code class=\"language-js\">console.log(style);  \n{ foo:\"foo_foo_abcde\", bar:\"foo_bar_abcde\" }\n</code></pre>\n\n<blockquote>\n  <p><strong>How this works:</strong>  When you <code>import</code> the less/css/scss file, it gets added as a stylesheet <em>(somewhere, handled internally by <a href=\"https://github.com/webpack/css-loader\">css-loader</a>)</em>.  Your classnames will be transformed to \"local\" (namespaced) classnames.  You can control how this works, but the most common way is to transform <code>.class</code> into <code>filename_class_[hash:0:5]</code>.  This keeps things namespaced <em>(by file)</em>, versioned <em>(via the truncated hash)</em>, and readable <em>(the original class name is still there)</em>.</p>\n</blockquote>\n\n<p>All of this means that when you set <code>class={style.foo}</code> in your JSX <em>(or any other form of markup)</em>, you're setting it to the <em>local</em> version of that named class, <code>class=\"foo_foo_abcde\"</code>.</p>\n\n<hr />\n\n<p>In order for all of this to work, you need to tell <a href=\"https://github.com/webpack/css-loader\">css-loader</a> that you want to use <a href=\"https://github.com/css-modules/css-modules\">CSS Modules</a>:</p>\n\n<pre><code class=\"language-js\">module: {  \n  loaders: [\n    {\n      test: /\\.(less|css)$/,\n      loader: [\n        'style',\n        'css?modules&amp;importLoaders=1',\n        'less'   // if you want .less support\n      ].join('!')\n    }\n  ]\n}\n</code></pre>\n\n<p>If you want to customize the imported \"local\" names, you can supply a simple template string for the <code>localIdentName</code> option:</p>\n\n<pre><code class=\"language-js\">css?modules&amp;importLoaders=1&amp;localIdentName=[local]_[hash:base64:5]  \n</code></pre>\n\n<p>Think this seems worth it?</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2016-01-10T21:41:31.999Z","created_by":1,"updated_at":"2019-02-17T20:12:08.687Z","updated_by":1,"published_at":"2016-01-10T21:59:11.680Z","published_by":1},{"id":8,"uuid":"251b069b-ac2e-447b-9cf3-1e238fdfe86c","title":"A Challenge for Centralized State","slug":"a-challenge-for-centralized-state","markdown":"I build distributed frontends using components ([preact] components, but that's not important).  Components are a great unit of composition when the structure of a system cannot be statically determined.  We often simplify state management by centralizing it, but does that negatively impact our ability to compose things at runtime?\n\n### Prerequisite: SplitPoint\n\nIn this post, I'm going to brazenly pretend there exists a common definition for a `<SplitPoint>` component:\n\n> `SplitPoint` invokes an async `load()` function (passed as a prop), then renders result as its child.\n\nA horribly naive implementation of this component might look like this:\n\n```js\nclass SplitPoint extends Component {\n  constructor({ load }) {\n    load().then( Child => this.setState({ Child }) )\n  }\n  render() {\n    let { Child } = this.state\n    let { load, ...props } = this.props\n    return <Child {...props} />\n  }\n}\n```\n\nWe can use this component to lazy-load (webpack-)chunked components on first render.\n\nIn Webpack (2!) this might look like:\n\n```js\n<SplitPoint load={ () => import('./SomeComponent') } />\n```\n\nHowever, we can just as easily emulate this without actual code loading, using a function that returns a `Promise` resolving to a Component:\n\n```js\n// a \"chunk\": a Promise that resolves to a Component\nconst loadComponent = () => Promise.resolve(\n  class SomeComponent extends Component {\n    render() { return <div>whatever</div> }\n  }\n)\n\n<SplitPoint load={ () => loadComponent() } />\n                 // ^ unnecessary? yes.\n```\n\nThe main point here is that we can asynchronously pull in new components and render them into the Virtual DOM tree,\nsimply by wrapping them in a `<SplitPoint />` and chunking the Component definition.\n\n\n### Using Lazy-Loaded Components\n\nHere's an example of what it looks like to use lazily-loaded Components in a more real-world setting:\n\n```js\nconst Sidebar = () => (\n  <aside>\n    <SplitPoint load={ () => import('./Ad') } />\n    <SplitPoint load={ () => import('./Map') } />\n    <SplitPoint load={ () => import('./Nearby') } />\n    <SplitPoint load={ () => import('./AnotherAd') } />\n  </aside>\n)\n```\n\n... rendering `<Sidebar />` actually triggers network calls to go get the necessary components, and when they resolve they are rendered in-place.\n\n**The same technique is used to chunk routes, pages, etc.**\n\n\n### But Centralized State!\n\nNow let's say we're using something like Redux for a centralized store.\n\nOur components are going to pull initial state from that central store, and `subscribe()` to to changes to update in response.\n\nThe components in our Sidebar were `Ad`, `Map`, `Nearby` and `AnotherAd` (revenue is important). Let's ignore the Ads (everyone does) and focus on `Map` and `Nearby`. Both of these Components want to use the same `location` value from the centralized store.\n\nThat `location` value isn't free, though - its existence in that store includes a bunch of code to:\n\n- fetch the user's location from an IP address\n- geolocate them using browser APIs\n- save location preferences to localStorage; or if signed in,\n- save an authenticated user's location preferences to a service somewhere\n\n_... that might be a nontrivial amount of code._\n\nIf we're building a sufficiently large application, there will come a time when the functionality associated with values\nin the store would be worth splitting out into chunks, to be loaded on-demand.\n\nOr, perhaps we don't know ahead of time _(at build time)_\nif there will even be Components in this application that rely on that `location` value at all?  Maybe their existence in the UI is determined at runtime by something like a CMS, authentication status, or flags?\n\nThe solution here would be to code-split the logic around that `location` value so that it's only downloaded and executed when the application actually needs to use it.  However, how do we know that the application needs to access `location`?\n\n```js\n// getters on `state`?\n@connect( state => ({\n  location: state.location\n}) )\nexport default class Map extends Component {\n  render() {\n    this.props.location   // accessed synchronously\n    return <div>a map</div>\n  }\n}\n```\n\nYou might be inclined to say this:\n\n> \"hey, that's easy! just have Map load the reducer and inject it into the store.\"\n\n... and I might be inclined to agree - except it's quite possible our other `location`-using component, `<Nearby>`, might be rendered first. Or maybe `<Map>` won't be rendered at all.  Do we have both components load and inject that code-splitted business logic into the store when they are first mounted?\n\nI hope you weren't reading this expecting a solution or even a library that solves this problem magically, since I have neither. Maybe you do?\n\n\n[preact]: https://github.com/developit/preact","html":"<p>I build distributed frontends using components (<a href=\"https://github.com/developit/preact\">preact</a> components, but that's not important).  Components are a great unit of composition when the structure of a system cannot be statically determined.  We often simplify state management by centralizing it, but does that negatively impact our ability to compose things at runtime?</p>\n\n<h3 id=\"prerequisitesplitpoint\">Prerequisite: SplitPoint</h3>\n\n<p>In this post, I'm going to brazenly pretend there exists a common definition for a <code>&lt;SplitPoint&gt;</code> component:</p>\n\n<blockquote>\n  <p><code>SplitPoint</code> invokes an async <code>load()</code> function (passed as a prop), then renders result as its child.</p>\n</blockquote>\n\n<p>A horribly naive implementation of this component might look like this:</p>\n\n<pre><code class=\"language-js\">class SplitPoint extends Component {  \n  constructor({ load }) {\n    load().then( Child =&gt; this.setState({ Child }) )\n  }\n  render() {\n    let { Child } = this.state\n    let { load, ...props } = this.props\n    return &lt;Child {...props} /&gt;\n  }\n}\n</code></pre>\n\n<p>We can use this component to lazy-load (webpack-)chunked components on first render.</p>\n\n<p>In Webpack (2!) this might look like:</p>\n\n<pre><code class=\"language-js\">&lt;SplitPoint load={ () =&gt; import('./SomeComponent') } /&gt;  \n</code></pre>\n\n<p>However, we can just as easily emulate this without actual code loading, using a function that returns a <code>Promise</code> resolving to a Component:</p>\n\n<pre><code class=\"language-js\">// a \"chunk\": a Promise that resolves to a Component\nconst loadComponent = () =&gt; Promise.resolve(  \n  class SomeComponent extends Component {\n    render() { return &lt;div&gt;whatever&lt;/div&gt; }\n  }\n)\n\n&lt;SplitPoint load={ () =&gt; loadComponent() } /&gt;  \n                 // ^ unnecessary? yes.\n</code></pre>\n\n<p>The main point here is that we can asynchronously pull in new components and render them into the Virtual DOM tree, <br />\nsimply by wrapping them in a <code>&lt;SplitPoint /&gt;</code> and chunking the Component definition.</p>\n\n<h3 id=\"usinglazyloadedcomponents\">Using Lazy-Loaded Components</h3>\n\n<p>Here's an example of what it looks like to use lazily-loaded Components in a more real-world setting:</p>\n\n<pre><code class=\"language-js\">const Sidebar = () =&gt; (  \n  &lt;aside&gt;\n    &lt;SplitPoint load={ () =&gt; import('./Ad') } /&gt;\n    &lt;SplitPoint load={ () =&gt; import('./Map') } /&gt;\n    &lt;SplitPoint load={ () =&gt; import('./Nearby') } /&gt;\n    &lt;SplitPoint load={ () =&gt; import('./AnotherAd') } /&gt;\n  &lt;/aside&gt;\n)\n</code></pre>\n\n<p>... rendering <code>&lt;Sidebar /&gt;</code> actually triggers network calls to go get the necessary components, and when they resolve they are rendered in-place.</p>\n\n<p><strong>The same technique is used to chunk routes, pages, etc.</strong></p>\n\n<h3 id=\"butcentralizedstate\">But Centralized State!</h3>\n\n<p>Now let's say we're using something like Redux for a centralized store.</p>\n\n<p>Our components are going to pull initial state from that central store, and <code>subscribe()</code> to to changes to update in response.</p>\n\n<p>The components in our Sidebar were <code>Ad</code>, <code>Map</code>, <code>Nearby</code> and <code>AnotherAd</code> (revenue is important). Let's ignore the Ads (everyone does) and focus on <code>Map</code> and <code>Nearby</code>. Both of these Components want to use the same <code>location</code> value from the centralized store.</p>\n\n<p>That <code>location</code> value isn't free, though - its existence in that store includes a bunch of code to:</p>\n\n<ul>\n<li>fetch the user's location from an IP address</li>\n<li>geolocate them using browser APIs</li>\n<li>save location preferences to localStorage; or if signed in,</li>\n<li>save an authenticated user's location preferences to a service somewhere</li>\n</ul>\n\n<p><em>... that might be a nontrivial amount of code.</em></p>\n\n<p>If we're building a sufficiently large application, there will come a time when the functionality associated with values <br />\nin the store would be worth splitting out into chunks, to be loaded on-demand.</p>\n\n<p>Or, perhaps we don't know ahead of time <em>(at build time)</em> <br />\nif there will even be Components in this application that rely on that <code>location</code> value at all?  Maybe their existence in the UI is determined at runtime by something like a CMS, authentication status, or flags?</p>\n\n<p>The solution here would be to code-split the logic around that <code>location</code> value so that it's only downloaded and executed when the application actually needs to use it.  However, how do we know that the application needs to access <code>location</code>?</p>\n\n<pre><code class=\"language-js\">// getters on `state`?\n@connect( state =&gt; ({\n  location: state.location\n}) )\nexport default class Map extends Component {  \n  render() {\n    this.props.location   // accessed synchronously\n    return &lt;div&gt;a map&lt;/div&gt;\n  }\n}\n</code></pre>\n\n<p>You might be inclined to say this:</p>\n\n<blockquote>\n  <p>\"hey, that's easy! just have Map load the reducer and inject it into the store.\"</p>\n</blockquote>\n\n<p>... and I might be inclined to agree - except it's quite possible our other <code>location</code>-using component, <code>&lt;Nearby&gt;</code>, might be rendered first. Or maybe <code>&lt;Map&gt;</code> won't be rendered at all.  Do we have both components load and inject that code-splitted business logic into the store when they are first mounted?</p>\n\n<p>I hope you weren't reading this expecting a solution or even a library that solves this problem magically, since I have neither. Maybe you do?</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-01-20T17:45:43.578Z","created_by":1,"updated_at":"2019-02-17T20:14:00.328Z","updated_by":1,"published_at":"2017-01-20T17:58:37.392Z","published_by":1},{"id":2,"uuid":"d3c61806-5295-4b2d-8ace-a0a8154544fb","title":"WTF is JSX","slug":"wtf-is-jsx","markdown":"JSX is actually quite straightforward: take 1 minute and read this, and you'll understand everything there is to know about this interesting alternative to templates.\n\n_Alternative title: \"Living with JSX\"_\n\n\nThe Pragma\n----------\n\nYou declare this per-file or per-function to tell your transpiler (eg: Babel) the name of a function that should be called _at runtime_ for each node (see [Transpilation](#Transpilation)).\n\nIn the example below, we are saying \"inject calls to an `h()` function for each node\":\n\n```js\n/** @jsx h */\n```\n\n---\n\nTranspilation\n-------------\n\nIf you're not using a transpiler yet, you should be. Writing, debugging, testing and running JavaScript is all more effective when using ES6/ES2015. [Babel](http://babeljs.io) is the most popular and highly recommended transpiler out there, so I'll assume that's what you are using.\n\nAlong with converting your ES6/ES7+ syntax to JavaScript-of-today, Babel includes support for transpiling JSX ==right out of the box==. You don't need to add or change anything to use this feature.\n\nIt's easiest to see how this works by looking at a very simple example:\n\n**Before:** _(the code you write)_\n\n```js\n/** @jsx h */\nlet foo = <div id=\"foo\">Hello!</div>;\n```\n\n**After:** _(the code you run)_\n\n```js\nvar foo = h('div', {id:\"foo\"}, 'Hello!');\n```\n\nYou might be looking at that second code snippet thinking it wouldn't be so bad just building UI using functions...\n\nThis is why I started to get on board with JSX: if it disappeared off the face of the earth, writing the output by hand would still be pretty comfortable.\n\n\n> **JSX is just a sugar for a syntax that's _already_ pretty decent.**\n\nPeople even use it for whole projects: [hyperscript]\n\n\n----\n\n\nLet's Build a JSX Renderer\n--------------------------\n\nFirst, we'll need to define that `h()` function our transpiled code is calling.\n\nYou can call this whatever you want, I use `h()` because the original idea for this type of \"builder\" function was called [hyperscript] (\"hyper~~text~~\" + \"~~java~~script\").\n\n```js\nfunction h(nodeName, attributes, ...args) {\n  \tlet children = args.length ? [].concat(...args) : null;\n  \treturn { nodeName, attributes, children };\n}\n```\n\nOk, that was easy.\n\n> *Unfamiliar with ES6/ES2015?*\n>\n> * That `...` in the arguments list is a *rest param*. It collects \"the rest\" of the arguments into an Array.\n> * The `concat(...args)` bit is a *spread operator*: it takes that Array and expands it into arguments to `concat()`. The use of `concat()` here is to collapse any nested Arrays of child nodes.\n\n\nNow we have these nested JSON objects our `h()` function spits out, so we end up with a \"tree\" like this:\n\n```js\n{\n  nodeName: \"div\",\n  attributes: {\n    \"id\": \"foo\"\n  },\n  children: [\"Hello!\"]\n}\n```\n\n\nSo we just need a function that accepts that format and spits out actual DOM nodes:\n\n```js\nfunction render(vnode) {\n    // Strings just convert to #text Nodes:\n    if (vnode.split) return document.createTextNode(vnode);\n\n    // create a DOM element with the nodeName of our VDOM element:\n    let n = document.createElement(vnode.nodeName);\n\n    // copy attributes onto the new node:\n    let a = vnode.attributes || {};\n    Object.keys(a).forEach( k => n.setAttribute(k, a[k]) );\n\n    // render (build) and then append child nodes:\n    (vnode.children || []).forEach( c => n.appendChild(render(c)) );\n\n    return n;\n}\n```\n\nSweet. It's not hard to understand how that works.\nIf it helps, you can think of \"Virtual DOM\" as a very simple configuration for how to build a given DOM structure.\n\n> The benefit of virtual DOM is that it is extremely lightweight. Small objects referring to other small objects, a structure composed by easily optimizable application logic.\n>\n> This also means it is not tied to any rendering logic or slow DOM methods.\n\n\n---\n\n\nUsing JSX\n---------\n\nWe know that JSX is transformed into `h()` function calls.  \nThose function calls create a simple \"Virtual\" DOM tree.  \nWe can use the `render()` function to make a matching \"real\" DOM tree.  \nHere's what that looks like:\n\n```js\n// JSX -> VDOM:\nlet vdom = <div id=\"foo\">Hello!</div>;\n\n// VDOM -> DOM:\nlet dom = render(vdom);\n\n// add the tree to <body>:\ndocument.body.appendChild(dom);\n```\n\n##### Partials, Iteration & Logic: No new Syntax\n\n> Instead of the limited concepts introduced by template languages, we have all of JavaScript.\n\n\"Partials\" are a concept introduced by logicless/limited-logic template engines to re-use chunks of a view across differing contexts.\n\nIteration is something each new template language seems to re-invent (I'm as guilty as anyone). With JSX, there is no one-off syntax to learn: iterate how you would anywhere else in your JavaScript program. You pick the iteration style that best suits a given task: `[].forEach()`, `[].map()`, `for` and `while` loops, etc.\n\nLogic, like iteration, is something template languages love to re-invent. On one hand, logicless templates provide a very poor means of embedding logic into a view: limited constructs like `{{#if value}}` push logic into a controller layer, encouraging bloat. This circumvents building a language for describing more complex logic, avoiding predictability & security pitfalls.\n\nOn the opposite end of the spectrum, engines that use code-generation - _a technique that ranges from gross to unforgivable_ - often boast the ability to execute arbitrary JavaScript expressions for logic or even iteration. Here is a good enough reason to avoid this at all costs: your code is being ripped out of its original location _(perhaps a module, a closure or within markup)_ and evaluated \"somewhere else\". That's not predictable or secure enough for me.\n\n> JSX allows _all_ of of JavaScript's language features, without relying on generating grotesque code in a build step and without `eval()` & friends.\n\n```js\n// Array of strings we want to show in a list:\nlet items = ['foo', 'bar', 'baz'];\n\n// creates one list item given some text:\nfunction item(text) {\n    return <li>{text}</li>;\n}\n\n// a \"view\" with \"iteration\" and \"a partial\":\nlet list = render(\n  <ul>\n    { items.map(item) }\n  </ul>\n);\n```\n\n`render()` returns a DOM node (the `<ul>` in the above case), so we just need to place that into the DOM:\n\n```js\ndocument.body.appendChild(list);\n```\n\n\n---\n\nPutting it Together\n-------------------\n\nHere's the full source for the little virtual DOM renderer and a view that uses it.\nA CodePen with some styling is available below.\n\n```js\nconst ITEMS = 'hello there people'.split(' ');\n\n// turn an Array into list items: \nlet list = items => items.map( p => <li> {p} </li> );\n \n// view with a call out (\"partial\") to generate a list from an Array:\nlet vdom = (\n    <div id=\"foo\">\n        <p>Look, a simple JSX DOM renderer!</p>\n        <ul>{ list(ITEMS) }</ul>\n    </div>\n);\n \n// render() converts our \"virtual DOM\" (see below) to a real DOM tree:\nlet dom = render(vdom);\n \n// append the new nodes somewhere:\ndocument.body.appendChild(dom);\n \n// Remember that \"virtual DOM\"? It's just JSON - each \"VNode\" is an object with 3 properties.\nlet json = JSON.stringify(vdom, null, '  ');\n\n// The whole process (JSX -> VDOM -> DOM) in one step:\ndocument.body.appendChild(\n    render( <pre id=\"vdom\">{ json }</pre> )\n);\n```\n\n\n[Codepen Demo](http://codepen.io/developit/pen/aOYywe)\n--------------\n\n<iframe height=\"600\" scrolling=\"no\" src=\"//codepen.io/developit/embed/aOYywe/?height=600&theme-id=16424&default-tab=result\" frameborder=\"no\" style=\"width:100%;\"></iframe>\n\n\n[hyperscript]: https://github.com/dominictarr/hyperscript","html":"<p>JSX is actually quite straightforward: take 1 minute and read this, and you'll understand everything there is to know about this interesting alternative to templates.</p>\n\n<p><em>Alternative title: \"Living with JSX\"</em></p>\n\n<h2 id=\"thepragma\">The Pragma  </h2>\n\n<p>You declare this per-file or per-function to tell your transpiler (eg: Babel) the name of a function that should be called <em>at runtime</em> for each node (see <a href=\"#Transpilation\">Transpilation</a>).</p>\n\n<p>In the example below, we are saying \"inject calls to an <code>h()</code> function for each node\":</p>\n\n<pre><code class=\"language-js\">/** @jsx h */\n</code></pre>\n\n<hr />\n\n<h2 id=\"transpilation\">Transpilation  </h2>\n\n<p>If you're not using a transpiler yet, you should be. Writing, debugging, testing and running JavaScript is all more effective when using ES6/ES2015. <a href=\"http://babeljs.io\">Babel</a> is the most popular and highly recommended transpiler out there, so I'll assume that's what you are using.</p>\n\n<p>Along with converting your ES6/ES7+ syntax to JavaScript-of-today, Babel includes support for transpiling JSX <mark>right out of the box</mark>. You don't need to add or change anything to use this feature.</p>\n\n<p>It's easiest to see how this works by looking at a very simple example:</p>\n\n<p><strong>Before:</strong> <em>(the code you write)</em></p>\n\n<pre><code class=\"language-js\">/** @jsx h */\nlet foo = &lt;div id=\"foo\"&gt;Hello!&lt;/div&gt;;  \n</code></pre>\n\n<p><strong>After:</strong> <em>(the code you run)</em></p>\n\n<pre><code class=\"language-js\">var foo = h('div', {id:\"foo\"}, 'Hello!');  \n</code></pre>\n\n<p>You might be looking at that second code snippet thinking it wouldn't be so bad just building UI using functions...</p>\n\n<p>This is why I started to get on board with JSX: if it disappeared off the face of the earth, writing the output by hand would still be pretty comfortable.</p>\n\n<blockquote>\n  <p><strong>JSX is just a sugar for a syntax that's <em>already</em> pretty decent.</strong></p>\n</blockquote>\n\n<p>People even use it for whole projects: <a href=\"https://github.com/dominictarr/hyperscript\">hyperscript</a></p>\n\n<hr />\n\n<h2 id=\"letsbuildajsxrenderer\">Let's Build a JSX Renderer  </h2>\n\n<p>First, we'll need to define that <code>h()</code> function our transpiled code is calling.</p>\n\n<p>You can call this whatever you want, I use <code>h()</code> because the original idea for this type of \"builder\" function was called <a href=\"https://github.com/dominictarr/hyperscript\">hyperscript</a> (\"hyper<del>text</del>\" + \"<del>java</del>script\").</p>\n\n<pre><code class=\"language-js\">function h(nodeName, attributes, ...args) {  \n      let children = args.length ? [].concat(...args) : null;\n      return { nodeName, attributes, children };\n}\n</code></pre>\n\n<p>Ok, that was easy.</p>\n\n<blockquote>\n  <p><em>Unfamiliar with ES6/ES2015?</em></p>\n  \n  <ul>\n  <li>That <code>...</code> in the arguments list is a <em>rest param</em>. It collects \"the rest\" of the arguments into an Array.</li>\n  <li>The <code>concat(...args)</code> bit is a <em>spread operator</em>: it takes that Array and expands it into arguments to <code>concat()</code>. The use of <code>concat()</code> here is to collapse any nested Arrays of child nodes.</li>\n  </ul>\n</blockquote>\n\n<p>Now we have these nested JSON objects our <code>h()</code> function spits out, so we end up with a \"tree\" like this:</p>\n\n<pre><code class=\"language-js\">{\n  nodeName: \"div\",\n  attributes: {\n    \"id\": \"foo\"\n  },\n  children: [\"Hello!\"]\n}\n</code></pre>\n\n<p>So we just need a function that accepts that format and spits out actual DOM nodes:</p>\n\n<pre><code class=\"language-js\">function render(vnode) {  \n    // Strings just convert to #text Nodes:\n    if (vnode.split) return document.createTextNode(vnode);\n\n    // create a DOM element with the nodeName of our VDOM element:\n    let n = document.createElement(vnode.nodeName);\n\n    // copy attributes onto the new node:\n    let a = vnode.attributes || {};\n    Object.keys(a).forEach( k =&gt; n.setAttribute(k, a[k]) );\n\n    // render (build) and then append child nodes:\n    (vnode.children || []).forEach( c =&gt; n.appendChild(render(c)) );\n\n    return n;\n}\n</code></pre>\n\n<p>Sweet. It's not hard to understand how that works. <br />\nIf it helps, you can think of \"Virtual DOM\" as a very simple configuration for how to build a given DOM structure.</p>\n\n<blockquote>\n  <p>The benefit of virtual DOM is that it is extremely lightweight. Small objects referring to other small objects, a structure composed by easily optimizable application logic.</p>\n  \n  <p>This also means it is not tied to any rendering logic or slow DOM methods.</p>\n</blockquote>\n\n<hr />\n\n<h2 id=\"usingjsx\">Using JSX  </h2>\n\n<p>We know that JSX is transformed into <code>h()</code> function calls. <br />\nThose function calls create a simple \"Virtual\" DOM tree. <br />\nWe can use the <code>render()</code> function to make a matching \"real\" DOM tree. <br />\nHere's what that looks like:</p>\n\n<pre><code class=\"language-js\">// JSX -&gt; VDOM:\nlet vdom = &lt;div id=\"foo\"&gt;Hello!&lt;/div&gt;;\n\n// VDOM -&gt; DOM:\nlet dom = render(vdom);\n\n// add the tree to &lt;body&gt;:\ndocument.body.appendChild(dom);  \n</code></pre>\n\n<h5 id=\"partialsiterationlogicnonewsyntax\">Partials, Iteration &amp; Logic: No new Syntax</h5>\n\n<blockquote>\n  <p>Instead of the limited concepts introduced by template languages, we have all of JavaScript.</p>\n</blockquote>\n\n<p>\"Partials\" are a concept introduced by logicless/limited-logic template engines to re-use chunks of a view across differing contexts.</p>\n\n<p>Iteration is something each new template language seems to re-invent (I'm as guilty as anyone). With JSX, there is no one-off syntax to learn: iterate how you would anywhere else in your JavaScript program. You pick the iteration style that best suits a given task: <code>[].forEach()</code>, <code>[].map()</code>, <code>for</code> and <code>while</code> loops, etc.</p>\n\n<p>Logic, like iteration, is something template languages love to re-invent. On one hand, logicless templates provide a very poor means of embedding logic into a view: limited constructs like <code>{{#if value}}</code> push logic into a controller layer, encouraging bloat. This circumvents building a language for describing more complex logic, avoiding predictability &amp; security pitfalls.</p>\n\n<p>On the opposite end of the spectrum, engines that use code-generation - <em>a technique that ranges from gross to unforgivable</em> - often boast the ability to execute arbitrary JavaScript expressions for logic or even iteration. Here is a good enough reason to avoid this at all costs: your code is being ripped out of its original location <em>(perhaps a module, a closure or within markup)</em> and evaluated \"somewhere else\". That's not predictable or secure enough for me.</p>\n\n<blockquote>\n  <p>JSX allows <em>all</em> of of JavaScript's language features, without relying on generating grotesque code in a build step and without <code>eval()</code> &amp; friends.</p>\n</blockquote>\n\n<pre><code class=\"language-js\">// Array of strings we want to show in a list:\nlet items = ['foo', 'bar', 'baz'];\n\n// creates one list item given some text:\nfunction item(text) {  \n    return &lt;li&gt;{text}&lt;/li&gt;;\n}\n\n// a \"view\" with \"iteration\" and \"a partial\":\nlet list = render(  \n  &lt;ul&gt;\n    { items.map(item) }\n  &lt;/ul&gt;\n);\n</code></pre>\n\n<p><code>render()</code> returns a DOM node (the <code>&lt;ul&gt;</code> in the above case), so we just need to place that into the DOM:</p>\n\n<pre><code class=\"language-js\">document.body.appendChild(list);  \n</code></pre>\n\n<hr />\n\n<h2 id=\"puttingittogether\">Putting it Together  </h2>\n\n<p>Here's the full source for the little virtual DOM renderer and a view that uses it. <br />\nA CodePen with some styling is available below.</p>\n\n<pre><code class=\"language-js\">const ITEMS = 'hello there people'.split(' ');\n\n// turn an Array into list items: \nlet list = items =&gt; items.map( p =&gt; &lt;li&gt; {p} &lt;/li&gt; );\n\n// view with a call out (\"partial\") to generate a list from an Array:\nlet vdom = (  \n    &lt;div id=\"foo\"&gt;\n        &lt;p&gt;Look, a simple JSX DOM renderer!&lt;/p&gt;\n        &lt;ul&gt;{ list(ITEMS) }&lt;/ul&gt;\n    &lt;/div&gt;\n);\n\n// render() converts our \"virtual DOM\" (see below) to a real DOM tree:\nlet dom = render(vdom);\n\n// append the new nodes somewhere:\ndocument.body.appendChild(dom);\n\n// Remember that \"virtual DOM\"? It's just JSON - each \"VNode\" is an object with 3 properties.\nlet json = JSON.stringify(vdom, null, '  ');\n\n// The whole process (JSX -&gt; VDOM -&gt; DOM) in one step:\ndocument.body.appendChild(  \n    render( &lt;pre id=\"vdom\"&gt;{ json }&lt;/pre&gt; )\n);\n</code></pre>\n\n<h2 id=\"codependemohttpcodepeniodevelopitpenaoyywe\"><a href=\"http://codepen.io/developit/pen/aOYywe\">Codepen Demo</a></h2>\n\n<iframe height=\"600\" scrolling=\"no\" src=\"//codepen.io/developit/embed/aOYywe/?height=600&theme-id=16424&default-tab=result\" frameborder=\"no\" style=\"width:100%;\"></iframe>","image":null,"featured":true,"page":false,"status":"published","language":"en_US","meta_title":"WTF is JSX","meta_description":null,"author_id":1,"created_at":"2015-07-07T16:01:14.392Z","created_by":1,"updated_at":"2019-02-17T20:14:33.009Z","updated_by":1,"published_at":"2015-07-07T17:19:00.000Z","published_by":1},{"id":17,"uuid":"206896fc-f71b-46ae-8ca3-b1e4b2affbd9","title":"Modern Script Loading","slug":"modern-script-loading","markdown":"> Serving the right code to the right browsers can be tricky. Here are some options.\n\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1562702391/modern-script-loading_ku0eml.jpg\" width=\"100%\">\n\nServing modern code to modern browsers can be great for performance. Your JavaScript bundles can contain more compact or optimized modern syntax, while still supporting older browsers.\n\nThe tooling ecosystem has consolidated on using the [module/nomodule pattern](https://philipwalton.com/articles/deploying-es2015-code-in-production-today/) for declaratively loading modern VS legacy code, which provides browsers with both sources and lets them decide which to use:\n\n```html\n<script type=\"module\" src=\"/modern.js\"></script>\n<script nomodule src=\"/legacy.js\"></script>\n```\n\nUnfortunately, it's not quite that straightforward. The HTML-based approach shown above triggers [over-fetching of scripts in Edge and Safari](https://gist.github.com/jakub-g/5fc11af85a061ca29cc84892f1059fec).\n\n### What can we do?\n\nWhat can we do? We want to deliver two compile targets depending on the browser, but a couple older browsers don't quite support the nice clean syntax for doing so.\n\nFirst, there's the [Safari Fix](https://gist.github.com/samthor/64b114e4a4f539915a95b91ffd340acc). Safari 10.1 supports JS Modules not the `nomodule` attribute on scripts, which causes it to execute both the modern and legacy code _(yikes!)_. Thankfully, Sam found a way to use a non-standard `beforeload` event supported in Safari 10 & 11 to polyfill `nomodule`.\n\n\n#### Option 1: Load Dynamically\n\nWe can circumvent these issues by implementing a tiny script loader, similar to how [LoadCSS](https://github.com/filamentgroup/loadCSS) works. Instead of relying on browsers to implement both ES Modules and the `nomodule` attribute, we can attempt to execute a Module script as a \"litmus test\", then use the result of that test to choose whether to load modern or legacy code.\n\n```html\n<!-- use a module script to detect modern browsers: -->\n<script type=module>\n  self.modern = true\n</script>\n\n<!-- now use that flag to load modern VS legacy code: -->\n<script>\n  addEventListener('load', function() {\n    var s = document.createElement('script')\n    if (self.modern) {\n      s.src = '/modern.js'\n      s.type = 'module'\n    }\n    else {\n      s.src = '/legacy.js'\n    }\n    document.head.appendChild(s)\n  })\n</script>\n```\n\nHowever, this solution requires waiting until our first \"litmus test\" module script has run before it can inject the correct script. This is because `<script type=module>` is always asynchronous. There is a better way!\n\nA standalone variant of this can be implemented by checking if the browser supports `nomodule`. This would mean browsers like Safari 10.1 are treated as legacy even though they support Modules, but that [might be](https://github.com/web-padawan/polymer3-webpack-starter/issues/33#issuecomment-474993984) a [good thing](https://github.com/babel/babel/pull/9584). Here's the code for that:\n\n```js\nvar s = document.createElement('script')\nif ('noModule' in s) {  // notice the casing\n  s.type = 'module'\n  s.src = '/modern.js'\n}\nelse\n  s.src = '/legacy.js'\n}\ndocument.head.appendChild(s)\n```\n\nThis can be quickly rolled into a function that loads modern or legacy code, and also ensures both are loaded asynchronously:\n\n```html\n<script>\n  $loadjs(\"/modern.js\",\"/legacy.js\")\n  function $loadjs(src,fallback,s) {\n    s = document.createElement('script')\n    if ('noModule' in s) s.type = 'module', s.src = src\n    else s.async = true, s.src = fallback\n    document.head.appendChild(s)\n  }\n</script>\n```\n\n_What's the trade-off?_ **preloading**.\n\nThe trouble with this solution is that, because it's completely dynamic, the browser won't be able to discover our JavaScript resources until it runs the bootstrapping code we wrote to inject modern vs legacy scripts. Normally, browsers scan HTML as it is being streamed to look for resources they can preload. There's a solution, though it's not perfect: we can use `<link rel=modulepreload>` to preload the modern version of a bundle in modern browsers. Unfortunately, [only Chrome supports `modulepreload`](https://developers.google.com/web/updates/2017/12/modulepreload) so far.\n\n```html\n<link rel=\"modulepreload\" href=\"/modern.js\">\n<script type=module>self.modern=1</script>\n<!-- etc -->\n```\n\nWhether this technique works for you can come down to the size of the HTML document you're embedding those scripts into. If your HTML payload is as small as a splash screen or just enough to bootstrap a client-side application, giving up the preload scanner is less likely to impact performance. If you are server-rendering a lot of meaningful HTML for the browser to stream, the preload scanner is your friend and this might not be the best approach for you.\n\nHere's what this solution might look like in prod:\n\n```html\n<link rel=\"modulepreload\" href=\"/modern.js\">\n<script type=module>self.modern=1</script>\n<script>\n  $loadjs(\"/modern.js\",\"/legacy.js\")\n  function $loadjs(e,d,c){c=document.createElement(\"script\"),self.modern?(c.src=e,c.type=\"module\"):c.src=d,document.head.appendChild(c)}\n</script>\n```\n\nIt's also be pointed out that the set of [browsers supporting JS Modules](https://caniuse.com/#feat=es6-module) is quite similar to [those that support](https://caniuse.com/#feat=link-rel-preload) `<link rel=preload>`. For some websites, it might make sense to use `<link rel=preload as=script crossorigin>` rather than relying on modulepreload. This may have performance drawbacks, since classic script preloading doesn't spread parsing work out over time as well as modulepreload.\n\n\n#### Option 2: User Agent Sniffing\n\nI don't have a concise code sample for this since User Agent detection is nontrivial, but there's a great [Smashing Magazine article](https://www.smashingmagazine.com/2018/10/smart-bundling-legacy-code-browsers/) about it.\n\nEssentially, this technique starts with the same `<script src=bundle.js>` in the HTML for all browsers. When `bundle.js` is requested, the server parses the requesting browser's User Agent string and chooses whether to return modern or legacy JavaScript, depending on whether that browser is recognized as modern or not.\n\nWhile this approach is versatile, it comes with some severe implications:\n\n- since server smarts are required, this doesn't work for static deployment (static site generators, Netlify, etc)\n- caching for those JavaScript URLs now varies based on User Agent, which is highly volatile\n- UA detection is difficult and can be prone to false classification\n- the User Agent string is easily spoofable and new UA's arrive daily\n\nOne way to address these limitations is to combine the module/nomodule pattern with User Agent differentiation in order to avoid sending multiple bundle versions in the first place. This approach still reduces cacheability of the page, but allows for effective preloading, since the server generating our HTML knows whether to use `modulepreload` or `preload`.\n\n\n```js\nfunction renderPage(request, response) {\n  let html = `<html><head>...`;\n\n  const agent = request.headers.userAgent;\n  const isModern = userAgent.isModern(agent);\n  if (isModern) {\n    html += `\n      <link rel=modulepreload href=modern.mjs>\n      <script type=module src=modern.mjs></script>\n    `;\n  } else {\n    html += `\n      <link rel=preload as=script href=legacy.js>\n      <script src=legacy.js></script>\n    `;\n  }\n\n  response.end(html);\n}\n```\n\nFor websites already generating HTML on the server in response to each request, this can be an effective solution for modern script loading.\n\n#### Option 3: Penalize older browsers\n\nThe ill-effects of the module/nomodule pattern are seen in old versions of Chrome, Firefox and Safari - browser versions with very limited usage, since users are automatically updated to the latest version. This doesn't hold true for Edge 16-18, but there is hope: new versions of Edge will use a Chromium-based renderer that doesn't suffer from this issue.\n\nIt might be perfectly reasonable for some applications to accept this as a trade-off: you get to deliver modern code to 90% of browsers, at the expense of some extra bandwidth on older browsers. Notably, none of the User Agents suffering from this over-fetching issue have significant mobile market share - so those bytes are less likely to be coming from an expensive mobile plan or through a device with a slow processor.\n\nIf you're building a site where your users are primarily on mobile or recent browsers, the simplest form of the module/nomodule pattern will work for the vast majority of your users. Just be sure to include the [Safari 10.1 fix](https://gist.github.com/samthor/64b114e4a4f539915a95b91ffd340acc) if you have usage from slightly older iOS devices.\n\n```html\n<!-- polyfill `nomodule` in Safari 10.1: -->\n<script type=module>\n!function(e,t,n){!(\"noModule\"in(t=e.createElement(\"script\")))&&\"onbeforeload\"in t&&(n=!1,e.addEventListener(\"beforeload\",function(e){if(e.target===t)n=!0;else if(!e.target.hasAttribute(\"nomodule\")||!n)return;e.preventDefault()},!0),t.type=\"module\",t.src=\".\",e.head.appendChild(t),t.remove())}(document)\n</script>\n\n<!-- 90+% of browsers: -->\n<script src=modern.js type=module></script>\n\n<!-- IE, Edge <16, Safari <10.1, old desktop: -->\n<script src=legacy.js nomodule async defer></script>\n```\n\n#### Option 4: Use conditional bundles\n\nOne clever approach here is to use `nomodule` to conditionally load bundles containing code that isn't needed in modern browsers, such as polyfills. With this approach, the worst-case is that the polyfills are loaded or possibly even executed (in Safari 10.1), but the effect is limited to \"over-polyfilling\". Given that the current prevailing approach is to load and execute polyfills in all browsers, this can be a net improvement.\n\n```html\n<!-- newer browsers won't load this bundle: -->\n<script nomodule src=\"polyfills.js\"></script>\n\n<!-- all browsers load this one: -->\n<script src=\"/bundle.js\"></script>\n```\n\nAngular CLI can be configured to use this approach for polyfills, as [demonstrated by Minko Gechev](https://blog.mgechev.com/2019/02/06/5-angular-cli-features/#conditional-polyfill-serving). After reading about this approach, I realized we could switch the automatic polyfill injection in preact-cli to use it - [this PR](https://github.com/preactjs/preact-cli/pull/833/files) shows how easy it can be to adopt the technique.\n\nFor those using Webpack, there's a [handy plugin](https://github.com/swimmadude66/webpack-nomodule-plugin) for `html-webpack-plugin` that makes it easy to add nomodule to polyfill bundles.\n\n---\n\n### What should you do?\n\nThe answer depends on your use-case. If you're building a client-side application and your app's HTML payload is little more than a `<script>`, you might find _Option 1_ to be compelling. If you're building a server-rendered website and can afford the caching impact, _Option 2_ could be for you. If you're using [universal rendering](https://developers.google.com/web/updates/2019/02/rendering-on-the-web#rehydration), the performance benefits offered by preload scanning might be very important, and you look to _Option 3_ or _Option 4_. Choose what fits your architecture.\n\nPersonally, I tend to make the decision to optimize for faster parse times on mobile rather than the download cost on some desktop browsers. Mobile users experience parsing and data costs as actual expenses - battery drain and data fees - whereas desktop users don't tend to have these constraints. Plus, it's optimizing for the 90% - for the stuff I work on, most users are on modern and/or mobile browsers.\n\n\n### Further Reading\n\nInterested in diving deeper into this space? Here's some places to start digging:\n\n- There's some great additional context on Phil's [webpack-esnext-boilerplate](https://github.com/philipwalton/webpack-esnext-boilerplate/issues/1).\n\n- Ralph [implemented module/nomodule in Next.js](https://github.com/zeit/next.js/pull/7704), and is working on solving these issues there.\n\n\nThanks to [Phil](https://twitter.com/philwalton), [Shubhie](https://twitter.com/shubhie), [Alex](https://twitter.com/atcastle), [Houssein](https://twitter.com/hdjirdeh), [Ralph](https://twitter.com/Janicklas) and [Addy](https://twitter.com/addyosmani) for the feedback.\n\n<div style=\"font-size:70%; color:#666; background:#eee; border:1px solid #ccc; padding: 10px; line-height:1.3;\">\n<strong>2019-07-16:</strong> fixed code sample in Option 1, which was broken due to the asynchronous <code>self.modern</code> initialization.\n<br>\n</div>","html":"<blockquote>\n  <p>Serving the right code to the right browsers can be tricky. Here are some options.</p>\n</blockquote>\n\n<p><img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1562702391/modern-script-loading_ku0eml.jpg\" width=\"100%\"></p>\n\n<p>Serving modern code to modern browsers can be great for performance. Your JavaScript bundles can contain more compact or optimized modern syntax, while still supporting older browsers.</p>\n\n<p>The tooling ecosystem has consolidated on using the <a href=\"https://philipwalton.com/articles/deploying-es2015-code-in-production-today/\">module/nomodule pattern</a> for declaratively loading modern VS legacy code, which provides browsers with both sources and lets them decide which to use:</p>\n\n<pre><code class=\"language-html\">&lt;script type=\"module\" src=\"/modern.js\"&gt;&lt;/script&gt;  \n&lt;script nomodule src=\"/legacy.js\"&gt;&lt;/script&gt;  \n</code></pre>\n\n<p>Unfortunately, it's not quite that straightforward. The HTML-based approach shown above triggers <a href=\"https://gist.github.com/jakub-g/5fc11af85a061ca29cc84892f1059fec\">over-fetching of scripts in Edge and Safari</a>.</p>\n\n<h3 id=\"whatcanwedo\">What can we do?</h3>\n\n<p>What can we do? We want to deliver two compile targets depending on the browser, but a couple older browsers don't quite support the nice clean syntax for doing so.</p>\n\n<p>First, there's the <a href=\"https://gist.github.com/samthor/64b114e4a4f539915a95b91ffd340acc\">Safari Fix</a>. Safari 10.1 supports JS Modules not the <code>nomodule</code> attribute on scripts, which causes it to execute both the modern and legacy code <em>(yikes!)</em>. Thankfully, Sam found a way to use a non-standard <code>beforeload</code> event supported in Safari 10 &amp; 11 to polyfill <code>nomodule</code>.</p>\n\n<h4 id=\"option1loaddynamically\">Option 1: Load Dynamically</h4>\n\n<p>We can circumvent these issues by implementing a tiny script loader, similar to how <a href=\"https://github.com/filamentgroup/loadCSS\">LoadCSS</a> works. Instead of relying on browsers to implement both ES Modules and the <code>nomodule</code> attribute, we can attempt to execute a Module script as a \"litmus test\", then use the result of that test to choose whether to load modern or legacy code.</p>\n\n<pre><code class=\"language-html\">&lt;!-- use a module script to detect modern browsers: --&gt;  \n&lt;script type=module&gt;  \n  self.modern = true\n&lt;/script&gt;\n\n&lt;!-- now use that flag to load modern VS legacy code: --&gt;  \n&lt;script&gt;  \n  addEventListener('load', function() {\n    var s = document.createElement('script')\n    if (self.modern) {\n      s.src = '/modern.js'\n      s.type = 'module'\n    }\n    else {\n      s.src = '/legacy.js'\n    }\n    document.head.appendChild(s)\n  })\n&lt;/script&gt;  \n</code></pre>\n\n<p>However, this solution requires waiting until our first \"litmus test\" module script has run before it can inject the correct script. This is because <code>&lt;script type=module&gt;</code> is always asynchronous. There is a better way!</p>\n\n<p>A standalone variant of this can be implemented by checking if the browser supports <code>nomodule</code>. This would mean browsers like Safari 10.1 are treated as legacy even though they support Modules, but that <a href=\"https://github.com/web-padawan/polymer3-webpack-starter/issues/33#issuecomment-474993984\">might be</a> a <a href=\"https://github.com/babel/babel/pull/9584\">good thing</a>. Here's the code for that:</p>\n\n<pre><code class=\"language-js\">var s = document.createElement('script')  \nif ('noModule' in s) {  // notice the casing  \n  s.type = 'module'\n  s.src = '/modern.js'\n}\nelse  \n  s.src = '/legacy.js'\n}\ndocument.head.appendChild(s)  \n</code></pre>\n\n<p>This can be quickly rolled into a function that loads modern or legacy code, and also ensures both are loaded asynchronously:</p>\n\n<pre><code class=\"language-html\">&lt;script&gt;  \n  $loadjs(\"/modern.js\",\"/legacy.js\")\n  function $loadjs(src,fallback,s) {\n    s = document.createElement('script')\n    if ('noModule' in s) s.type = 'module', s.src = src\n    else s.async = true, s.src = fallback\n    document.head.appendChild(s)\n  }\n&lt;/script&gt;  \n</code></pre>\n\n<p><em>What's the trade-off?</em> <strong>preloading</strong>.</p>\n\n<p>The trouble with this solution is that, because it's completely dynamic, the browser won't be able to discover our JavaScript resources until it runs the bootstrapping code we wrote to inject modern vs legacy scripts. Normally, browsers scan HTML as it is being streamed to look for resources they can preload. There's a solution, though it's not perfect: we can use <code>&lt;link rel=modulepreload&gt;</code> to preload the modern version of a bundle in modern browsers. Unfortunately, <a href=\"https://developers.google.com/web/updates/2017/12/modulepreload\">only Chrome supports <code>modulepreload</code></a> so far.</p>\n\n<pre><code class=\"language-html\">&lt;link rel=\"modulepreload\" href=\"/modern.js\"&gt;  \n&lt;script type=module&gt;self.modern=1&lt;/script&gt;  \n&lt;!-- etc --&gt;  \n</code></pre>\n\n<p>Whether this technique works for you can come down to the size of the HTML document you're embedding those scripts into. If your HTML payload is as small as a splash screen or just enough to bootstrap a client-side application, giving up the preload scanner is less likely to impact performance. If you are server-rendering a lot of meaningful HTML for the browser to stream, the preload scanner is your friend and this might not be the best approach for you.</p>\n\n<p>Here's what this solution might look like in prod:</p>\n\n<pre><code class=\"language-html\">&lt;link rel=\"modulepreload\" href=\"/modern.js\"&gt;  \n&lt;script type=module&gt;self.modern=1&lt;/script&gt;  \n&lt;script&gt;  \n  $loadjs(\"/modern.js\",\"/legacy.js\")\n  function $loadjs(e,d,c){c=document.createElement(\"script\"),self.modern?(c.src=e,c.type=\"module\"):c.src=d,document.head.appendChild(c)}\n&lt;/script&gt;  \n</code></pre>\n\n<p>It's also be pointed out that the set of <a href=\"https://caniuse.com/#feat=es6-module\">browsers supporting JS Modules</a> is quite similar to <a href=\"https://caniuse.com/#feat=link-rel-preload\">those that support</a> <code>&lt;link rel=preload&gt;</code>. For some websites, it might make sense to use <code>&lt;link rel=preload as=script crossorigin&gt;</code> rather than relying on modulepreload. This may have performance drawbacks, since classic script preloading doesn't spread parsing work out over time as well as modulepreload.</p>\n\n<h4 id=\"option2useragentsniffing\">Option 2: User Agent Sniffing</h4>\n\n<p>I don't have a concise code sample for this since User Agent detection is nontrivial, but there's a great <a href=\"https://www.smashingmagazine.com/2018/10/smart-bundling-legacy-code-browsers/\">Smashing Magazine article</a> about it.</p>\n\n<p>Essentially, this technique starts with the same <code>&lt;script src=bundle.js&gt;</code> in the HTML for all browsers. When <code>bundle.js</code> is requested, the server parses the requesting browser's User Agent string and chooses whether to return modern or legacy JavaScript, depending on whether that browser is recognized as modern or not.</p>\n\n<p>While this approach is versatile, it comes with some severe implications:</p>\n\n<ul>\n<li>since server smarts are required, this doesn't work for static deployment (static site generators, Netlify, etc)</li>\n<li>caching for those JavaScript URLs now varies based on User Agent, which is highly volatile</li>\n<li>UA detection is difficult and can be prone to false classification</li>\n<li>the User Agent string is easily spoofable and new UA's arrive daily</li>\n</ul>\n\n<p>One way to address these limitations is to combine the module/nomodule pattern with User Agent differentiation in order to avoid sending multiple bundle versions in the first place. This approach still reduces cacheability of the page, but allows for effective preloading, since the server generating our HTML knows whether to use <code>modulepreload</code> or <code>preload</code>.</p>\n\n<pre><code class=\"language-js\">function renderPage(request, response) {  \n  let html = `&lt;html&gt;&lt;head&gt;...`;\n\n  const agent = request.headers.userAgent;\n  const isModern = userAgent.isModern(agent);\n  if (isModern) {\n    html += `\n      &lt;link rel=modulepreload href=modern.mjs&gt;\n      &lt;script type=module src=modern.mjs&gt;&lt;/script&gt;\n    `;\n  } else {\n    html += `\n      &lt;link rel=preload as=script href=legacy.js&gt;\n      &lt;script src=legacy.js&gt;&lt;/script&gt;\n    `;\n  }\n\n  response.end(html);\n}\n</code></pre>\n\n<p>For websites already generating HTML on the server in response to each request, this can be an effective solution for modern script loading.</p>\n\n<h4 id=\"option3penalizeolderbrowsers\">Option 3: Penalize older browsers</h4>\n\n<p>The ill-effects of the module/nomodule pattern are seen in old versions of Chrome, Firefox and Safari - browser versions with very limited usage, since users are automatically updated to the latest version. This doesn't hold true for Edge 16-18, but there is hope: new versions of Edge will use a Chromium-based renderer that doesn't suffer from this issue.</p>\n\n<p>It might be perfectly reasonable for some applications to accept this as a trade-off: you get to deliver modern code to 90% of browsers, at the expense of some extra bandwidth on older browsers. Notably, none of the User Agents suffering from this over-fetching issue have significant mobile market share - so those bytes are less likely to be coming from an expensive mobile plan or through a device with a slow processor.</p>\n\n<p>If you're building a site where your users are primarily on mobile or recent browsers, the simplest form of the module/nomodule pattern will work for the vast majority of your users. Just be sure to include the <a href=\"https://gist.github.com/samthor/64b114e4a4f539915a95b91ffd340acc\">Safari 10.1 fix</a> if you have usage from slightly older iOS devices.</p>\n\n<pre><code class=\"language-html\">&lt;!-- polyfill `nomodule` in Safari 10.1: --&gt;  \n&lt;script type=module&gt;  \n!function(e,t,n){!(\"noModule\"in(t=e.createElement(\"script\")))&amp;&amp;\"onbeforeload\"in t&amp;&amp;(n=!1,e.addEventListener(\"beforeload\",function(e){if(e.target===t)n=!0;else if(!e.target.hasAttribute(\"nomodule\")||!n)return;e.preventDefault()},!0),t.type=\"module\",t.src=\".\",e.head.appendChild(t),t.remove())}(document)\n&lt;/script&gt;\n\n&lt;!-- 90+% of browsers: --&gt;  \n&lt;script src=modern.js type=module&gt;&lt;/script&gt;\n\n&lt;!-- IE, Edge &lt;16, Safari &lt;10.1, old desktop: --&gt;  \n&lt;script src=legacy.js nomodule async defer&gt;&lt;/script&gt;  \n</code></pre>\n\n<h4 id=\"option4useconditionalbundles\">Option 4: Use conditional bundles</h4>\n\n<p>One clever approach here is to use <code>nomodule</code> to conditionally load bundles containing code that isn't needed in modern browsers, such as polyfills. With this approach, the worst-case is that the polyfills are loaded or possibly even executed (in Safari 10.1), but the effect is limited to \"over-polyfilling\". Given that the current prevailing approach is to load and execute polyfills in all browsers, this can be a net improvement.</p>\n\n<pre><code class=\"language-html\">&lt;!-- newer browsers won't load this bundle: --&gt;  \n&lt;script nomodule src=\"polyfills.js\"&gt;&lt;/script&gt;\n\n&lt;!-- all browsers load this one: --&gt;  \n&lt;script src=\"/bundle.js\"&gt;&lt;/script&gt;  \n</code></pre>\n\n<p>Angular CLI can be configured to use this approach for polyfills, as <a href=\"https://blog.mgechev.com/2019/02/06/5-angular-cli-features/#conditional-polyfill-serving\">demonstrated by Minko Gechev</a>. After reading about this approach, I realized we could switch the automatic polyfill injection in preact-cli to use it - <a href=\"https://github.com/preactjs/preact-cli/pull/833/files\">this PR</a> shows how easy it can be to adopt the technique.</p>\n\n<p>For those using Webpack, there's a <a href=\"https://github.com/swimmadude66/webpack-nomodule-plugin\">handy plugin</a> for <code>html-webpack-plugin</code> that makes it easy to add nomodule to polyfill bundles.</p>\n\n<hr />\n\n<h3 id=\"whatshouldyoudo\">What should you do?</h3>\n\n<p>The answer depends on your use-case. If you're building a client-side application and your app's HTML payload is little more than a <code>&lt;script&gt;</code>, you might find <em>Option 1</em> to be compelling. If you're building a server-rendered website and can afford the caching impact, <em>Option 2</em> could be for you. If you're using <a href=\"https://developers.google.com/web/updates/2019/02/rendering-on-the-web#rehydration\">universal rendering</a>, the performance benefits offered by preload scanning might be very important, and you look to <em>Option 3</em> or <em>Option 4</em>. Choose what fits your architecture.</p>\n\n<p>Personally, I tend to make the decision to optimize for faster parse times on mobile rather than the download cost on some desktop browsers. Mobile users experience parsing and data costs as actual expenses - battery drain and data fees - whereas desktop users don't tend to have these constraints. Plus, it's optimizing for the 90% - for the stuff I work on, most users are on modern and/or mobile browsers.</p>\n\n<h3 id=\"furtherreading\">Further Reading</h3>\n\n<p>Interested in diving deeper into this space? Here's some places to start digging:</p>\n\n<ul>\n<li><p>There's some great additional context on Phil's <a href=\"https://github.com/philipwalton/webpack-esnext-boilerplate/issues/1\">webpack-esnext-boilerplate</a>.</p></li>\n<li><p>Ralph <a href=\"https://github.com/zeit/next.js/pull/7704\">implemented module/nomodule in Next.js</a>, and is working on solving these issues there.</p></li>\n</ul>\n\n<p>Thanks to <a href=\"https://twitter.com/philwalton\">Phil</a>, <a href=\"https://twitter.com/shubhie\">Shubhie</a>, <a href=\"https://twitter.com/atcastle\">Alex</a>, <a href=\"https://twitter.com/hdjirdeh\">Houssein</a>, <a href=\"https://twitter.com/Janicklas\">Ralph</a> and <a href=\"https://twitter.com/addyosmani\">Addy</a> for the feedback.</p>\n\n<div style=\"font-size:70%; color:#666; background:#eee; border:1px solid #ccc; padding: 10px; line-height:1.3;\">  \n<strong>2019-07-16:</strong> fixed code sample in Option 1, which was broken due to the asynchronous <code>self.modern</code> initialization.  \n<br>  \n</div>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2019-07-09T17:02:57.017Z","created_by":1,"updated_at":"2019-07-16T17:52:32.227Z","updated_by":1,"published_at":"2019-07-09T19:34:19.219Z","published_by":1},{"id":15,"uuid":"0812e466-acfa-469b-b79a-a26176f26e6a","title":"Application Holotypes: A Guide to Architecture Decisions","slug":"application-holotypes","markdown":"<div align=\"center\">\n<video src=\"https://res.cloudinary.com/wedding-website/video/upload/ac_none,c_scale,w_800/v1550250966/holotypes_kmgtw4.mp4\" width=\"400\" style=\"max-height:300px;\" autoplay playsinline muted loop></video>\n</div>\n\nAnalyzing the characteristics of real-world applications is difficult. We often make generalizations about applications we see in the wild, both anecdotal and statistical: \"Single-Page Applications are slower than multipage\" or \"apps with low TTI loaded fast\". However, the extent to which these generalizations hold for the performance and architectural characteristics we care about varies. I believe one of the primary determinants of this variability are a product's features and design constraints, and classifying applications based on their features & constraints can enable more targeted and impactful solutions to the problems faced by each.\n\nConstructing a set of named categories into which applications can be effectively grouped presents a challenge: it's difficult to predict all possible groups, and the boundaries set by each are subjective and likely to change over time. Furthermore, abstract groupings like this can be difficult to reason about or visualize. For example, what performance optimization techniques might we recommend to developers of \"thick-client, page-centric rich media applications with offline browsing and user contribution\"? It's much easier to frame discussions in the concrete, asking instead what we might recommend to developers of \"Instagram-like apps\".\n\nIn order to establish this framing, we can construct a list of holotype applications. These can either be representative of the web as it exists today, or predicated on changes we foresee developers making in response to trends and platform initiatives. To make things easier, holotypes representing portions of the web's long tail of historical and legacy content can be more general, whereas those representing current and upcoming applications can be more narrowly scoped to allow for more specific recommendations.\n\n\n## Meet the Holotypes\n\nEach holotype application is accompanied by a rough category name, additional real-world examples, as well as the characteristics & constraints that define its architecture. Ideal implementation and delivery techniques are also provided, based on the architectural context.\n\n#### 🎪 Social Networking Destinations\n\n**Holotype:**  Facebook  \n**Examples:**  LinkedIn, Reddit, Google+  \n**Characteristics:**  multifaceted, sub-applications, infinite scrolling content, user contribution, realtime updates, notifications  \n**Constraints:**  extended session depth, large scale, realtime updates, resource contention from embedded content, nested applications, SEO  \n**Ideal Implementation:**  Single-Page Application with prerendering of shell and landing pages.  \n**Ideal Delivery:**  PWA in standalone display mode. TWA.\n\n#### 🤳 Social Media Applications\n\n**Holotype:**  Instagram  \n**Examples:** Youtube, Twitter  \n**Characteristics:**  rich media, infinite scrolling content, user contribution, realtime updates, notifications, embeddability, embedded content  \n**Constraints:**  extended session depth, realtime updates, resource contention from embedded content, uninterruptible media playback, SEO  \n**Ideal Implementation:**  Single-Page Application with app shell prerendering & caching.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 🛍 Storefronts\n\n**Holotype:**  Amazon  \n**Examples:**  Bestbuy, Newegg, Shopify(-based stores)  \n**Characteristics:**  search, payments, discoverability, filtering & sorting  \n**Constraints:**  shallow to medium session depth, small interactions, high cart/checkout dropoff, SEO  \n**Ideal Implementation:**  Server-rendered site with CSR/SPA takeover or turbolinks-style transitions.  \n**Ideal Delivery:**  PWA in default display mode.\n\n#### 📰 Content Websites\n\n**Holotype:**  CNN  \n**Examples:**  FT, BBC, BuzzFeed, Engadget, Salon, Smashing Magazine, The Onion  \n**Characteristics:**  discoverability, rich media, embedded content  \n**Constraints:**  shallow session depth (~1), resource contention from ads & multivariate testing, SEO  \n**Ideal Implementation:**  Server-rendered site with turbolinks-style transitions.  \n**Ideal Delivery:**  PWA in default display mode.\n\n#### 📨 [PIM](https://en.wikipedia.org/wiki/Personal_information_management) Applications\n\n**Holotype:**  Gmail  \n**Examples:**  Google Calendar, Outlook.com, Fastmail  \n**Characteristics:**  thick-client, infinite lists, embedded content, rich text editing, sanitization, MDI, storage, offline & sync, notifications  \n**Constraints:**  extended session length, sensitive & largely uncacheable data, high security risk, often offline  \n**Ideal Implementation:**  Single Page App with app shell caching.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 📝 Productivity Applications\n\n**Holotype:**  Google Docs  \n**Examples:**  Office.com, Zoho, Dropbox, Box  \n**Characteristics:**  thick-client, rich text editing, offline & sync, filesystem, clipboard, storage, image manipulation, embedded content  \n**Constraints:**  extended session length and multiple concurrent sessions favor client-side implementation.  \n**Ideal Implementation:**  Single Page App. Consider app shell caching. Unload page between apps.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 🎧 Media Players\n\n**Holotype:**  Spotify  \n**Examples:**  Youtube Music, Google Play Music, Tidal, Soundcloud, Pandora, Deezer  \n**Characteristics:**  rich media, thick-client, infinite scrolling content, filtering & sorting, notifications, OS integration, offline, embeddability  \n**Constraints:**  extended session length, playback must continue as the user navigates.  \n**Ideal Implementation:**  Single Page App with app shell prerendering & caching. Server-render &lt;head&gt; for discovery.  \n**Ideal Delivery:** PWA in standalone display mode.\n\n#### 🎨 Graphical Editors\n\n**Holotype:**  Figma  \n**Examples:**  AutoCAD, Tinkercad, Photopea, Polarr  \n**Characteristics:**  3D rendering & GPU, image manipulation, fullscreen & pointer capture, MDI, storage, offline, filesystem, threads, wasm  \n**Constraints:**  long session length, sensitivity to input & rendering latency, large objects/files  \n**Ideal Implementation:**  Single Page App. Separate lighter browsing UI from editor.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 👨‍🎤 Media Editors\n\n**Holotype:**  Soundtrap  \n**Examples:**  Looplabs  \n**Characteristics:**  Audio processing, device integration (midi,usb), storage, offline, filesystem, threads, wasm  \n**Constraints:**  long session length, low-latency DSP, low-latency media recording & playback, large file sizes/IO  \n**Ideal Implementation:**  Single Page App. Separate lighter browsing UI from editor.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 👩‍💻 Engineering Tools\n\n**Holotype:**  Codesandbox  \n**Examples:**  Codepen, Jupyter Notebook, RStudio, StackBlitz  \n**Characteristics:**  thick-client, MDI, storage, offline, filesystem, threads, embedded content  \n**Constraints:**  extremely long session length, low-latency text input, large memory footprint, custom input handling and text rendering, security of preview content  \n**Ideal Implementation:**  Single Page App. Consider separating browsing UI from editor.  \n**Ideal Delivery:**  PWA in standalone display mode.\n\n#### 🎮 Immersive / AAA Games\n\n**Holotype:**  Stadia  \n**Examples:**  Heraclos, Duelyst, OUIGO  \n**Characteristics:**  3D rendering & GPU, P2P, audio processing, fullscreen & pointer capture, storage, offline, filesystem, threads, device integration (gamepad), wasm  \n**Constraints:**  long session length (highly interactive), immersion, extremely sensitive to input and rendering latency, requires consistent or stepped FPS, extreme asset sizes  \n**Ideal Implementation:**  Single Page App  \n**Ideal Delivery:**  PWA in fullscreen display mode.\n\n#### 👾 Casual Games\n\n**Holotype:**  Robostorm  \n**Examples:**  Tank Off, War Brokers, GoreScript, Air Wars, \".io games\"  \n**Characteristics:**  2D & 3D rendering & GPU, P2P, audio processing, storage, offline, embeddability  \n**Constraints:**  long session length, sensitive to input and rendering latency, needs consistent/stepped FPS  \n**Ideal Implementation:**  Single Page App  \n**Ideal Delivery:**  embedded in another site, or PWA in fullscreen display mode.\n\n\n> Think I'm missing representation for a category?\n>\n> Missing a good example? Comment or tweet your suggestions!\n","html":"<div align=\"center\">  \n<video src=\"https://res.cloudinary.com/wedding-website/video/upload/ac_none,c_scale,w_800/v1550250966/holotypes_kmgtw4.mp4\" width=\"400\" style=\"max-height:300px;\" autoplay playsinline muted loop></video>  \n</div>\n\n<p>Analyzing the characteristics of real-world applications is difficult. We often make generalizations about applications we see in the wild, both anecdotal and statistical: \"Single-Page Applications are slower than multipage\" or \"apps with low TTI loaded fast\". However, the extent to which these generalizations hold for the performance and architectural characteristics we care about varies. I believe one of the primary determinants of this variability are a product's features and design constraints, and classifying applications based on their features &amp; constraints can enable more targeted and impactful solutions to the problems faced by each.</p>\n\n<p>Constructing a set of named categories into which applications can be effectively grouped presents a challenge: it's difficult to predict all possible groups, and the boundaries set by each are subjective and likely to change over time. Furthermore, abstract groupings like this can be difficult to reason about or visualize. For example, what performance optimization techniques might we recommend to developers of \"thick-client, page-centric rich media applications with offline browsing and user contribution\"? It's much easier to frame discussions in the concrete, asking instead what we might recommend to developers of \"Instagram-like apps\".</p>\n\n<p>In order to establish this framing, we can construct a list of holotype applications. These can either be representative of the web as it exists today, or predicated on changes we foresee developers making in response to trends and platform initiatives. To make things easier, holotypes representing portions of the web's long tail of historical and legacy content can be more general, whereas those representing current and upcoming applications can be more narrowly scoped to allow for more specific recommendations.</p>\n\n<h2 id=\"meettheholotypes\">Meet the Holotypes</h2>\n\n<p>Each holotype application is accompanied by a rough category name, additional real-world examples, as well as the characteristics &amp; constraints that define its architecture. Ideal implementation and delivery techniques are also provided, based on the architectural context.</p>\n\n<h4 id=\"socialnetworkingdestinations\">🎪 Social Networking Destinations</h4>\n\n<p><strong>Holotype:</strong>  Facebook <br />\n<strong>Examples:</strong>  LinkedIn, Reddit, Google+ <br />\n<strong>Characteristics:</strong>  multifaceted, sub-applications, infinite scrolling content, user contribution, realtime updates, notifications <br />\n<strong>Constraints:</strong>  extended session depth, large scale, realtime updates, resource contention from embedded content, nested applications, SEO <br />\n<strong>Ideal Implementation:</strong>  Single-Page Application with prerendering of shell and landing pages. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode. TWA.</p>\n\n<h4 id=\"socialmediaapplications\">🤳 Social Media Applications</h4>\n\n<p><strong>Holotype:</strong>  Instagram <br />\n<strong>Examples:</strong> Youtube, Twitter <br />\n<strong>Characteristics:</strong>  rich media, infinite scrolling content, user contribution, realtime updates, notifications, embeddability, embedded content <br />\n<strong>Constraints:</strong>  extended session depth, realtime updates, resource contention from embedded content, uninterruptible media playback, SEO <br />\n<strong>Ideal Implementation:</strong>  Single-Page Application with app shell prerendering &amp; caching. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"storefronts\">🛍 Storefronts</h4>\n\n<p><strong>Holotype:</strong>  Amazon <br />\n<strong>Examples:</strong>  Bestbuy, Newegg, Shopify(-based stores) <br />\n<strong>Characteristics:</strong>  search, payments, discoverability, filtering &amp; sorting <br />\n<strong>Constraints:</strong>  shallow to medium session depth, small interactions, high cart/checkout dropoff, SEO <br />\n<strong>Ideal Implementation:</strong>  Server-rendered site with CSR/SPA takeover or turbolinks-style transitions. <br />\n<strong>Ideal Delivery:</strong>  PWA in default display mode.</p>\n\n<h4 id=\"contentwebsites\">📰 Content Websites</h4>\n\n<p><strong>Holotype:</strong>  CNN <br />\n<strong>Examples:</strong>  FT, BBC, BuzzFeed, Engadget, Salon, Smashing Magazine, The Onion <br />\n<strong>Characteristics:</strong>  discoverability, rich media, embedded content <br />\n<strong>Constraints:</strong>  shallow session depth (~1), resource contention from ads &amp; multivariate testing, SEO <br />\n<strong>Ideal Implementation:</strong>  Server-rendered site with turbolinks-style transitions. <br />\n<strong>Ideal Delivery:</strong>  PWA in default display mode.</p>\n\n<h4 id=\"pimhttpsenwikipediaorgwikipersonal_information_managementapplications\">📨 <a href=\"https://en.wikipedia.org/wiki/Personal_information_management\">PIM</a> Applications</h4>\n\n<p><strong>Holotype:</strong>  Gmail <br />\n<strong>Examples:</strong>  Google Calendar, Outlook.com, Fastmail <br />\n<strong>Characteristics:</strong>  thick-client, infinite lists, embedded content, rich text editing, sanitization, MDI, storage, offline &amp; sync, notifications <br />\n<strong>Constraints:</strong>  extended session length, sensitive &amp; largely uncacheable data, high security risk, often offline <br />\n<strong>Ideal Implementation:</strong>  Single Page App with app shell caching. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"productivityapplications\">📝 Productivity Applications</h4>\n\n<p><strong>Holotype:</strong>  Google Docs <br />\n<strong>Examples:</strong>  Office.com, Zoho, Dropbox, Box <br />\n<strong>Characteristics:</strong>  thick-client, rich text editing, offline &amp; sync, filesystem, clipboard, storage, image manipulation, embedded content <br />\n<strong>Constraints:</strong>  extended session length and multiple concurrent sessions favor client-side implementation. <br />\n<strong>Ideal Implementation:</strong>  Single Page App. Consider app shell caching. Unload page between apps. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"mediaplayers\">🎧 Media Players</h4>\n\n<p><strong>Holotype:</strong>  Spotify <br />\n<strong>Examples:</strong>  Youtube Music, Google Play Music, Tidal, Soundcloud, Pandora, Deezer <br />\n<strong>Characteristics:</strong>  rich media, thick-client, infinite scrolling content, filtering &amp; sorting, notifications, OS integration, offline, embeddability <br />\n<strong>Constraints:</strong>  extended session length, playback must continue as the user navigates. <br />\n<strong>Ideal Implementation:</strong>  Single Page App with app shell prerendering &amp; caching. Server-render &lt;head&gt; for discovery. <br />\n<strong>Ideal Delivery:</strong> PWA in standalone display mode.</p>\n\n<h4 id=\"graphicaleditors\">🎨 Graphical Editors</h4>\n\n<p><strong>Holotype:</strong>  Figma <br />\n<strong>Examples:</strong>  AutoCAD, Tinkercad, Photopea, Polarr <br />\n<strong>Characteristics:</strong>  3D rendering &amp; GPU, image manipulation, fullscreen &amp; pointer capture, MDI, storage, offline, filesystem, threads, wasm <br />\n<strong>Constraints:</strong>  long session length, sensitivity to input &amp; rendering latency, large objects/files <br />\n<strong>Ideal Implementation:</strong>  Single Page App. Separate lighter browsing UI from editor. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"mediaeditors\">👨‍🎤 Media Editors</h4>\n\n<p><strong>Holotype:</strong>  Soundtrap <br />\n<strong>Examples:</strong>  Looplabs <br />\n<strong>Characteristics:</strong>  Audio processing, device integration (midi,usb), storage, offline, filesystem, threads, wasm <br />\n<strong>Constraints:</strong>  long session length, low-latency DSP, low-latency media recording &amp; playback, large file sizes/IO <br />\n<strong>Ideal Implementation:</strong>  Single Page App. Separate lighter browsing UI from editor. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"engineeringtools\">👩‍💻 Engineering Tools</h4>\n\n<p><strong>Holotype:</strong>  Codesandbox <br />\n<strong>Examples:</strong>  Codepen, Jupyter Notebook, RStudio, StackBlitz <br />\n<strong>Characteristics:</strong>  thick-client, MDI, storage, offline, filesystem, threads, embedded content <br />\n<strong>Constraints:</strong>  extremely long session length, low-latency text input, large memory footprint, custom input handling and text rendering, security of preview content <br />\n<strong>Ideal Implementation:</strong>  Single Page App. Consider separating browsing UI from editor. <br />\n<strong>Ideal Delivery:</strong>  PWA in standalone display mode.</p>\n\n<h4 id=\"immersiveaaagames\">🎮 Immersive / AAA Games</h4>\n\n<p><strong>Holotype:</strong>  Stadia <br />\n<strong>Examples:</strong>  Heraclos, Duelyst, OUIGO <br />\n<strong>Characteristics:</strong>  3D rendering &amp; GPU, P2P, audio processing, fullscreen &amp; pointer capture, storage, offline, filesystem, threads, device integration (gamepad), wasm <br />\n<strong>Constraints:</strong>  long session length (highly interactive), immersion, extremely sensitive to input and rendering latency, requires consistent or stepped FPS, extreme asset sizes <br />\n<strong>Ideal Implementation:</strong>  Single Page App <br />\n<strong>Ideal Delivery:</strong>  PWA in fullscreen display mode.</p>\n\n<h4 id=\"casualgames\">👾 Casual Games</h4>\n\n<p><strong>Holotype:</strong>  Robostorm <br />\n<strong>Examples:</strong>  Tank Off, War Brokers, GoreScript, Air Wars, \".io games\" <br />\n<strong>Characteristics:</strong>  2D &amp; 3D rendering &amp; GPU, P2P, audio processing, storage, offline, embeddability <br />\n<strong>Constraints:</strong>  long session length, sensitive to input and rendering latency, needs consistent/stepped FPS <br />\n<strong>Ideal Implementation:</strong>  Single Page App <br />\n<strong>Ideal Delivery:</strong>  embedded in another site, or PWA in fullscreen display mode.</p>\n\n<blockquote>\n  <p>Think I'm missing representation for a category?</p>\n  \n  <p>Missing a good example? Comment or tweet your suggestions!</p>\n</blockquote>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":"Application Holotypes: A Guide to Architecture Decisions","meta_description":"Analyzing real-world apps is difficult. Classifying based on features & constraints enables targeted solutions to the problems faced by each.","author_id":1,"created_at":"2019-02-15T16:22:02.103Z","created_by":1,"updated_at":"2019-12-01T21:03:06.018Z","updated_by":1,"published_at":"2019-02-15T16:33:29.693Z","published_by":1},{"id":18,"uuid":"cb5ed036-141e-4270-adcb-3025ecea8b39","title":"Rome, a new JavaScript Toolchain","slug":"rome-javascript-toolchain","markdown":"<img src=\"https://raw.githubusercontent.com/romejs/rome/master/website/static/img/rome-logo-black.svg\" width=\"100\" style=\"display:block; max-width:100px;\">\n\nSebastian McKenzie, the original creator of Yarn and Babel and a member of the React Native team at Facebook, has been working on an “all-in-one” solution for JavaScript and TypeScript development.\n\nThe [Rome](https://github.com/facebookexperimental/rome) project, a reference to “all roads lead to Rome”, was made public on Feb 26th 2020.\n\n\n## What is Rome?\n\n[Rome](https://github.com/facebookexperimental/rome) is a from-scratch implementation of a complete JavaScript toolchain. It compiles and bundles JavaScript projects, lints and type-checks, runs tests, and can also format code.\n\n\n#### What does it look like?\n\nWhile Rome is still very early-stage, the CLI provides some helpful information about its use:\n\n\n<table>\n  <tr>\n   <td><strong>CLI Command</strong>\n   </td>\n   <td><strong>Description</strong>\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome bundle</code>\n   </td>\n   <td>build a standalone js bundle for a package\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome compile</code>\n   </td>\n   <td>compile a single file\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome develop</code>\n   </td>\n   <td>start a web server\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome parse</code>\n   </td>\n   <td>parse a single file and dump its ast\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome resolve</code>\n   </td>\n   <td>resolve a file\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome analyzeDependencies</code>\n   </td>\n   <td>analyze and dump the dependencies of a file\n   </td>\n  </tr>\n</table>\n\n\nFor full usage details, [see CLI Usage](#cliusage).\n\n\n#### Why might this be a good idea?\n\nRome takes a different approach to JavaScript tooling than existing Open Source stacks, and is perhaps more similar to the internal monorepo-based tooling found at very large companies. Rather than assembling a build pipeline by passing source code through multiple disparate tools for various tasks, Rome performs all build and compile steps itself.\n\nThis helps address one of the problems faced by popular bundlers like Webpack and Rollup, which is that whole-program analysis and optimization ends up being very difficult or expensive because each tool must parse and construct its own AST.\n\n## Bundling\n\nRome’s architecture is relatively unique: all compilation happens on a per-module basis, which allows each module to be processed in a pool of worker threads. This works well for per-module transforms, but presents a challenge for bundling: in order to avoid having to re-parse every module produced by the workers, the modules need to be pre-namespaced such that they can all share a single scope.\n\nTo make bundling possible despite compilation being per-file, Rome prefixes all module-scoped variables with an identifier generated based on the module’s filename. For example, a `foo` variable in a file called `test.js` becomes `test_js_foo`.\n\nThis is also applied to each module’s imported and exported identifiers, which means any module export can be addressed using only the module’s filename and the export name:\n\n\n<table border=\"1\" bordercolor=\"#ddd\">\n  <tr>\n   <td><strong>Filename</strong>\n   </td>\n   <td><strong>Contents</strong>\n   </td>\n   <td><strong>Output</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>test.js\n   </td>\n   <td>\n\n```js\nexport const foo = 1;\n```\n   </td>\n   <td>\n```js\nconst ___R$test_js$foo = 1;\n```\n   </td>\n  </tr>\n  <tr>\n   <td>index.js\n   </td>\n   <td>\n```js\nimport { foo } from './test.js';\nconsole.log(foo);\n```\n   </td>\n   <td>\n```js\nconsole.log(___R$test_js$foo);\n```\n   </td>\n  </tr>\n</table>\n\n\n## Output Quality\n\nFor the modern web developer, tooling often dictates how efficient and size-conscious our applications can be. This means we have a vested interest in understanding the composition of our bundles, and Rome’s output is worth paying some attention to. In particular, I’m always interested in getting a sense of whether the bundles generated by a tool collapse modules into a shared closure like Rollup, or preserve module boundaries using closures and a runtime loader implementation like Webpack.\n\nI conducted an initial investigation of what Rome’s output looks like. It appears to produce “scope-collapsed” single-closure bundles, fairly similar to those generated by Rollup:\n\n\n<table border=\"1\" bordercolor=\"#ddd\">\n  <tr>\n   <td><strong>Input (module):</strong>\n   </td>\n   <td><strong>Output (bundle):</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>\n```js\nfunction hello() {\n  return 'Hello World';\n}\n\nconsole.log(hello());\n```\n   </td>\n   <td>\n```js\n(function(global) {\n  'use strict';\n  // input.ts\n\n  const ___R$rome$input_ts = {};\n  function ___R$$priv$rome$input_ts$hello() {\n    return 'Hello World';\n  }\n\n  console.log(___R$$priv$rome$input_ts$hello());\n\n  return ___R$rome$input_ts;\n})(typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : this);\n```\n   </td>\n  </tr>\n</table>\n\n\nThere is currently no provided way to minify the bundled output, which is to be expected given the project’s early preview status. However, running the above result through Terser yields a very reasonable output:\n\n\n```js\n!function(o) {\n    \"use strict\";\n    console.log(\"Hello World\");\n}(\"undefined\" != typeof global ? global : \"undefined\" != typeof window && window);\n```\n\n\nAs you can see, there’s a small amount of low-hanging optimization fruit here even with this very simple bundle. Ideally the bundler could be made aware of the intended mode, and if it were known to be compiling for an ES Modules target it could omit the closure and strict mode directive. It could also hoist the declaration of “global” to module scope, which in the above case would allow Terser to dead-code-eliminate it.\n\n\n## In Larger Projects\n\nLet’s look at a very slightly more complex demo, involving two modules with a shared common dependency:\n\n**entry.tsx**:\n\n```js\nimport React from './react';\nimport title from './other';\n// Note: dynamic import doesn't yet work in Rome\n// const title = import('./other').then(m => m.default);\n\nasync function App(props: any) {\n  return <div id=\"app\">{await title()}</div>\n}\n\nApp({}).then(console.log);\n```\n\n\n**other.tsx**:\n\n```js\nimport React from './react';\nexport default () => <h1>Hello World</h1>;\n```\n\n\n**react.tsx**:\n\n```js\ntype VNode = {\n  type: string;\n  props: any;\n  children: Array<VNode|string>\n};\nfunction createElement(\n  type: string,\n  props: any,\n  ...children: Array<VNode|string>\n): VNode {\n  return { type, props, children };\n}\nexport default { createElement };\n```\n\n\nBundling this using `rome bundle entry.tsx out` produces a directory with an index.js file (and a Source Map):\n\n\n```js\n(function(global) {\n  'use strict';\n  // rome/react.tsx\n\n  function ___R$$priv$rome$react_tsx$createElement(\n    type, props, ...children\n  ) {\n    return {type: type, props: props, children: children};\n  }\n  const ___R$rome$react_tsx$default = {\n    createElement: ___R$$priv$rome$react_tsx$createElement\n  };\n\n  // rome/other.tsx\n\n  const ___R$rome$other_tsx$default = () =>\n    ___R$rome$react_tsx$default.createElement(\n      'h1', null, 'Hello World'\n    );\n\n  // rome/test.tsx\n\n  const ___R$rome$test_tsx = {};\n  async function ___R$$priv$rome$test_tsx$App(props) {\n    return ___R$rome$react_tsx$default.createElement(\n      'div', { id: 'app'},\n      (await ___R$rome$other_tsx$default())\n    );\n  }\n\n  ___R$$priv$rome$test_tsx$App({}).then(console.log);\n\n  return ___R$rome$test_tsx;\n})(typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : this);\n```\n\n\nIt’s a little bit harder to follow, but we can see the same structure as the single-module example is still in place.\n\nStripping away the module implementations and dead CommonJS interop code from Rome’s output, our three source modules are inlined into a single wrapping closure:\n\n```js\n(function(global) {\n  'use strict';\n  // rome/react.tsx\n  const ___R$rome$react_tsx$default = /* snip */;\n\n  // rome/other.tsx\n  const ___R$rome$other_tsx$default = /* snip */;\n\n  // rome/entry.tsx\n  ___R$$priv$rome$entry_tsx$App({}).then(console.log);\n})(window);\n```\n\n\n## Production Minification\n\nAs I mentioned, Rome doesn’t currently include production minification, though its design does lend itself well to minification at the bundle level. We can run the above output through Terser to see what it looks like. I’ve beautified Terser’s output here for readability:\n\n\n```js\n! function(e) {\n    const n = {\n        createElement: function(e, n, ...t) {\n            return {\n                type: e,\n                props: n,\n                children: t\n            }\n        }\n    };\n    (async function(e) {\n        return n.createElement(\"div\", {\n            id: \"app\"\n        }, await n.createElement(\"h1\", null, \"Hello World\"))\n    })().then(console.log)\n}(\"undefined\" != typeof global ? global : \"undefined\" != typeof window && window);\n```\n\nAfter minification, the output actually looks pretty good! This is a very simple example application though, so we’re not able to see how this scales up to full applications quite yet.\n\n\n## Further Optimization\n\nI’ve been [working on a project](https://twitter.com/i/events/1218283019083157505) for the past half-year that aims to apply automated optimization to bundled JavaScript (it’s not released yet, sorry!). As a test, I tried passing Rome’s output through that compiler before passing it through Terser with the same settings as above. I’m happy to say this yielded something close to an ideal output: there’s no wrapping function, no dead code, and it leverages the size benefits of modern syntax:\n\n\n```js\nconst e = {\n  createElement: (e, n, ...t) =>\n    ({ type: e, props: n, children: t })\n};\n(async () =>\n  e.createElement(\"div\", { id: \"app\" },\n    await e.createElement(\"h1\", null, \"Hello World\")\n  )\n)().then(console.log);\n```\n\nThis is promising! \n\n\n## Code Splitting\n\nRome does not yet appear to support dynamic import or Code Splitting. Using `import()` statements in code actually does discover the imported module, but it gets inlined into the bundle as if it were a static import. The original `import()` statement is left unmodified in the generated output, which causes an error.\n\nIt remains to be seen how Code Splitting and chunking will affect the output quality, since both rely on accessing variables enclosed in one bundle from another. I’m not yet familiar enough with Rome to even guess at what this might look like.\n\n\n## CLI Usage\n\nIf you just want to take a peek at what Rome’s CLI has on offer, here’s the --help output you’ll get without having to build it yourself (though it’s very quick to build!):\n\n\n```sh\n$ rome --help\n  Usage: rome [command] [flags]\n\n  Options\n\n    --benchmark\n    --benchmark-iterations <num>\n    --collect-markers\n    --cwd <input>\n    --focus <input>\n    --grep <input>\n    --inverse-grep\n    --log-path <input>\n    --logs\n    --log-workers\n    --markers-path <input>\n    --max-diagnostics <num>\n    --no-profile-workers\n    --no-show-all-diagnostics\n    --profile\n    --profile-path <input>\n    --profile-sampling <num>\n    --profile-timeout <num>\n    --rage\n    --rage-path <input>\n    --resolver-mocks\n    --resolver-scale <num>\n    --silent\n    --temporary-daemon\n    --verbose\n    --verbose-diagnostics\n    --watch\n\n  Code Quality Commands\n\n    ci    install dependencies, run lint and tests\n    lint  run lint against a set of files\n    test  run tests\n      --no-coverage\n      --show-all-coverage\n      --update-snapshots\n\n  Internal Commands\n\n    evict  evict a file from the memory cache\n    logs   \n    rage   \n\n  Process Management Commands\n\n    restart  restart daemon\n    start    start daemon (if none running)\n    status   get the current daemon status\n    stop     stop a running daemon if one exists\n    web      \n\n  Project Management Commands\n\n    config   \n    publish  TODO\n    run      TODO\n\n  Source Code Commands\n\n    analyzeDependencies  analyze and dump the dependencies of a file\n      --compact\n      --focus-source <input>\n    bundle               build a standalone js bundle for a package\n    compile              compile a single file\n      --bundle\n    develop              start a web server\n      --port <num>\n    parse                parse a single file and dump its ast\n      --no-compact\n      --show-despite-diagnostics\n    resolve              resolve a file\n```\n","html":"<p><img src=\"https://raw.githubusercontent.com/romejs/rome/master/website/static/img/rome-logo-black.svg\" width=\"100\" style=\"display:block; max-width:100px;\"></p>\n\n<p>Sebastian McKenzie, the original creator of Yarn and Babel and a member of the React Native team at Facebook, has been working on an “all-in-one” solution for JavaScript and TypeScript development.</p>\n\n<p>The <a href=\"https://github.com/facebookexperimental/rome\">Rome</a> project, a reference to “all roads lead to Rome”, was made public on Feb 26th 2020.</p>\n\n<h2 id=\"whatisrome\">What is Rome?</h2>\n\n<p><a href=\"https://github.com/facebookexperimental/rome\">Rome</a> is a from-scratch implementation of a complete JavaScript toolchain. It compiles and bundles JavaScript projects, lints and type-checks, runs tests, and can also format code.</p>\n\n<h4 id=\"whatdoesitlooklike\">What does it look like?</h4>\n\n<p>While Rome is still very early-stage, the CLI provides some helpful information about its use:</p>\n\n<table>  \n  <tr>\n   <td><strong>CLI Command</strong>\n   </td>\n   <td><strong>Description</strong>\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome bundle</code>\n   </td>\n   <td>build a standalone js bundle for a package\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome compile</code>\n   </td>\n   <td>compile a single file\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome develop</code>\n   </td>\n   <td>start a web server\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome parse</code>\n   </td>\n   <td>parse a single file and dump its ast\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome resolve</code>\n   </td>\n   <td>resolve a file\n   </td>\n  </tr>\n  <tr>\n   <td><code>rome analyzeDependencies</code>\n   </td>\n   <td>analyze and dump the dependencies of a file\n   </td>\n  </tr>\n</table>\n\n<p>For full usage details, <a href=\"#cliusage\">see CLI Usage</a>.</p>\n\n<h4 id=\"whymightthisbeagoodidea\">Why might this be a good idea?</h4>\n\n<p>Rome takes a different approach to JavaScript tooling than existing Open Source stacks, and is perhaps more similar to the internal monorepo-based tooling found at very large companies. Rather than assembling a build pipeline by passing source code through multiple disparate tools for various tasks, Rome performs all build and compile steps itself.</p>\n\n<p>This helps address one of the problems faced by popular bundlers like Webpack and Rollup, which is that whole-program analysis and optimization ends up being very difficult or expensive because each tool must parse and construct its own AST.</p>\n\n<h2 id=\"bundling\">Bundling</h2>\n\n<p>Rome’s architecture is relatively unique: all compilation happens on a per-module basis, which allows each module to be processed in a pool of worker threads. This works well for per-module transforms, but presents a challenge for bundling: in order to avoid having to re-parse every module produced by the workers, the modules need to be pre-namespaced such that they can all share a single scope.</p>\n\n<p>To make bundling possible despite compilation being per-file, Rome prefixes all module-scoped variables with an identifier generated based on the module’s filename. For example, a <code>foo</code> variable in a file called <code>test.js</code> becomes <code>test_js_foo</code>.</p>\n\n<p>This is also applied to each module’s imported and exported identifiers, which means any module export can be addressed using only the module’s filename and the export name:</p>\n\n<table border=\"1\" bordercolor=\"#ddd\">  \n  <tr>\n   <td><strong>Filename</strong>\n   </td>\n   <td><strong>Contents</strong>\n   </td>\n   <td><strong>Output</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>test.js\n   </td>\n   <td>\n\n\n<pre><code class=\"language-js\">export const foo = 1;  \n</code></pre>\n\n\n   </td>\n   <td>\n\n<pre><code class=\"language-js\">const ___R$test_js$foo = 1;  \n</code></pre>\n\n\n   </td>\n  </tr>\n  <tr>\n   <td>index.js\n   </td>\n   <td>\n\n<pre><code class=\"language-js\">import { foo } from './test.js';  \nconsole.log(foo);  \n</code></pre>\n\n\n   </td>\n   <td>\n\n<pre><code class=\"language-js\">console.log(___R$test_js$foo);  \n</code></pre>\n\n\n   </td>\n  </tr>\n</table>\n\n<h2 id=\"outputquality\">Output Quality</h2>\n\n<p>For the modern web developer, tooling often dictates how efficient and size-conscious our applications can be. This means we have a vested interest in understanding the composition of our bundles, and Rome’s output is worth paying some attention to. In particular, I’m always interested in getting a sense of whether the bundles generated by a tool collapse modules into a shared closure like Rollup, or preserve module boundaries using closures and a runtime loader implementation like Webpack.</p>\n\n<p>I conducted an initial investigation of what Rome’s output looks like. It appears to produce “scope-collapsed” single-closure bundles, fairly similar to those generated by Rollup:</p>\n\n<table border=\"1\" bordercolor=\"#ddd\">  \n  <tr>\n   <td><strong>Input (module):</strong>\n   </td>\n   <td><strong>Output (bundle):</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>\n\n<pre><code class=\"language-js\">function hello() {  \n  return 'Hello World';\n}\n\nconsole.log(hello());  \n</code></pre>\n\n\n   </td>\n   <td>\n\n<pre><code class=\"language-js\">(function(global) {\n  'use strict';\n  // input.ts\n\n  const ___R$rome$input_ts = {};\n  function ___R$$priv$rome$input_ts$hello() {\n    return 'Hello World';\n  }\n\n  console.log(___R$$priv$rome$input_ts$hello());\n\n  return ___R$rome$input_ts;\n})(typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : this);\n</code></pre>\n\n\n   </td>\n  </tr>\n</table>\n\n<p>There is currently no provided way to minify the bundled output, which is to be expected given the project’s early preview status. However, running the above result through Terser yields a very reasonable output:</p>\n\n<pre><code class=\"language-js\">!function(o) {\n    \"use strict\";\n    console.log(\"Hello World\");\n}(\"undefined\" != typeof global ? global : \"undefined\" != typeof window &amp;&amp; window);\n</code></pre>\n\n<p>As you can see, there’s a small amount of low-hanging optimization fruit here even with this very simple bundle. Ideally the bundler could be made aware of the intended mode, and if it were known to be compiling for an ES Modules target it could omit the closure and strict mode directive. It could also hoist the declaration of “global” to module scope, which in the above case would allow Terser to dead-code-eliminate it.</p>\n\n<h2 id=\"inlargerprojects\">In Larger Projects</h2>\n\n<p>Let’s look at a very slightly more complex demo, involving two modules with a shared common dependency:</p>\n\n<p><strong>entry.tsx</strong>:</p>\n\n<pre><code class=\"language-js\">import React from './react';  \nimport title from './other';  \n// Note: dynamic import doesn't yet work in Rome\n// const title = import('./other').then(m =&gt; m.default);\n\nasync function App(props: any) {  \n  return &lt;div id=\"app\"&gt;{await title()}&lt;/div&gt;\n}\n\nApp({}).then(console.log);  \n</code></pre>\n\n<p><strong>other.tsx</strong>:</p>\n\n<pre><code class=\"language-js\">import React from './react';  \nexport default () =&gt; &lt;h1&gt;Hello World&lt;/h1&gt;;  \n</code></pre>\n\n<p><strong>react.tsx</strong>:</p>\n\n<pre><code class=\"language-js\">type VNode = {  \n  type: string;\n  props: any;\n  children: Array&lt;VNode|string&gt;\n};\nfunction createElement(  \n  type: string,\n  props: any,\n  ...children: Array&lt;VNode|string&gt;\n): VNode {\n  return { type, props, children };\n}\nexport default { createElement };  \n</code></pre>\n\n<p>Bundling this using <code>rome bundle entry.tsx out</code> produces a directory with an index.js file (and a Source Map):</p>\n\n<pre><code class=\"language-js\">(function(global) {\n  'use strict';\n  // rome/react.tsx\n\n  function ___R$$priv$rome$react_tsx$createElement(\n    type, props, ...children\n  ) {\n    return {type: type, props: props, children: children};\n  }\n  const ___R$rome$react_tsx$default = {\n    createElement: ___R$$priv$rome$react_tsx$createElement\n  };\n\n  // rome/other.tsx\n\n  const ___R$rome$other_tsx$default = () =&gt;\n    ___R$rome$react_tsx$default.createElement(\n      'h1', null, 'Hello World'\n    );\n\n  // rome/test.tsx\n\n  const ___R$rome$test_tsx = {};\n  async function ___R$$priv$rome$test_tsx$App(props) {\n    return ___R$rome$react_tsx$default.createElement(\n      'div', { id: 'app'},\n      (await ___R$rome$other_tsx$default())\n    );\n  }\n\n  ___R$$priv$rome$test_tsx$App({}).then(console.log);\n\n  return ___R$rome$test_tsx;\n})(typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : this);\n</code></pre>\n\n<p>It’s a little bit harder to follow, but we can see the same structure as the single-module example is still in place.</p>\n\n<p>Stripping away the module implementations and dead CommonJS interop code from Rome’s output, our three source modules are inlined into a single wrapping closure:</p>\n\n<pre><code class=\"language-js\">(function(global) {\n  'use strict';\n  // rome/react.tsx\n  const ___R$rome$react_tsx$default = /* snip */;\n\n  // rome/other.tsx\n  const ___R$rome$other_tsx$default = /* snip */;\n\n  // rome/entry.tsx\n  ___R$$priv$rome$entry_tsx$App({}).then(console.log);\n})(window);\n</code></pre>\n\n<h2 id=\"productionminification\">Production Minification</h2>\n\n<p>As I mentioned, Rome doesn’t currently include production minification, though its design does lend itself well to minification at the bundle level. We can run the above output through Terser to see what it looks like. I’ve beautified Terser’s output here for readability:</p>\n\n<pre><code class=\"language-js\">! function(e) {\n    const n = {\n        createElement: function(e, n, ...t) {\n            return {\n                type: e,\n                props: n,\n                children: t\n            }\n        }\n    };\n    (async function(e) {\n        return n.createElement(\"div\", {\n            id: \"app\"\n        }, await n.createElement(\"h1\", null, \"Hello World\"))\n    })().then(console.log)\n}(\"undefined\" != typeof global ? global : \"undefined\" != typeof window &amp;&amp; window);\n</code></pre>\n\n<p>After minification, the output actually looks pretty good! This is a very simple example application though, so we’re not able to see how this scales up to full applications quite yet.</p>\n\n<h2 id=\"furtheroptimization\">Further Optimization</h2>\n\n<p>I’ve been <a href=\"https://twitter.com/i/events/1218283019083157505\">working on a project</a> for the past half-year that aims to apply automated optimization to bundled JavaScript (it’s not released yet, sorry!). As a test, I tried passing Rome’s output through that compiler before passing it through Terser with the same settings as above. I’m happy to say this yielded something close to an ideal output: there’s no wrapping function, no dead code, and it leverages the size benefits of modern syntax:</p>\n\n<pre><code class=\"language-js\">const e = {  \n  createElement: (e, n, ...t) =&gt;\n    ({ type: e, props: n, children: t })\n};\n(async () =&gt;\n  e.createElement(\"div\", { id: \"app\" },\n    await e.createElement(\"h1\", null, \"Hello World\")\n  )\n)().then(console.log);\n</code></pre>\n\n<p>This is promising! </p>\n\n<h2 id=\"codesplitting\">Code Splitting</h2>\n\n<p>Rome does not yet appear to support dynamic import or Code Splitting. Using <code>import()</code> statements in code actually does discover the imported module, but it gets inlined into the bundle as if it were a static import. The original <code>import()</code> statement is left unmodified in the generated output, which causes an error.</p>\n\n<p>It remains to be seen how Code Splitting and chunking will affect the output quality, since both rely on accessing variables enclosed in one bundle from another. I’m not yet familiar enough with Rome to even guess at what this might look like.</p>\n\n<h2 id=\"cliusage\">CLI Usage</h2>\n\n<p>If you just want to take a peek at what Rome’s CLI has on offer, here’s the --help output you’ll get without having to build it yourself (though it’s very quick to build!):</p>\n\n<pre><code class=\"language-sh\">$ rome --help\n  Usage: rome [command] [flags]\n\n  Options\n\n    --benchmark\n    --benchmark-iterations &lt;num&gt;\n    --collect-markers\n    --cwd &lt;input&gt;\n    --focus &lt;input&gt;\n    --grep &lt;input&gt;\n    --inverse-grep\n    --log-path &lt;input&gt;\n    --logs\n    --log-workers\n    --markers-path &lt;input&gt;\n    --max-diagnostics &lt;num&gt;\n    --no-profile-workers\n    --no-show-all-diagnostics\n    --profile\n    --profile-path &lt;input&gt;\n    --profile-sampling &lt;num&gt;\n    --profile-timeout &lt;num&gt;\n    --rage\n    --rage-path &lt;input&gt;\n    --resolver-mocks\n    --resolver-scale &lt;num&gt;\n    --silent\n    --temporary-daemon\n    --verbose\n    --verbose-diagnostics\n    --watch\n\n  Code Quality Commands\n\n    ci    install dependencies, run lint and tests\n    lint  run lint against a set of files\n    test  run tests\n      --no-coverage\n      --show-all-coverage\n      --update-snapshots\n\n  Internal Commands\n\n    evict  evict a file from the memory cache\n    logs   \n    rage   \n\n  Process Management Commands\n\n    restart  restart daemon\n    start    start daemon (if none running)\n    status   get the current daemon status\n    stop     stop a running daemon if one exists\n    web      \n\n  Project Management Commands\n\n    config   \n    publish  TODO\n    run      TODO\n\n  Source Code Commands\n\n    analyzeDependencies  analyze and dump the dependencies of a file\n      --compact\n      --focus-source &lt;input&gt;\n    bundle               build a standalone js bundle for a package\n    compile              compile a single file\n      --bundle\n    develop              start a web server\n      --port &lt;num&gt;\n    parse                parse a single file and dump its ast\n      --no-compact\n      --show-despite-diagnostics\n    resolve              resolve a file\n</code></pre>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2020-02-28T17:15:32.008Z","created_by":1,"updated_at":"2020-06-02T23:42:23.346Z","updated_by":1,"published_at":"2020-02-28T17:40:00.000Z","published_by":1},{"id":20,"uuid":"5c238afd-c29b-4bb1-8416-3a5f01d4cdf7","title":"Event Listeners: Delegation VS Direct Binding","slug":"event-delegation-vs-direct-binding","markdown":"<div>\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1598628155/nasa-Q1p7bh3SHj8-unsplash_inzedd.jpg\">\n\n<figcaption style=\"position:relative;top:-1em;text-align:right;font-size:70%;\"><a href=\"https://unsplash.com/photos/Q1p7bh3SHj8\" target=\"_blank\" style=\"color:#999;text-decoration:none;\">Image courtesy of NASA</a></figcaption>\n</div>\n\nThe DOM provides a mechanism for registering event handlers that supports two techniques for observing events: directly-bound per-element listeners, _and_ “delegated” listeners that receive events originating from within an entire subtree.\n\nFrameworks and libraries that abstract event listener registration generally choose between the two approaches, yet this area of front-end performance has seen relatively limited debate. Library developers often rely on past experience to make decisions relating to event delegation vs direct binding, which I’ll try to summarize in this article.\n\n\n### Direct Binding\n\nThe oldest and simplest way to listen for DOM events is to register an event handler function directly on the node that will emit that event. Most DOM events propagate up the tree from their originating `target` Node, so this approach can be combined freely with delegation techniques (more on that later).\n\nHere’s a simple example of a directly bound event handler that intercepts clicks on a particular anchor link:\n\n```html\n<a href=\"/\" id=\"home\">Home</a>\n<script>\n  home.addEventListener('click', e => {\n    const link = e.currentTarget;   // <a>\n    history.pushState(null, null, link.href);\n    fancyPageLoad(link.href);  // \"ajax\"\n    e.preventDefault();  // prevent page load\n    e.stopPropagation();\n  });\n</script>\n```\n\nIn the example, direct binding is accomplished easily because we already have a reference to the element on which the click event will be triggered. This is a case where direct binding is also the best approach from a performance standpoint, since no DOM tree traversal is required to register or handle the event. Strictly looking at our own logic, registering and invoking the listener are both `O(1)` operations.\n\n### Event Delegation\n\nEvent delegation is a technique for listening for events in the aggregate. It leverages the fact that most events “bubble” up the DOM tree, which means they can be intercepted at the tree’s root and handled there.\n\nOne of the key features that makes event delegation valuable is that it is possible to handle events from any target node _without_ having a prior reference to that node. In cases where an event handler needs to listen on a large or changing set of target nodes, this avoids having to manually manage adding and removing handlers from each node. \n\nImagine our previous link click handling example, except now there are many links on the page, and additional links may be added or removed over time:\n\n```html\n<a href=\"/\">Home</a>\n<a href=\"/profile\">Profile</a>\n<a href=\"/search\">Search</a>\n<script>\n  function handleClick(e) {\n    history.pushState(null, null, this.href);\n    fancyPageLoad(this.href);\n    e.preventDefault();\n  }\n  for (let link of document.querySelectorAll('a[href]')) {\n    link.addEventListener('click', handleClick);\n  }\n  // ...listen for added/removed links using MutationObserver...\n</script>\n```\n\nImplementing this using direct binding requires searching the DOM for anchorlink elements and registering event handlers on each. We’d also need to use something like `MutationObserver` to detect newly-added links and register our handler on them. This would be expensive, since searching the DOM incurs a runtime performance cost and increases memory usage, as does `MutationObserver`. Listener invocation has the same performance as the previous simple direct binding example, but registration no longer runs in constant time.\n\nLet's compare this to a solution using event delegation:\n\n```html\n<a href=\"/\">Home</a>\n<a href=\"/profile\">Profile</a>\n<a href=\"/search\">Search</a>\n<script>\n  addEventListener('click', e => {\n    let target = e.target;\n    do {\n      if (target.localName === 'a') {\n        history.pushState(null, null, target.href);\n        fancyPageLoad(target.href);\n        e.preventDefault();\n        break;\n      }\n    } while (target = target.parentNode);\n  });\n</script>\n```\n\nNow our example uses a single delegated event handler, which removes all event handler management costs. There is a small performance tradeoff being made here, which is that the handler has to walk up the DOM tree to detect if a click occurred on a link. In this case our logic for registering the listeners is `O(1)`, and the listener's invocation is `O(log(n))`.\n\nIn many cases where there’s a very large number of event targets or where event targets are not known up-front, event delegation can improve performance by relying on the browser’s hit testing logic to dynamically observe events of a given type.\n\n### Event delegation can be tricky\n\nIt’s important to note that event delegation can create a set of problems not found when using directly-bound event handlers. Delegation can make event “pathing” difficult, and the effects of this are sometimes only revealed as a codebase increases in complexity. One example of this occurs when the DOM tree is mutated during the course of an event’s capturing or bubbling phase: should an event continue bubbling if its target or an ancestor is removed?\n\nA concrete example of where event pathing grows difficult is handling events from other documents in a fully delegated event handling model. An event triggered within an iframe does not bubble up to the parent document, which means it cannot be handled via delegation. This can be addressed by adding additional delegated event handlers in documents, which can either handle or retarget/refire the event in the parent document to emulate bubbling. While edge cases like these are not always important to account for, if they become necessary it can complicate event delegation and reduce its performance value.\n\n### Missing out on features\n\nFor those exploring event delegation, it’s important to take note of some direct binding features that are more difficult or even impossible to leverage in a delegated model. In the past few years, the [addEventListener API](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener) has gained support for one-time handlers that are automatically removed after being fired, which can help avoid a class of memory leak caused by DOM references retained solely to allow for listener removal.\n\nPassive listeners are another addEventListener feature introduced somewhat recently, offering a way to listen for events without blocking user interaction when they occur. This is an important technique to have at your disposal when implementing things like touch and scroll reactivity. Browsers are actively moving towards firing passive events by default, however this is happening slowly and on a case-by-case basis due to a high potential for breaking the web. Until this transition is complete, it’s a good idea to make sure your solution for delegating events provides a way to register passive listeners - or even uses passive listeners by default.\n\nAnother feature that event delegation implementations sometimes struggle with recreating is the level of optimization already present in browser event implementations. Events are created and initialized at the root of a document and their hit-tested event path is constructed in advance despite its JavaScript representation being lazily-constructed. The same Event object instance is passed to each handler invoked during the capturing and bubbling phases. Browsers engines can optimize garbage collection of Event instances, since they do not have to hold a strong reference to an event. It should be possible to approximate these optimizations in a JavaScript implementation using recently-added language features like [WeakRef and Finalizers](https://v8.dev/features/weak-references), however it’s unlikely any popular solutions will leverage this for some time.\n\nFinally, one of the most compelling arguments in favor of directly binding event listeners rather than using global event delegation is interoperability. Event listeners registered directly on nodes are partaking in the DOM’s cooperative event handling model: every element and its listeners have a chance to observe or intercept events, and can participate in a shared decision on how a given event should be handled. This becomes apparent when combining multiple frameworks on a page - if each framework implements its own event propagation model using global delegated listeners, important event handling concerns like default behavior prevention and retargeting can become difficult or even impossible.\n\n\n### Event delegation is not a better addEventListener\n\nThe tradeoff between direct binding and event delegation is hard to measure, which makes it difficult to clearly state which approach is better overall. As illustrated above, there are certainly cases where maintaining listeners across a set DOM nodes requires bookkeeping that incurs a performance penalty compared to event delegation. Using event delegation defers some of this cost so that it is paid as part of handling each event, which can be disadvantageous if event handling performance is paramount.\n\nOne generalization that can guide the decision between these approaches is that direct binding is generally a better option if the code in question already has a stable reference to the DOM node on which an event will be fired. These are cases with inherently minimal bookkeeping cost, since the lifecycle of an event handler does not need to be manually managed. As a rule of thumb, if you don’t have to search for a node in order to attach an event handler to it, it’s likely a good case for binding directly.\n\nOne concrete example of such a case is Preact’s event handler abstraction, which is often brought up when discussing the efficacy or delegated vs direct event handling. Preact’s renderer is already responsible for retaining a mirror tree in order to perform Virtual DOM diffing, which means there’s already [a clear place](https://github.com/preactjs/preact/blob/82bcc15638ce747b311c9bf1c6840b0640c75151/src/diff/props.js#L100-L109) to perform direct event handler binding during updates. To minimize any invocation cost associated with `addEventListener()` and `removeEventListener()`, a single proxy listener is registered for all events that looks up the current listener for a given event when it is fired. This means “swapping” an event handler to a new function reference only updates the current handler reference and does not remove or re-add any event listeners.\n\n\n### You don’t have to choose\n\nUltimately, it’s best not to treat event delegation and direct binding as dichotomous. Both techniques have merit, and there are many cases where a combined solution offers the best performance or least complexity.\n","html":"<div>  \n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1598628155/nasa-Q1p7bh3SHj8-unsplash_inzedd.jpg\">\n\n<figcaption style=\"position:relative;top:-1em;text-align:right;font-size:70%;\"><a href=\"https://unsplash.com/photos/Q1p7bh3SHj8\" target=\"_blank\" style=\"color:#999;text-decoration:none;\">Image courtesy of NASA</a></figcaption>  \n</div>\n\n<p>The DOM provides a mechanism for registering event handlers that supports two techniques for observing events: directly-bound per-element listeners, <em>and</em> “delegated” listeners that receive events originating from within an entire subtree.</p>\n\n<p>Frameworks and libraries that abstract event listener registration generally choose between the two approaches, yet this area of front-end performance has seen relatively limited debate. Library developers often rely on past experience to make decisions relating to event delegation vs direct binding, which I’ll try to summarize in this article.</p>\n\n<h3 id=\"directbinding\">Direct Binding</h3>\n\n<p>The oldest and simplest way to listen for DOM events is to register an event handler function directly on the node that will emit that event. Most DOM events propagate up the tree from their originating <code>target</code> Node, so this approach can be combined freely with delegation techniques (more on that later).</p>\n\n<p>Here’s a simple example of a directly bound event handler that intercepts clicks on a particular anchor link:</p>\n\n<pre><code class=\"language-html\">&lt;a href=\"/\" id=\"home\"&gt;Home&lt;/a&gt;  \n&lt;script&gt;  \n  home.addEventListener('click', e =&gt; {\n    const link = e.currentTarget;   // &lt;a&gt;\n    history.pushState(null, null, link.href);\n    fancyPageLoad(link.href);  // \"ajax\"\n    e.preventDefault();  // prevent page load\n    e.stopPropagation();\n  });\n&lt;/script&gt;  \n</code></pre>\n\n<p>In the example, direct binding is accomplished easily because we already have a reference to the element on which the click event will be triggered. This is a case where direct binding is also the best approach from a performance standpoint, since no DOM tree traversal is required to register or handle the event. Strictly looking at our own logic, registering and invoking the listener are both <code>O(1)</code> operations.</p>\n\n<h3 id=\"eventdelegation\">Event Delegation</h3>\n\n<p>Event delegation is a technique for listening for events in the aggregate. It leverages the fact that most events “bubble” up the DOM tree, which means they can be intercepted at the tree’s root and handled there.</p>\n\n<p>One of the key features that makes event delegation valuable is that it is possible to handle events from any target node <em>without</em> having a prior reference to that node. In cases where an event handler needs to listen on a large or changing set of target nodes, this avoids having to manually manage adding and removing handlers from each node. </p>\n\n<p>Imagine our previous link click handling example, except now there are many links on the page, and additional links may be added or removed over time:</p>\n\n<pre><code class=\"language-html\">&lt;a href=\"/\"&gt;Home&lt;/a&gt;  \n&lt;a href=\"/profile\"&gt;Profile&lt;/a&gt;  \n&lt;a href=\"/search\"&gt;Search&lt;/a&gt;  \n&lt;script&gt;  \n  function handleClick(e) {\n    history.pushState(null, null, this.href);\n    fancyPageLoad(this.href);\n    e.preventDefault();\n  }\n  for (let link of document.querySelectorAll('a[href]')) {\n    link.addEventListener('click', handleClick);\n  }\n  // ...listen for added/removed links using MutationObserver...\n&lt;/script&gt;  \n</code></pre>\n\n<p>Implementing this using direct binding requires searching the DOM for anchorlink elements and registering event handlers on each. We’d also need to use something like <code>MutationObserver</code> to detect newly-added links and register our handler on them. This would be expensive, since searching the DOM incurs a runtime performance cost and increases memory usage, as does <code>MutationObserver</code>. Listener invocation has the same performance as the previous simple direct binding example, but registration no longer runs in constant time.</p>\n\n<p>Let's compare this to a solution using event delegation:</p>\n\n<pre><code class=\"language-html\">&lt;a href=\"/\"&gt;Home&lt;/a&gt;  \n&lt;a href=\"/profile\"&gt;Profile&lt;/a&gt;  \n&lt;a href=\"/search\"&gt;Search&lt;/a&gt;  \n&lt;script&gt;  \n  addEventListener('click', e =&gt; {\n    let target = e.target;\n    do {\n      if (target.localName === 'a') {\n        history.pushState(null, null, target.href);\n        fancyPageLoad(target.href);\n        e.preventDefault();\n        break;\n      }\n    } while (target = target.parentNode);\n  });\n&lt;/script&gt;  \n</code></pre>\n\n<p>Now our example uses a single delegated event handler, which removes all event handler management costs. There is a small performance tradeoff being made here, which is that the handler has to walk up the DOM tree to detect if a click occurred on a link. In this case our logic for registering the listeners is <code>O(1)</code>, and the listener's invocation is <code>O(log(n))</code>.</p>\n\n<p>In many cases where there’s a very large number of event targets or where event targets are not known up-front, event delegation can improve performance by relying on the browser’s hit testing logic to dynamically observe events of a given type.</p>\n\n<h3 id=\"eventdelegationcanbetricky\">Event delegation can be tricky</h3>\n\n<p>It’s important to note that event delegation can create a set of problems not found when using directly-bound event handlers. Delegation can make event “pathing” difficult, and the effects of this are sometimes only revealed as a codebase increases in complexity. One example of this occurs when the DOM tree is mutated during the course of an event’s capturing or bubbling phase: should an event continue bubbling if its target or an ancestor is removed?</p>\n\n<p>A concrete example of where event pathing grows difficult is handling events from other documents in a fully delegated event handling model. An event triggered within an iframe does not bubble up to the parent document, which means it cannot be handled via delegation. This can be addressed by adding additional delegated event handlers in documents, which can either handle or retarget/refire the event in the parent document to emulate bubbling. While edge cases like these are not always important to account for, if they become necessary it can complicate event delegation and reduce its performance value.</p>\n\n<h3 id=\"missingoutonfeatures\">Missing out on features</h3>\n\n<p>For those exploring event delegation, it’s important to take note of some direct binding features that are more difficult or even impossible to leverage in a delegated model. In the past few years, the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener\">addEventListener API</a> has gained support for one-time handlers that are automatically removed after being fired, which can help avoid a class of memory leak caused by DOM references retained solely to allow for listener removal.</p>\n\n<p>Passive listeners are another addEventListener feature introduced somewhat recently, offering a way to listen for events without blocking user interaction when they occur. This is an important technique to have at your disposal when implementing things like touch and scroll reactivity. Browsers are actively moving towards firing passive events by default, however this is happening slowly and on a case-by-case basis due to a high potential for breaking the web. Until this transition is complete, it’s a good idea to make sure your solution for delegating events provides a way to register passive listeners - or even uses passive listeners by default.</p>\n\n<p>Another feature that event delegation implementations sometimes struggle with recreating is the level of optimization already present in browser event implementations. Events are created and initialized at the root of a document and their hit-tested event path is constructed in advance despite its JavaScript representation being lazily-constructed. The same Event object instance is passed to each handler invoked during the capturing and bubbling phases. Browsers engines can optimize garbage collection of Event instances, since they do not have to hold a strong reference to an event. It should be possible to approximate these optimizations in a JavaScript implementation using recently-added language features like <a href=\"https://v8.dev/features/weak-references\">WeakRef and Finalizers</a>, however it’s unlikely any popular solutions will leverage this for some time.</p>\n\n<p>Finally, one of the most compelling arguments in favor of directly binding event listeners rather than using global event delegation is interoperability. Event listeners registered directly on nodes are partaking in the DOM’s cooperative event handling model: every element and its listeners have a chance to observe or intercept events, and can participate in a shared decision on how a given event should be handled. This becomes apparent when combining multiple frameworks on a page - if each framework implements its own event propagation model using global delegated listeners, important event handling concerns like default behavior prevention and retargeting can become difficult or even impossible.</p>\n\n<h3 id=\"eventdelegationisnotabetteraddeventlistener\">Event delegation is not a better addEventListener</h3>\n\n<p>The tradeoff between direct binding and event delegation is hard to measure, which makes it difficult to clearly state which approach is better overall. As illustrated above, there are certainly cases where maintaining listeners across a set DOM nodes requires bookkeeping that incurs a performance penalty compared to event delegation. Using event delegation defers some of this cost so that it is paid as part of handling each event, which can be disadvantageous if event handling performance is paramount.</p>\n\n<p>One generalization that can guide the decision between these approaches is that direct binding is generally a better option if the code in question already has a stable reference to the DOM node on which an event will be fired. These are cases with inherently minimal bookkeeping cost, since the lifecycle of an event handler does not need to be manually managed. As a rule of thumb, if you don’t have to search for a node in order to attach an event handler to it, it’s likely a good case for binding directly.</p>\n\n<p>One concrete example of such a case is Preact’s event handler abstraction, which is often brought up when discussing the efficacy or delegated vs direct event handling. Preact’s renderer is already responsible for retaining a mirror tree in order to perform Virtual DOM diffing, which means there’s already <a href=\"https://github.com/preactjs/preact/blob/82bcc15638ce747b311c9bf1c6840b0640c75151/src/diff/props.js#L100-L109\">a clear place</a> to perform direct event handler binding during updates. To minimize any invocation cost associated with <code>addEventListener()</code> and <code>removeEventListener()</code>, a single proxy listener is registered for all events that looks up the current listener for a given event when it is fired. This means “swapping” an event handler to a new function reference only updates the current handler reference and does not remove or re-add any event listeners.</p>\n\n<h3 id=\"youdonthavetochoose\">You don’t have to choose</h3>\n\n<p>Ultimately, it’s best not to treat event delegation and direct binding as dichotomous. Both techniques have merit, and there are many cases where a combined solution offers the best performance or least complexity.</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2020-08-28T13:59:33.023Z","created_by":1,"updated_at":"2020-08-28T15:00:15.942Z","updated_by":1,"published_at":"2020-08-28T15:00:15.947Z","published_by":1},{"id":16,"uuid":"997ef92f-4d8a-45c0-bf50-58249bf6c7e2","title":"Enabling Modern JavaScript on npm","slug":"enabling-modern-js-on-npm","markdown":"> Modern JavaScript syntax lets you do more with less code, but how much of the JavaScript we ship to users is actually modern?\n\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559234852/code-screenshot_1_zkday3.jpg\" width=\"400\" style=\"opacity:0.8; border-radius:10px;\">\n\nFor the past few years we’ve been writing modern JavaScript (or [TypeScript](https://www.typescriptlang.org/)), which is then transpiled to ES5 as a build step. This has let the “state of the art” of JavaScript move forward at a faster pace than could have otherwise been achieved while supporting older browsers.\n\nMore recently, developers have adopted differential bundling techniques where two or more distinct sets of JavaScript files are produced to target different environments.  The most common example of this is the [module/nomodule pattern](https://philipwalton.com/articles/deploying-es2015-code-in-production-today/), which leverages native JS Modules (also known as \"ES Modules\") support as its “cutting the mustard” test: modules-supporting browsers request modern JavaScript (~[ES2017](https://www.ecma-international.org/ecma-262/8.0/index.html)), and older browsers request the more heavily polyfilled and transpiled legacy bundles. Compiling for the set of browsers defined by their JS Modules support is made relatively straightforward courtesy of the [targets.esmodules](https://babeljs.io/docs/en/babel-preset-env#targetsesmodules) option in [@babel/preset-env](https://babeljs.io/docs/en/babel-preset-env), and [Webpack](https://webpack.js.org/) plugins like [babel-esm-plugin](https://github.com/prateekbh/babel-esm-plugin#readme) make producing two sets of JavaScript bundles mostly painless.\n\nGiven the above, where are all the blog posts and case-studies showing the glorious performance and bundle size benefits that have been achieved using this technique? It turns out, shipping modern JavaScript requires more than changing our build targets.\n\n\n## It’s not our code\n\nCurrent solutions for producing paired modern & legacy bundles focus solely on “authored code” - the code we write that implements an application. These solutions can’t currently help with the code we install from sources like npm - that’s a problem, since [some sources](https://youtu.be/-xZHWK-vHbQ?t=2064) place the ratio of installed code to authored code is somewhere in the ballpark of 10:1. While this ratio will clearly be different for every project, we've consistently found that the JavaScript shipped to users contains a high amount of installed code. Even walking this estimate back, there are clear indications that the ecosystem favors installing existing modules over authoring new one-off modules.\n\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559231502/authored_vs_installed_ev2szc.png\" width=\"400\">\n\nIn many ways this represents a triumph for Open Source: developers are able to build on the communal value of shared code and collaborate on generalized solutions to their problems in a public forum.\n\n<p style=\"max-width:10em; margin:10px; padding:20px; background:#333; color:white; font:140%/1.2 serif; text-align:center; float:right;\">&ldquo;the dependencies we install from npm are stuck in 2014&rdquo;</p>\n\nAs it turns out, this amazing ecosystem also holds the most important missing piece of our modern JavaScript puzzle: **the dependencies we install from npm are stuck in 2014.**\n\n<br style=\"clear:both;\">\n\n## “Just JavaScript”\n\nThe modules we publish to npm are “JavaScript”, but that’s where any expectation of uniformity ends. Front-end developers consuming JavaScript from npm near universally expect that JavaScript to run “in a browser”. Given the diverse set of browsers we need to support, we end up in a situation where modules need to support the Lowest Common Denominator from their consumers’ browser support targets. The eventuality that played out means we have come to explicitly depend on all code in `node_modules` being ECMAScript 5. In some very rare cases, developers use bolted-on solutions to detect non-ES5 modules and preprocess them down to their desired output target (here’s [a hacky approach](https://gist.github.com/developit/081148d83348ebe9a1bc1ba0707e1bb8) you shouldn’t use). As a community, the backwards compatibility of each new ECMAScript version has allowed us to largely ignore the effect this has had on our applications, despite an ever-widening gap between the syntax we write and the syntax found in most of our favorite npm dependencies.\n\nThis has led to a general acceptance that npm modules should be transpiled before they are published to the registry. The publishing process for authors generally involves bundling source modules to multiple formats: JS Modules, CommonJS and UMD. Module authors sometimes denote these different bundles using a set of unofficial fields in a module’s package.json, where `\"module\"` points to an `.mjs` file, `\"unpkg\"` points to the UMD bundle, and `\"main\"` is still left to reference a CommonJS file.\n\n```json\n{\n  \"main\": \"dist/es5-commonjs.js\",\n  \"module\": \"dist/es5-modules.mjs\",\n  \"unpkg\": \"dist/es5-umd.js\"\n}\n```\n\nAll of these formats affect only a module’s interface - its imports and exports - and this lead to an unfortunate consensus among developers and tooling that even modern JS Modules should be transpiled to a library’s lowest support target. It has been suggested that package authors could begin allowing modern JavaScript syntax in the entry module denoted in their package.json via the `module` field. Unfortunately, this approach is incompatible with today’s tooling - more specifically, it’s incompatible with the way we’ve all configured our tooling. These configurations are different for every project, which makes this a massive undertaking since the tools themselves are not what needs to be changed. Instead, the changes would need to be made in each and every application’s build configuration.\n\nThe reason these constraints hold firm is in large part due to popular bundlers like Webpack and Rollup shipping without a default behavior for whether JavaScript imported from `node_modules` should be processed. These tools can be easily configured to treat `node_modules` the same as authored code, but their documentation [consistently recommends](https://webpack.js.org/loaders/babel-loader/#usage) developers [disable Babel transpilation](https://github.com/rollup/rollup-plugin-babel#usage) for `node_modules`. This recommendation is generally given citing build performance improvements, even though the slower build produces better results for end users. This makes any in-place changes to the semantics of importing code from `node_modules` exceptionally difficult to propagate through the ecosystem, since the tools don’t actually control what gets transpiled and how. This control rests in the hands of application developers, which means the problem is decentralized.\n\n\n## The module author’s perspective\n\nThe authors of our favorite npm modules are also involved. At present, there are five main reasons why module authors end up being forced to transpile their JavaScript before publishing it to npm:\n\n\n1. We know app developers aren’t transpiling `node_modules` to match their support targets.\n2. We can’t rely on app developers to set up sufficient minification and optimization.\n3. Library size must be measured in bundled+minified+gzipped bytes to be realistic.\n4. There is still a widespread expectation that npm modules are delivered as ECMAScript 5.\n5. Increasing a module’s JS version requirement means the code is unavailable to some users.\n\nWhen combined, these reasons make it virtually impossible for the author of a popular module to move to modern JavaScript by default. Put yourself in the shoes of a module author: would you be willing to publish only modern syntax, knowing the resulting update would break builds or production deploys for the majority of your users?\n\nThe npm ecosystem’s current state and inability to bifurcate classic vs modern JavaScript publishing is what holds us back from collectively embracing JS Modules and ES20xx.\n\n\n### Module authoring tools hurt, too\n\nJust like with application bundlers being configurable without an implied default behaviour for `node_modules`, changing the module authoring landscape is an unfortunately distributed problem. Since most module authors tend to roll their own build tooling as requirements vary from project to project, there isn’t really a set of canonical tools to which changes could be made. [Microbundle](https://github.com/developit/microbundle) has been gaining traction as a shared solution, and [@pika/pack](https://www.pikapkg.com/blog/introducing-pika-pack/) recently launched with similar goals to optimize the format in which modules are published to npm. Unfortunately, these tools still have a long way to go before being considered widespread.\n\nAssuming a group of solutions like Microbundle, Pika and Angular’s [library bundler](https://angular.io/cli/generate#library) could be influenced, it may be possible to shift the ecosystem using popular modules as an example. An effort on this scale would be likely to encounter some resistance from module consumers, since many are not yet aware of the limitations their bundling strategies impose. However, these upended expectations are the very shift our community needs.\n\n\n## Looking Forward\n\nIt’s not all doom and gloom. While Webpack and Rollup encourage unprocessed npm module usage only through their documentation, Browserify actually [disables all transforms](https://github.com/babel/babelify#why-arent-files-in-node_modules-being-transformed) within `node_modules` by default. That means Browserify could be modified to produce modern/legacy bundles automatically, without requiring every single application developer to change their build configuration. Similarly, opinionated tools built atop Webpack and Rollup provide a few centralized places where we could make changes that bring modern JS to `node_modules`. If we made these changes within [Next.js](https://nextjs.org/), [Create React App](https://facebook.github.io/create-react-app/docs/getting-started), [Angular CLI](https://cli.angular.io/), [Vue CLI](https://cli.vuejs.org/) and [Preact CLI](https://github.com/developit/preact-cli), the resulting build configurations would eventually make their way out to a decent fraction of applications using those tools.\n\nLooking to the vast majority of build systems for JavaScript applications that are one-off or customized per-project, there is no central place to modify them. One option we could consider as a way to slowly move the community to Modern JS-friendly configurations would be to modify Webpack to show warnings when JavaScript resources imported from `node_modules` are left unprocessed. Babel [announced some new features](https://babeljs.io/blog/2018/06/26/on-consuming-and-publishing-es2015+-packages) last year that allow selective transpiling of `node_modules`, and Create React App recently started transpiling `node_modules` using a conservative configuration. Similarly, tools could be created for inspecting our bundled JavaScript to see how much of it is shipped as over-polyfilled or inefficient legacy syntax.\n\n\n## The last piece\n\nLet’s assume we could build automation and guidance into our tools, and that doing so would eventually move the thousands (millions?) of applications using those tools over to configurations that allow modern syntax to be used within `node_modules`. In order for this to have any effect, we need to come up with a consistent way for package authors to specify the location of their modern JS source, and also get consensus on what “modern” means in that context. For a package published 3 years ago, “modern” could have meant ES2015. For a package published today, would “modern” include [class fields](https://developers.google.com/web/updates/2018/12/class-fields), [BigInt](https://developers.google.com/web/updates/2018/05/bigint) or [Dynamic Import](https://developers.google.com/web/updates/2017/11/dynamic-import)? It’s hard to say, since browser support and specification stage vary.\n\nThis comes to a head when we consider the effect on differential bundling. For those not familiar, Differential Bundling refers to a setup that lets us write modern JavaScript, then build separate sets of output bundles targeting different environments. In the most popular usage, we have a set of bundles targeting newer browsers that contains ~ES2015 syntax, and then a “legacy” set of bundles for all other browsers that is transpiled down to ES5 and polyfilled.\n\n<img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559231328/modern_legacy_transpile_qbvkdd.png\" width=\"1000\" alt=\"Diagram showing multiple JavaScript source files being bundled into separate sets of JavaScript files: one for modern browsers, and another for all other browsers.\">\n\nThe problem is that, if we assume “modern” to mean “anything newer than ES5”, it becomes impossible to determine what syntax a package contains that needs to be transpiled in order to meet a given browser support target. We can address this problem by establishing a way for packages to express the specific set of syntax features they rely on, however this still requires maintaining many variant configurations to handle each set of input→output syntax pairs:\n\n<style>\n.syntax-table {\n  font-size: 80%;\n}\n</style>\n\n<table class=\"syntax-table\">\n  <tr>\n   <td><strong>Package Syntax</strong>\n   </td>\n   <td><strong>Output Target</strong>\n   </td>\n   <td><strong>Example “Downleveling” Transformations</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>ES5\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES5\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2015 (classes)\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2015 (classes)\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2017 (async/await)\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>async/await, classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2017 (async/await)\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2019\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>rest/spread, for-await, async/await, classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2019\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>rest/spread & for-await\n   </td>\n  </tr>\n</table>\n\n\n## What would you do?\n\nOver-transpiled JavaScript is an increasing fraction of the code we ship to end users, impacting initial load time and overall runtime performance of the web. We believe this is a problem needing a solution – a solution module authors _and_ consumers can agree upon. The problem space is relatively small, but there are many interested parties with unique constraints.\n\nWe’re looking to the community for help. What would you suggest to remediate this problem for the entire ecosystem of Open Source JavaScript? We want to hear from you, work with you, and help solve this problem in a scalable way for new syntax revisions. Reach out us on Twitter: [_developit](https://twitter.com/_developit), [kristoferbaxter](https://twitter.com/kristoferbaxter) and [nomadtechie](https://twitter.com/nomadtechie) are all eager to discuss.","html":"<blockquote>\n  <p>Modern JavaScript syntax lets you do more with less code, but how much of the JavaScript we ship to users is actually modern?</p>\n</blockquote>\n\n<p><img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559234852/code-screenshot_1_zkday3.jpg\" width=\"400\" style=\"opacity:0.8; border-radius:10px;\"></p>\n\n<p>For the past few years we’ve been writing modern JavaScript (or <a href=\"https://www.typescriptlang.org/\">TypeScript</a>), which is then transpiled to ES5 as a build step. This has let the “state of the art” of JavaScript move forward at a faster pace than could have otherwise been achieved while supporting older browsers.</p>\n\n<p>More recently, developers have adopted differential bundling techniques where two or more distinct sets of JavaScript files are produced to target different environments.  The most common example of this is the <a href=\"https://philipwalton.com/articles/deploying-es2015-code-in-production-today/\">module/nomodule pattern</a>, which leverages native JS Modules (also known as \"ES Modules\") support as its “cutting the mustard” test: modules-supporting browsers request modern JavaScript (~<a href=\"https://www.ecma-international.org/ecma-262/8.0/index.html\">ES2017</a>), and older browsers request the more heavily polyfilled and transpiled legacy bundles. Compiling for the set of browsers defined by their JS Modules support is made relatively straightforward courtesy of the <a href=\"https://babeljs.io/docs/en/babel-preset-env#targetsesmodules\">targets.esmodules</a> option in <a href=\"https://babeljs.io/docs/en/babel-preset-env\">@babel/preset-env</a>, and <a href=\"https://webpack.js.org/\">Webpack</a> plugins like <a href=\"https://github.com/prateekbh/babel-esm-plugin#readme\">babel-esm-plugin</a> make producing two sets of JavaScript bundles mostly painless.</p>\n\n<p>Given the above, where are all the blog posts and case-studies showing the glorious performance and bundle size benefits that have been achieved using this technique? It turns out, shipping modern JavaScript requires more than changing our build targets.</p>\n\n<h2 id=\"itsnotourcode\">It’s not our code</h2>\n\n<p>Current solutions for producing paired modern &amp; legacy bundles focus solely on “authored code” - the code we write that implements an application. These solutions can’t currently help with the code we install from sources like npm - that’s a problem, since <a href=\"https://youtu.be/-xZHWK-vHbQ?t=2064\">some sources</a> place the ratio of installed code to authored code is somewhere in the ballpark of 10:1. While this ratio will clearly be different for every project, we've consistently found that the JavaScript shipped to users contains a high amount of installed code. Even walking this estimate back, there are clear indications that the ecosystem favors installing existing modules over authoring new one-off modules.</p>\n\n<p><img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559231502/authored_vs_installed_ev2szc.png\" width=\"400\"></p>\n\n<p>In many ways this represents a triumph for Open Source: developers are able to build on the communal value of shared code and collaborate on generalized solutions to their problems in a public forum.</p>\n\n<p style=\"max-width:10em; margin:10px; padding:20px; background:#333; color:white; font:140%/1.2 serif; text-align:center; float:right;\">&ldquo;the dependencies we install from npm are stuck in 2014&rdquo;</p>\n\n<p>As it turns out, this amazing ecosystem also holds the most important missing piece of our modern JavaScript puzzle: <strong>the dependencies we install from npm are stuck in 2014.</strong></p>\n\n<p><br style=\"clear:both;\"></p>\n\n<h2 id=\"justjavascript\">“Just JavaScript”</h2>\n\n<p>The modules we publish to npm are “JavaScript”, but that’s where any expectation of uniformity ends. Front-end developers consuming JavaScript from npm near universally expect that JavaScript to run “in a browser”. Given the diverse set of browsers we need to support, we end up in a situation where modules need to support the Lowest Common Denominator from their consumers’ browser support targets. The eventuality that played out means we have come to explicitly depend on all code in <code>node_modules</code> being ECMAScript 5. In some very rare cases, developers use bolted-on solutions to detect non-ES5 modules and preprocess them down to their desired output target (here’s <a href=\"https://gist.github.com/developit/081148d83348ebe9a1bc1ba0707e1bb8\">a hacky approach</a> you shouldn’t use). As a community, the backwards compatibility of each new ECMAScript version has allowed us to largely ignore the effect this has had on our applications, despite an ever-widening gap between the syntax we write and the syntax found in most of our favorite npm dependencies.</p>\n\n<p>This has led to a general acceptance that npm modules should be transpiled before they are published to the registry. The publishing process for authors generally involves bundling source modules to multiple formats: JS Modules, CommonJS and UMD. Module authors sometimes denote these different bundles using a set of unofficial fields in a module’s package.json, where <code>\"module\"</code> points to an <code>.mjs</code> file, <code>\"unpkg\"</code> points to the UMD bundle, and <code>\"main\"</code> is still left to reference a CommonJS file.</p>\n\n<pre><code class=\"language-json\">{\n  \"main\": \"dist/es5-commonjs.js\",\n  \"module\": \"dist/es5-modules.mjs\",\n  \"unpkg\": \"dist/es5-umd.js\"\n}\n</code></pre>\n\n<p>All of these formats affect only a module’s interface - its imports and exports - and this lead to an unfortunate consensus among developers and tooling that even modern JS Modules should be transpiled to a library’s lowest support target. It has been suggested that package authors could begin allowing modern JavaScript syntax in the entry module denoted in their package.json via the <code>module</code> field. Unfortunately, this approach is incompatible with today’s tooling - more specifically, it’s incompatible with the way we’ve all configured our tooling. These configurations are different for every project, which makes this a massive undertaking since the tools themselves are not what needs to be changed. Instead, the changes would need to be made in each and every application’s build configuration.</p>\n\n<p>The reason these constraints hold firm is in large part due to popular bundlers like Webpack and Rollup shipping without a default behavior for whether JavaScript imported from <code>node_modules</code> should be processed. These tools can be easily configured to treat <code>node_modules</code> the same as authored code, but their documentation <a href=\"https://webpack.js.org/loaders/babel-loader/#usage\">consistently recommends</a> developers <a href=\"https://github.com/rollup/rollup-plugin-babel#usage\">disable Babel transpilation</a> for <code>node_modules</code>. This recommendation is generally given citing build performance improvements, even though the slower build produces better results for end users. This makes any in-place changes to the semantics of importing code from <code>node_modules</code> exceptionally difficult to propagate through the ecosystem, since the tools don’t actually control what gets transpiled and how. This control rests in the hands of application developers, which means the problem is decentralized.</p>\n\n<h2 id=\"themoduleauthorsperspective\">The module author’s perspective</h2>\n\n<p>The authors of our favorite npm modules are also involved. At present, there are five main reasons why module authors end up being forced to transpile their JavaScript before publishing it to npm:</p>\n\n<ol>\n<li>We know app developers aren’t transpiling <code>node_modules</code> to match their support targets.  </li>\n<li>We can’t rely on app developers to set up sufficient minification and optimization.  </li>\n<li>Library size must be measured in bundled+minified+gzipped bytes to be realistic.  </li>\n<li>There is still a widespread expectation that npm modules are delivered as ECMAScript 5.  </li>\n<li>Increasing a module’s JS version requirement means the code is unavailable to some users.</li>\n</ol>\n\n<p>When combined, these reasons make it virtually impossible for the author of a popular module to move to modern JavaScript by default. Put yourself in the shoes of a module author: would you be willing to publish only modern syntax, knowing the resulting update would break builds or production deploys for the majority of your users?</p>\n\n<p>The npm ecosystem’s current state and inability to bifurcate classic vs modern JavaScript publishing is what holds us back from collectively embracing JS Modules and ES20xx.</p>\n\n<h3 id=\"moduleauthoringtoolshurttoo\">Module authoring tools hurt, too</h3>\n\n<p>Just like with application bundlers being configurable without an implied default behaviour for <code>node_modules</code>, changing the module authoring landscape is an unfortunately distributed problem. Since most module authors tend to roll their own build tooling as requirements vary from project to project, there isn’t really a set of canonical tools to which changes could be made. <a href=\"https://github.com/developit/microbundle\">Microbundle</a> has been gaining traction as a shared solution, and <a href=\"https://www.pikapkg.com/blog/introducing-pika-pack/\">@pika/pack</a> recently launched with similar goals to optimize the format in which modules are published to npm. Unfortunately, these tools still have a long way to go before being considered widespread.</p>\n\n<p>Assuming a group of solutions like Microbundle, Pika and Angular’s <a href=\"https://angular.io/cli/generate#library\">library bundler</a> could be influenced, it may be possible to shift the ecosystem using popular modules as an example. An effort on this scale would be likely to encounter some resistance from module consumers, since many are not yet aware of the limitations their bundling strategies impose. However, these upended expectations are the very shift our community needs.</p>\n\n<h2 id=\"lookingforward\">Looking Forward</h2>\n\n<p>It’s not all doom and gloom. While Webpack and Rollup encourage unprocessed npm module usage only through their documentation, Browserify actually <a href=\"https://github.com/babel/babelify#why-arent-files-in-node_modules-being-transformed\">disables all transforms</a> within <code>node_modules</code> by default. That means Browserify could be modified to produce modern/legacy bundles automatically, without requiring every single application developer to change their build configuration. Similarly, opinionated tools built atop Webpack and Rollup provide a few centralized places where we could make changes that bring modern JS to <code>node_modules</code>. If we made these changes within <a href=\"https://nextjs.org/\">Next.js</a>, <a href=\"https://facebook.github.io/create-react-app/docs/getting-started\">Create React App</a>, <a href=\"https://cli.angular.io/\">Angular CLI</a>, <a href=\"https://cli.vuejs.org/\">Vue CLI</a> and <a href=\"https://github.com/developit/preact-cli\">Preact CLI</a>, the resulting build configurations would eventually make their way out to a decent fraction of applications using those tools.</p>\n\n<p>Looking to the vast majority of build systems for JavaScript applications that are one-off or customized per-project, there is no central place to modify them. One option we could consider as a way to slowly move the community to Modern JS-friendly configurations would be to modify Webpack to show warnings when JavaScript resources imported from <code>node_modules</code> are left unprocessed. Babel <a href=\"https://babeljs.io/blog/2018/06/26/on-consuming-and-publishing-es2015+-packages\">announced some new features</a> last year that allow selective transpiling of <code>node_modules</code>, and Create React App recently started transpiling <code>node_modules</code> using a conservative configuration. Similarly, tools could be created for inspecting our bundled JavaScript to see how much of it is shipped as over-polyfilled or inefficient legacy syntax.</p>\n\n<h2 id=\"thelastpiece\">The last piece</h2>\n\n<p>Let’s assume we could build automation and guidance into our tools, and that doing so would eventually move the thousands (millions?) of applications using those tools over to configurations that allow modern syntax to be used within <code>node_modules</code>. In order for this to have any effect, we need to come up with a consistent way for package authors to specify the location of their modern JS source, and also get consensus on what “modern” means in that context. For a package published 3 years ago, “modern” could have meant ES2015. For a package published today, would “modern” include <a href=\"https://developers.google.com/web/updates/2018/12/class-fields\">class fields</a>, <a href=\"https://developers.google.com/web/updates/2018/05/bigint\">BigInt</a> or <a href=\"https://developers.google.com/web/updates/2017/11/dynamic-import\">Dynamic Import</a>? It’s hard to say, since browser support and specification stage vary.</p>\n\n<p>This comes to a head when we consider the effect on differential bundling. For those not familiar, Differential Bundling refers to a setup that lets us write modern JavaScript, then build separate sets of output bundles targeting different environments. In the most popular usage, we have a set of bundles targeting newer browsers that contains ~ES2015 syntax, and then a “legacy” set of bundles for all other browsers that is transpiled down to ES5 and polyfilled.</p>\n\n<p><img src=\"https://res.cloudinary.com/wedding-website/image/upload/v1559231328/modern_legacy_transpile_qbvkdd.png\" width=\"1000\" alt=\"Diagram showing multiple JavaScript source files being bundled into separate sets of JavaScript files: one for modern browsers, and another for all other browsers.\"></p>\n\n<p>The problem is that, if we assume “modern” to mean “anything newer than ES5”, it becomes impossible to determine what syntax a package contains that needs to be transpiled in order to meet a given browser support target. We can address this problem by establishing a way for packages to express the specific set of syntax features they rely on, however this still requires maintaining many variant configurations to handle each set of input→output syntax pairs:</p>\n\n<style>  \n.syntax-table {\n  font-size: 80%;\n}\n</style>\n\n<table class=\"syntax-table\">  \n  <tr>\n   <td><strong>Package Syntax</strong>\n   </td>\n   <td><strong>Output Target</strong>\n   </td>\n   <td><strong>Example “Downleveling” Transformations</strong>\n   </td>\n  </tr>\n  <tr>\n   <td>ES5\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES5\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2015 (classes)\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2015 (classes)\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2017 (async/await)\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>async/await, classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2017 (async/await)\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>none\n   </td>\n  </tr>\n  <tr>\n   <td>ES2019\n   </td>\n   <td>ES5 / nomodule\n   </td>\n   <td>rest/spread, for-await, async/await, classes & tagged templates\n   </td>\n  </tr>\n  <tr>\n   <td>ES2019\n   </td>\n   <td><code>&lt;script type=module&gt;</code>\n   </td>\n   <td>rest/spread & for-await\n   </td>\n  </tr>\n</table>\n\n<h2 id=\"whatwouldyoudo\">What would you do?</h2>\n\n<p>Over-transpiled JavaScript is an increasing fraction of the code we ship to end users, impacting initial load time and overall runtime performance of the web. We believe this is a problem needing a solution – a solution module authors <em>and</em> consumers can agree upon. The problem space is relatively small, but there are many interested parties with unique constraints.</p>\n\n<p>We’re looking to the community for help. What would you suggest to remediate this problem for the entire ecosystem of Open Source JavaScript? We want to hear from you, work with you, and help solve this problem in a scalable way for new syntax revisions. Reach out us on Twitter: <a href=\"https://twitter.com/_developit\">_developit</a>, <a href=\"https://twitter.com/kristoferbaxter\">kristoferbaxter</a> and <a href=\"https://twitter.com/nomadtechie\">nomadtechie</a> are all eager to discuss.</p>","image":null,"featured":true,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":"Modern JavaScript syntax lets you do more with less code, but how much of the JavaScript we ship to users is actually modern?","author_id":1,"created_at":"2019-05-30T15:26:55.754Z","created_by":1,"updated_at":"2019-05-31T14:37:00.431Z","updated_by":1,"published_at":"2019-05-30T16:26:20.387Z","published_by":1},{"id":9,"uuid":"cd96183b-d93a-42fd-9288-fdf094107800","title":"UMD is Dead! Long Live UMD!","slug":"umd-is-dead-long-live-umd","markdown":"In the front-end world, we've been publishing modules as UMD (Universal Module Definition) for quite some time - at least [6 years](https://github.com/umdjs/umd/commit/d0657cb76bdef3e6f267895a20fb18181a0d3d58). That's a longevity we don't often see in this industry, and we owe the proponents and upholders of the UMD spec a debt of gratitude.\n\nThe UMD format has served the community well - it's the lingua franca of modules, and has generally enabled us to ignore format interoperability as module consumers.  Given that the value provided by UMD is clear, we should collectively spend a bit of time evaluating options for modernizing UMD in order to adapt to the next set of technologies being adopted.\n\nES Modules are here, and with them we've accepted a definitive syntax for expressing dependencies - `import` and `export`.  The community is now rallying around this syntax, and exploring new solutions like `import()` that account for dynamic dependencies.\n\nSince these new features can never be made to work with UMD, I would like to propose we modernize the UMD format by removing support for <abbr title=\"Asynchronous Module Definition\">AMD</abbr>.\n\nWhy remove AMD? Partly to encourage the emergence of new solutions that better interoperate with ES Modules (default imports in particular), and party to keep the UMD format consistent with its original goal:\n\n> \"Modules which can work anywhere, be that on the client, on the server or anywhere else.\n>\n> [..] compatibility with the most popular script loaders of the day.\"\n\nAMD is no longer a popular format, making it a likely distant fourth contender to ES Modules, CommonJS and globals.  The problems AMD solves have been moved elsewhere - typically into the realm of module bundlers like Webpack and Rollup.  Instead of asynchronous loading as a feature of our chosen module formats, it's an implementation detail of our chosen bundler.\n\nHere's what UMD looks like today:\n\n```js\n(function (root, factory) {\n  if (typeof define === 'function' && define.amd) {\n    define([], factory);\n  } else if (typeof module === 'object') {\n    module.exports = factory();\n  } else {\n    root.greatLibrary = factory();\n  }\n}(this, function () {\n  var exports = {};\n  return exports;\n}));\n```\n\nHere's what I'm proposing we run with moving forward for the general case:\n\n```js\n(function (root, factory) {\n  if (typeof module === 'object') {\n    module.exports = factory();\n  } else {\n    root.greatLibrary = factory();\n  }\n}(this, function () {\n  var exports = {};\n  return exports;\n}));\n```\n\nAt 137b (minified & gzipped), we're down to a fairly decent size for this little wrapper - however, this is just the start.\n\nHere's an optimized version for modules that contain a single function - a common case. Often modules are just a single export of something like a factory function, which means they don't need the wrapper function to encapsulate module-level variables.  For these, we can cut the size nearly in half:\n\n```js\n// this is already a global in the browser!\nfunction myGreatLibrary() {\n  // does great things here\n}\n// attempt to export for CommonJS\ntry { module.exports = myGreatLibrary; } catch (e) {}\n```\n\nThe above code is 79 bytes when minified and gzipped - that's not very much overhead at all!  It's important to note that the above case is not well-suited to modules with dependencies, since it doesn't differentiate between global and CommonJS uses.  For modules with dependencies, use the first proposed format.\n\n### Via Rollup\n\nHere's an example rollup configuration that uses [rollup-plugin-memory](https://github.com/TrySound/rollup-plugin-memory) to produce a bundle set up similarly to the above:\n\n```js\nimport memory from 'rollup-plugin-memory';\n\n// OR: require('./package.json').name\nconst NAME = 'preact';\n\nexport default {\n  entry: 'src/entry.js',\n  useStrict: false,\n  // wrap everything in a function:\n  format: 'iife',\n  plugins: [\n    // inject our bundle logic around the real entry:\n    memory({\n      path: 'src/entry.js',\n      contents: `\n        import lib from './index';\n        if (typeof module!='undefined') module.exports = lib;\n        else self.${NAME} = lib;\n      `\n    })\n  ]\n}\n```\n\nYou can tweak the configuration to suit your library's particular set up. For example, if you export a single wrapper function, you might set `format` to `es` (ES Modules), but then use `memory` to export nothing, instead using the optimized option from above:\n\n```js\ncontents: `\n  import myFunction from './index';\n  try { module.exports = myFunction; } catch (e) {}\n`\n```\n\n---\n\nSo, we've dropped AMD from the mix here. Despite that, because CommonJS and globals are supported our bundle will still load perfectly via Webpack, a `<script>` tag, `importScripts` `rollup-plugin-commonjs`, etc.  For Webpack 2 and Rollup itself we're producing these <abbr title=\"New Module Definition\">NMD</abbr> using ES Modules, so these bundled libraries don't even get used.\n\nI think this would be a nice change to see in the modules we all rely on. Do you?","html":"<p>In the front-end world, we've been publishing modules as UMD (Universal Module Definition) for quite some time - at least <a href=\"https://github.com/umdjs/umd/commit/d0657cb76bdef3e6f267895a20fb18181a0d3d58\">6 years</a>. That's a longevity we don't often see in this industry, and we owe the proponents and upholders of the UMD spec a debt of gratitude.</p>\n\n<p>The UMD format has served the community well - it's the lingua franca of modules, and has generally enabled us to ignore format interoperability as module consumers.  Given that the value provided by UMD is clear, we should collectively spend a bit of time evaluating options for modernizing UMD in order to adapt to the next set of technologies being adopted.</p>\n\n<p>ES Modules are here, and with them we've accepted a definitive syntax for expressing dependencies - <code>import</code> and <code>export</code>.  The community is now rallying around this syntax, and exploring new solutions like <code>import()</code> that account for dynamic dependencies.</p>\n\n<p>Since these new features can never be made to work with UMD, I would like to propose we modernize the UMD format by removing support for <abbr title=\"Asynchronous Module Definition\">AMD</abbr>.</p>\n\n<p>Why remove AMD? Partly to encourage the emergence of new solutions that better interoperate with ES Modules (default imports in particular), and party to keep the UMD format consistent with its original goal:</p>\n\n<blockquote>\n  <p>\"Modules which can work anywhere, be that on the client, on the server or anywhere else.</p>\n  \n  <p>[..] compatibility with the most popular script loaders of the day.\"</p>\n</blockquote>\n\n<p>AMD is no longer a popular format, making it a likely distant fourth contender to ES Modules, CommonJS and globals.  The problems AMD solves have been moved elsewhere - typically into the realm of module bundlers like Webpack and Rollup.  Instead of asynchronous loading as a feature of our chosen module formats, it's an implementation detail of our chosen bundler.</p>\n\n<p>Here's what UMD looks like today:</p>\n\n<pre><code class=\"language-js\">(function (root, factory) {\n  if (typeof define === 'function' &amp;&amp; define.amd) {\n    define([], factory);\n  } else if (typeof module === 'object') {\n    module.exports = factory();\n  } else {\n    root.greatLibrary = factory();\n  }\n}(this, function () {\n  var exports = {};\n  return exports;\n}));\n</code></pre>\n\n<p>Here's what I'm proposing we run with moving forward for the general case:</p>\n\n<pre><code class=\"language-js\">(function (root, factory) {\n  if (typeof module === 'object') {\n    module.exports = factory();\n  } else {\n    root.greatLibrary = factory();\n  }\n}(this, function () {\n  var exports = {};\n  return exports;\n}));\n</code></pre>\n\n<p>At 137b (minified &amp; gzipped), we're down to a fairly decent size for this little wrapper - however, this is just the start.</p>\n\n<p>Here's an optimized version for modules that contain a single function - a common case. Often modules are just a single export of something like a factory function, which means they don't need the wrapper function to encapsulate module-level variables.  For these, we can cut the size nearly in half:</p>\n\n<pre><code class=\"language-js\">// this is already a global in the browser!\nfunction myGreatLibrary() {  \n  // does great things here\n}\n// attempt to export for CommonJS\ntry { module.exports = myGreatLibrary; } catch (e) {}  \n</code></pre>\n\n<p>The above code is 79 bytes when minified and gzipped - that's not very much overhead at all!  It's important to note that the above case is not well-suited to modules with dependencies, since it doesn't differentiate between global and CommonJS uses.  For modules with dependencies, use the first proposed format.</p>\n\n<h3 id=\"viarollup\">Via Rollup</h3>\n\n<p>Here's an example rollup configuration that uses <a href=\"https://github.com/TrySound/rollup-plugin-memory\">rollup-plugin-memory</a> to produce a bundle set up similarly to the above:</p>\n\n<pre><code class=\"language-js\">import memory from 'rollup-plugin-memory';\n\n// OR: require('./package.json').name\nconst NAME = 'preact';\n\nexport default {  \n  entry: 'src/entry.js',\n  useStrict: false,\n  // wrap everything in a function:\n  format: 'iife',\n  plugins: [\n    // inject our bundle logic around the real entry:\n    memory({\n      path: 'src/entry.js',\n      contents: `\n        import lib from './index';\n        if (typeof module!='undefined') module.exports = lib;\n        else self.${NAME} = lib;\n      `\n    })\n  ]\n}\n</code></pre>\n\n<p>You can tweak the configuration to suit your library's particular set up. For example, if you export a single wrapper function, you might set <code>format</code> to <code>es</code> (ES Modules), but then use <code>memory</code> to export nothing, instead using the optimized option from above:</p>\n\n<pre><code class=\"language-js\">contents: `  \n  import myFunction from './index';\n  try { module.exports = myFunction; } catch (e) {}\n`\n</code></pre>\n\n<hr />\n\n<p>So, we've dropped AMD from the mix here. Despite that, because CommonJS and globals are supported our bundle will still load perfectly via Webpack, a <code>&lt;script&gt;</code> tag, <code>importScripts</code> <code>rollup-plugin-commonjs</code>, etc.  For Webpack 2 and Rollup itself we're producing these <abbr title=\"New Module Definition\">NMD</abbr> using ES Modules, so these bundled libraries don't even get used.</p>\n\n<p>I think this would be a nice change to see in the modules we all rely on. Do you?</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-03-21T22:57:25.426Z","created_by":1,"updated_at":"2019-02-17T20:13:18.215Z","updated_by":1,"published_at":"2017-03-22T02:56:21.272Z","published_by":1},{"id":22,"uuid":"0c2ce66f-63d4-4634-b3e5-fd88f9433619","title":"Element Worklet","slug":"element-worklet","markdown":"I've been contemplating ways to build more resilient web applications. One consistent issue that seems to crop up in my explorations is that we have no way to execute JavaScript at a given priority.\n\nWe can write asynchronous code, but this doesn't provide a general-purpose resiliency primitive.\n\n#### Un-yield-y\n\nIt is possible to write code that \"yields\" to allow other code to execute. Writing everything as async functions can accomplish this in specific cases, though only promise chains can be interrupted and it lacks any form of scheduling. This technique relies entirely on authors writing code to be interruptible, explicitly indicating where interruption may occur.\n\nIn addition to being opt-in, code that uses async/await, Promises or callbacks is still largely synchronous. The code between each point of asynchrony (await, Promise, callback) can't be interrupted. The following example function can only yield in a single location, the remaining code executes synchronously:\n\n```js\nasync function amazing() {\n  let items = [];\n  let seen = new Set();\n  for (let i=0; i<1000; i++) {\n    let item = await db.get(i);\n            // ^ yielding can only occur here\n    if (!seen.has(item.name)) {\n      seen.add(item.name);\n      items.push(item);\n    }\n  }\n  return items;\n}\n```\n\nCombined with the fact that most JavaScript doesn't use async/await or even Promises, makes it insufficient as a general-purpose resiliency primitive. **Most of the JavaScript executed by browsers is synchronous.**\n\n#### Why yield?\n\nThere is no language or platform feature that allows for interrupting arbitrary synchronous work in order to prioritize other work. There are a few reasons why we might want such a feature, but the one I find most compelling is to apply resiliency paradigms to _existing_ web code. Effectively, we want the ability to interrupt code wasn't written to be interrupted in order to allocate more time to executing high-priority code.\n\n```js\nfunction veryGoodCode() {\n  const start = Date.now();\n  while (Date.now() - start < 1000) {} // 🧐\n  generateRevenue(); // 💸\n}\n```\n\nThe code we run from npm modules, third-party embeds and ads is all given access to the same pool of computing power as an application's core functionality. Multi-process improvements in the browser like [out-of-process iframes](https://www.chromium.org/developers/design-documents/oop-iframes) address this for certain types of content embedded from other origins, which can mitigate the performance impact of things like ads. Unfortunately, we don't have a similar solution for our own applications.\n\nApplications are usually composed out of many distinct parts, but each part currently has the ability to impact the performance of all other parts. **We are missing a platform primitive for composing JavaScript modules while imposing performance constraints**.\n\n# Proposal: Element Worklet\n\nI drafted a proposal a while back and shared to various browser engineers, called [Element Worklet](https://github.com/developit/element-worklet). The proposal uses the existing concept of a [Worklet](https://developer.mozilla.org/en-US/docs/Web/API/Worklet), which is a standalone ECMAScript Module that executes in an isolated environment. This isolation means Worklets can be executed wherever is most suitable: Audio Worklets run on the audio rendering thread, Paint Worklets run on the compositor thread.\n\nElement Worklets are a new type of Worklet that can register Custom Elements. The code for an Element Worklet has access to a limited subset of the DOM API, which allows code to register one or more Custom Elements using the standard `customElements.define()` method. Custom Elements registered by a worklet must inherit from a global `WorkletElement` class, and are only able to render into their Shadow DOM (as well as being able to set their own attributes).\n\nCustom Elements registered by an Element Worklet are called \"worklet-backed elements\". These can be used on the main thread like any standard Custom Element, and can also be referenced from within the Shadow DOM of other worklet-backed elements, enabling arbitrary composition.\n\n#### Example\n\nThe following example shows how a `<code-editor>` element can be built as an Element Worklet. Doing so encapsulates the code editor implementation so that its performance is not impacted by the surrounding page. It also ensures the page's performance is not impacted by the editor.\n\nFirst, an HTML page includes the `<code-editor>` element in its markup the same as it would for a Custom Element. Then, a `code-editor.js` worklet module script is loaded using `addModule()`:\n\n<div class=\"code-title\"><code>index.html</code></div>\n\n```html\n<code-editor value=\"function foo(){}\"></code-editor>\n\n<script>\n  customElements.addModule('/code-editor.js');\n</script>\n```\n\nThe `code-editor.js` module is loaded in a new JavaScript context, separate from the page and its JavaScript. The module declares a Custom Element class that extends `WorkletElement`, and uses the `connectedCallback()` lifecycle method to instantiate [CodeMirror](https://codemirror.net) within its Shadow DOM. The element also observes \"value\" attribute changes to update the editor text. Finally, the Custom Element is registered via `customElements.define()`.\n\n<div class=\"code-title\"><code>code-editor.js</code></div>\n\n```js\nimport CodeMirror from 'https://unumd.glitch.me/codemirror';\n\nclass CodeEditor extends WorkletElement {\n  static get observedAttributes() {\n    return ['value'];\n  }\n\n  connectedCallback() {\n    const shadow = this.attachShadow({ mode: 'closed' });\n\n    this.editor = CodeMirror(shadow, {\n      value: this.getAttribute('value')\n    });\n  }\n\n  attributeChangedCallback(name, prev, value) {\n    if (name === 'value') this.editor.setValue(value);\n  }\n}\n\ncustomElements.define('code-editor', CodeEditor);\n```\n\nOnce the worklet module has finished executing and `customElements.define()` is called, the `code-editor` element is upgraded on the main thread.\n\n#### Data Sharing\n\nCustom Element properties set from the main thread are not reflected on a `WorkletElement`, only attributes. Attribute changes are observed the same as they are in Custom Elements, declared via a static `observedAttributes` property on the element's constructor. Attribute changes changes invoke `attributeChangedCallback()` on the WorkletElement instance, and may be batched.\n\nComplex data and transferrables can also be shared. The main thread and worklet instances of a WorkletElement each have a `port` property, which are ports of an MessageChannel specific to that instance, and can be used for message passing. This is similar to how `processor.port` is provided by audio worklet's AudioWorkletNode/AudioWorkletProcessor.\n\n#### Use Cases\n\n**Ads:** Advertisements currently use iframes for encapsulation, a technique of increasing cost as the effects of Spectre mitigations make their way into browsers. Element Worklet could provide a lightweight alternative to iframes for this use-case.\n\n**Third Party Embeds:** Embedded content like comment widgets, chats and helpdesks all of these currently use some combination of same-origin scripting and iframes, usually mixing origins (eg: a script in the embedder context communicating with an iframe from the embedee's context). Moving from `<script>` + `<iframe>` to Element Worklet seems like a reasonable fit for this case.\n\n**AMP:** The semantics defined in this proposal map reasonably well to `<amp-script>`, and a prototype of Element Worklet has been built using [worker-dom](https://github.com/ampproject/worker-dom), the library that underpins `<amp-script>`. AMP's approach is much more broadly applicable than Element Worklet, seeking to support arbitrary third-party code running in a sandboxed DOM environment. However, it's possible a solution like worker-dom would be able to leverage something like Element Worklet to simplify Element registration and upgrades, and to mitigate transfer overhead between threads.\n\n**Lazy Loading:** Component-based frameworks and libraries strive to provide solutions for lazily downloading, instantiating and rendering portions of an application. This process is entirely implemented in userland, which has the unfortunate side effect of making it invisible to the browser. In certain scenarios, it may be possible to use Element Worklet as the underly mechanism for lazily loading and rendering pieces of a component-based User Interface.\n\n**UI Component Libraries:** If this model can be shown to provide performance guarantees for Element registration, upgrade and rendering, it's possible a UI library would choose to provide their components as worklet-backed Elements through the use of one or more Element Worklets. This could have interesting implications for performance, since it would provide a way to impose performance guarantees. This is a safety net developers do not currently have for prebuilt modules. The (large) portions of a typical app that are defined by code installed from npm would have less ability to negatively impact the performance of first-party code.\n\n#### Feasibility\n\nThe hard part with such a broad proposal like this is making it something that would be feasible to implement. Part of the design of Element Worklet is aimed at avoiding implementation issues, like the use of a minimal DOM subset and exclusively asynchronous interaction between threads.\n\nAs part of investigating whether Element Worklet could be implemented at all, I've created an [Element Worklet prototype](#prototype). The prototype also demonstrates how Element Worklet could be used to control the performance impact of UI components, in addition to insulating their performance from the page.\n\n#### Open Questions\n\nThis proposal glosses over a some details that would be important were it to be implemented in a browser:\n\n- What DOM APIs should be available to Element Worklet code? Can `WorkletElement` provide a sufficient API surface to allow current libraries and approaches to be reused with minimal modification?\n\n- How would a Worklet obtain information that required the main thread to perform layout? (we need `async getBoundingClientRect()` and friends!)\n\n- Is the level of encapsulation too limiting? Does it fail to meet the needs of the most obvious use-cases like embedded video players?\n\n- Should Element Worklet provide an analog for Custom Element property getters/setters? Could custom properties/methods defined on a WorkletElement subclass be reflected asynchronously on the main thread in the style of Comlink? This seems important for handling complex data types without attribute serialization schemes.\n\n- Would it be possible to accept a \"priority\" option during Element Worklet registration? This would unlock a host of use-cases in which worklet code could be considered untrusted from a performance standpoint. The same option would be valuable when instantiating Web Workers.\n\n#### Prototype\n\nI have created a prototype implementation of Element Worklet using [worker-dom](https://github.com/ampproject/worker-dom/). The video below shows a page with two Element Worklets registered. One of the worklets intentionally executes long-running JavaScript that destroys performance. However, because each Element Worklet is executed on its own thread, only instances of the poor-performing worklet are affected. The page and the other worklets (in blue) remain responsive.\n\n<video playsinline autoplay controls loop width=\"960\" height=\"1028\" loading=\"lazy\" style=\"max-width:100%; height:auto; margin:auto; background:#ddd; border:5px solid #ddd; box-sizing:border-box;\">\n<source type=\"video/mp4\" src=\"https://i.imgur.com/MYIogxs.mp4\">\n</video>\n\nIn the second half of the video, both worklets are transformed by a Service Worker that injects execution tracking around every expression. When a worklet spends too long executing JS without yielding, its thread [is put to sleep](/javascript-sleep). This pauses execution of the slow worklet, limiting its performance impact and preserving more resources for the page and other worklets.\n\nThis demonstrates the proposed \"priority\" option for Element Worklet registration, which limits the performance impact of elements backed by a given worklet. In the demo, this results in a 10x reduction in CPU usage measured by Task Manager, from around 70% to just 7%.\n\n<center><h4>\n\n[try the Element Worklet prototype](https://element-worklet.glitch.me/) on Glitch →\n\n</h4></center>\n\n<center><h4>\n\n[view the spec proposal](https://github.com/developit/element-worklet) on GitHub →\n\n</h4></center>\n\n<br>\n\n<style>\n  .code-title {\n    margin-bottom:-.8em;\n  }\n  .code-title code {\n    font-weight: bold;\n    padding: .2em 1em;\n    border: none;\n    background: #E3EDF3;\n    color: #434D53;\n    border-radius: 3px 3px 3px 0;\n  }\n</style>","html":"<p>I've been contemplating ways to build more resilient web applications. One consistent issue that seems to crop up in my explorations is that we have no way to execute JavaScript at a given priority.</p>\n\n<p>We can write asynchronous code, but this doesn't provide a general-purpose resiliency primitive.</p>\n\n<h4 id=\"unyieldy\">Un-yield-y</h4>\n\n<p>It is possible to write code that \"yields\" to allow other code to execute. Writing everything as async functions can accomplish this in specific cases, though only promise chains can be interrupted and it lacks any form of scheduling. This technique relies entirely on authors writing code to be interruptible, explicitly indicating where interruption may occur.</p>\n\n<p>In addition to being opt-in, code that uses async/await, Promises or callbacks is still largely synchronous. The code between each point of asynchrony (await, Promise, callback) can't be interrupted. The following example function can only yield in a single location, the remaining code executes synchronously:</p>\n\n<pre><code class=\"language-js\">async function amazing() {  \n  let items = [];\n  let seen = new Set();\n  for (let i=0; i&lt;1000; i++) {\n    let item = await db.get(i);\n            // ^ yielding can only occur here\n    if (!seen.has(item.name)) {\n      seen.add(item.name);\n      items.push(item);\n    }\n  }\n  return items;\n}\n</code></pre>\n\n<p>Combined with the fact that most JavaScript doesn't use async/await or even Promises, makes it insufficient as a general-purpose resiliency primitive. <strong>Most of the JavaScript executed by browsers is synchronous.</strong></p>\n\n<h4 id=\"whyyield\">Why yield?</h4>\n\n<p>There is no language or platform feature that allows for interrupting arbitrary synchronous work in order to prioritize other work. There are a few reasons why we might want such a feature, but the one I find most compelling is to apply resiliency paradigms to <em>existing</em> web code. Effectively, we want the ability to interrupt code wasn't written to be interrupted in order to allocate more time to executing high-priority code.</p>\n\n<pre><code class=\"language-js\">function veryGoodCode() {  \n  const start = Date.now();\n  while (Date.now() - start &lt; 1000) {} // 🧐\n  generateRevenue(); // 💸\n}\n</code></pre>\n\n<p>The code we run from npm modules, third-party embeds and ads is all given access to the same pool of computing power as an application's core functionality. Multi-process improvements in the browser like <a href=\"https://www.chromium.org/developers/design-documents/oop-iframes\">out-of-process iframes</a> address this for certain types of content embedded from other origins, which can mitigate the performance impact of things like ads. Unfortunately, we don't have a similar solution for our own applications.</p>\n\n<p>Applications are usually composed out of many distinct parts, but each part currently has the ability to impact the performance of all other parts. <strong>We are missing a platform primitive for composing JavaScript modules while imposing performance constraints</strong>.</p>\n\n<h1 id=\"proposalelementworklet\">Proposal: Element Worklet</h1>\n\n<p>I drafted a proposal a while back and shared to various browser engineers, called <a href=\"https://github.com/developit/element-worklet\">Element Worklet</a>. The proposal uses the existing concept of a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Worklet\">Worklet</a>, which is a standalone ECMAScript Module that executes in an isolated environment. This isolation means Worklets can be executed wherever is most suitable: Audio Worklets run on the audio rendering thread, Paint Worklets run on the compositor thread.</p>\n\n<p>Element Worklets are a new type of Worklet that can register Custom Elements. The code for an Element Worklet has access to a limited subset of the DOM API, which allows code to register one or more Custom Elements using the standard <code>customElements.define()</code> method. Custom Elements registered by a worklet must inherit from a global <code>WorkletElement</code> class, and are only able to render into their Shadow DOM (as well as being able to set their own attributes).</p>\n\n<p>Custom Elements registered by an Element Worklet are called \"worklet-backed elements\". These can be used on the main thread like any standard Custom Element, and can also be referenced from within the Shadow DOM of other worklet-backed elements, enabling arbitrary composition.</p>\n\n<h4 id=\"example\">Example</h4>\n\n<p>The following example shows how a <code>&lt;code-editor&gt;</code> element can be built as an Element Worklet. Doing so encapsulates the code editor implementation so that its performance is not impacted by the surrounding page. It also ensures the page's performance is not impacted by the editor.</p>\n\n<p>First, an HTML page includes the <code>&lt;code-editor&gt;</code> element in its markup the same as it would for a Custom Element. Then, a <code>code-editor.js</code> worklet module script is loaded using <code>addModule()</code>:</p>\n\n<div class=\"code-title\"><code>index.html</code></div>\n\n<pre><code class=\"language-html\">&lt;code-editor value=\"function foo(){}\"&gt;&lt;/code-editor&gt;\n\n&lt;script&gt;  \n  customElements.addModule('/code-editor.js');\n&lt;/script&gt;  \n</code></pre>\n\n<p>The <code>code-editor.js</code> module is loaded in a new JavaScript context, separate from the page and its JavaScript. The module declares a Custom Element class that extends <code>WorkletElement</code>, and uses the <code>connectedCallback()</code> lifecycle method to instantiate <a href=\"https://codemirror.net\">CodeMirror</a> within its Shadow DOM. The element also observes \"value\" attribute changes to update the editor text. Finally, the Custom Element is registered via <code>customElements.define()</code>.</p>\n\n<div class=\"code-title\"><code>code-editor.js</code></div>\n\n<pre><code class=\"language-js\">import CodeMirror from 'https://unumd.glitch.me/codemirror';\n\nclass CodeEditor extends WorkletElement {  \n  static get observedAttributes() {\n    return ['value'];\n  }\n\n  connectedCallback() {\n    const shadow = this.attachShadow({ mode: 'closed' });\n\n    this.editor = CodeMirror(shadow, {\n      value: this.getAttribute('value')\n    });\n  }\n\n  attributeChangedCallback(name, prev, value) {\n    if (name === 'value') this.editor.setValue(value);\n  }\n}\n\ncustomElements.define('code-editor', CodeEditor);  \n</code></pre>\n\n<p>Once the worklet module has finished executing and <code>customElements.define()</code> is called, the <code>code-editor</code> element is upgraded on the main thread.</p>\n\n<h4 id=\"datasharing\">Data Sharing</h4>\n\n<p>Custom Element properties set from the main thread are not reflected on a <code>WorkletElement</code>, only attributes. Attribute changes are observed the same as they are in Custom Elements, declared via a static <code>observedAttributes</code> property on the element's constructor. Attribute changes changes invoke <code>attributeChangedCallback()</code> on the WorkletElement instance, and may be batched.</p>\n\n<p>Complex data and transferrables can also be shared. The main thread and worklet instances of a WorkletElement each have a <code>port</code> property, which are ports of an MessageChannel specific to that instance, and can be used for message passing. This is similar to how <code>processor.port</code> is provided by audio worklet's AudioWorkletNode/AudioWorkletProcessor.</p>\n\n<h4 id=\"usecases\">Use Cases</h4>\n\n<p><strong>Ads:</strong> Advertisements currently use iframes for encapsulation, a technique of increasing cost as the effects of Spectre mitigations make their way into browsers. Element Worklet could provide a lightweight alternative to iframes for this use-case.</p>\n\n<p><strong>Third Party Embeds:</strong> Embedded content like comment widgets, chats and helpdesks all of these currently use some combination of same-origin scripting and iframes, usually mixing origins (eg: a script in the embedder context communicating with an iframe from the embedee's context). Moving from <code>&lt;script&gt;</code> + <code>&lt;iframe&gt;</code> to Element Worklet seems like a reasonable fit for this case.</p>\n\n<p><strong>AMP:</strong> The semantics defined in this proposal map reasonably well to <code>&lt;amp-script&gt;</code>, and a prototype of Element Worklet has been built using <a href=\"https://github.com/ampproject/worker-dom\">worker-dom</a>, the library that underpins <code>&lt;amp-script&gt;</code>. AMP's approach is much more broadly applicable than Element Worklet, seeking to support arbitrary third-party code running in a sandboxed DOM environment. However, it's possible a solution like worker-dom would be able to leverage something like Element Worklet to simplify Element registration and upgrades, and to mitigate transfer overhead between threads.</p>\n\n<p><strong>Lazy Loading:</strong> Component-based frameworks and libraries strive to provide solutions for lazily downloading, instantiating and rendering portions of an application. This process is entirely implemented in userland, which has the unfortunate side effect of making it invisible to the browser. In certain scenarios, it may be possible to use Element Worklet as the underly mechanism for lazily loading and rendering pieces of a component-based User Interface.</p>\n\n<p><strong>UI Component Libraries:</strong> If this model can be shown to provide performance guarantees for Element registration, upgrade and rendering, it's possible a UI library would choose to provide their components as worklet-backed Elements through the use of one or more Element Worklets. This could have interesting implications for performance, since it would provide a way to impose performance guarantees. This is a safety net developers do not currently have for prebuilt modules. The (large) portions of a typical app that are defined by code installed from npm would have less ability to negatively impact the performance of first-party code.</p>\n\n<h4 id=\"feasibility\">Feasibility</h4>\n\n<p>The hard part with such a broad proposal like this is making it something that would be feasible to implement. Part of the design of Element Worklet is aimed at avoiding implementation issues, like the use of a minimal DOM subset and exclusively asynchronous interaction between threads.</p>\n\n<p>As part of investigating whether Element Worklet could be implemented at all, I've created an <a href=\"#prototype\">Element Worklet prototype</a>. The prototype also demonstrates how Element Worklet could be used to control the performance impact of UI components, in addition to insulating their performance from the page.</p>\n\n<h4 id=\"openquestions\">Open Questions</h4>\n\n<p>This proposal glosses over a some details that would be important were it to be implemented in a browser:</p>\n\n<ul>\n<li><p>What DOM APIs should be available to Element Worklet code? Can <code>WorkletElement</code> provide a sufficient API surface to allow current libraries and approaches to be reused with minimal modification?</p></li>\n<li><p>How would a Worklet obtain information that required the main thread to perform layout? (we need <code>async getBoundingClientRect()</code> and friends!)</p></li>\n<li><p>Is the level of encapsulation too limiting? Does it fail to meet the needs of the most obvious use-cases like embedded video players?</p></li>\n<li><p>Should Element Worklet provide an analog for Custom Element property getters/setters? Could custom properties/methods defined on a WorkletElement subclass be reflected asynchronously on the main thread in the style of Comlink? This seems important for handling complex data types without attribute serialization schemes.</p></li>\n<li><p>Would it be possible to accept a \"priority\" option during Element Worklet registration? This would unlock a host of use-cases in which worklet code could be considered untrusted from a performance standpoint. The same option would be valuable when instantiating Web Workers.</p></li>\n</ul>\n\n<h4 id=\"prototype\">Prototype</h4>\n\n<p>I have created a prototype implementation of Element Worklet using <a href=\"https://github.com/ampproject/worker-dom/\">worker-dom</a>. The video below shows a page with two Element Worklets registered. One of the worklets intentionally executes long-running JavaScript that destroys performance. However, because each Element Worklet is executed on its own thread, only instances of the poor-performing worklet are affected. The page and the other worklets (in blue) remain responsive.</p>\n\n<video playsinline autoplay controls loop width=\"960\" height=\"1028\" loading=\"lazy\" style=\"max-width:100%; height:auto; margin:auto; background:#ddd; border:5px solid #ddd; box-sizing:border-box;\">  \n<source type=\"video/mp4\" src=\"https://i.imgur.com/MYIogxs.mp4\">  \n</video>\n\n<p>In the second half of the video, both worklets are transformed by a Service Worker that injects execution tracking around every expression. When a worklet spends too long executing JS without yielding, its thread <a href=\"/javascript-sleep\">is put to sleep</a>. This pauses execution of the slow worklet, limiting its performance impact and preserving more resources for the page and other worklets.</p>\n\n<p>This demonstrates the proposed \"priority\" option for Element Worklet registration, which limits the performance impact of elements backed by a given worklet. In the demo, this results in a 10x reduction in CPU usage measured by Task Manager, from around 70% to just 7%.</p>\n\n<p><center><h4></p>\n\n<p><a href=\"https://element-worklet.glitch.me/\">try the Element Worklet prototype</a> on Glitch →</p>\n\n<p></h4></center></p>\n\n<p><center><h4></p>\n\n<p><a href=\"https://github.com/developit/element-worklet\">view the spec proposal</a> on GitHub →</p>\n\n<p></h4></center></p>\n\n<p><br></p>\n\n<style>  \n  .code-title {\n    margin-bottom:-.8em;\n  }\n  .code-title code {\n    font-weight: bold;\n    padding: .2em 1em;\n    border: none;\n    background: #E3EDF3;\n    color: #434D53;\n    border-radius: 3px 3px 3px 0;\n  }\n</style>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2021-01-14T22:30:25.282Z","created_by":1,"updated_at":"2021-01-20T17:46:33.214Z","updated_by":1,"published_at":"2021-01-20T17:46:33.220Z","published_by":1},{"id":21,"uuid":"29a2a782-c2e3-4f13-8be6-e440fd0a6b3f","title":"Real sleep() in JavaScript","slug":"javascript-sleep","markdown":"The JavaScript language is single-threaded, which means that blocking that single thread for any period of time will prevent importing things like input handling and rendering. \n\n...but about blocking the thread when that thread is a [Web Worker](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers)?\n\nIt's possible to implement [sleep()](https://en.wikipedia.org/wiki/Sleep_(system_call)) in JavaScript. A naive implementation of sleep() might look like this:\n\n```js\nfunction sleep(t) {\n  const start = Date.now();\n  while (Date.now() - start < t);\n}\n```\n\nThis solution has an obvious problem: even if we do want to block a thread for a period of time, doing so using a loop will consume all of the CPU time available to the thread. For a Web Worker, that's generally going to be 100% of one of your machine's cores. The goal with `sleep()` is generally to pause our code for a period of time, but this naive implementation actually causes our code to take as much time as possible - the opposite of what we need!\n\n#### XMLHttpRequest, old friend\n\nFortunately, there is another way to block a thread from JavaScript in the browser: synchronous XMLHttpRequest. Like a long-running `while()` loop, Synchronous XMLHttpRrequest blocks the thread and has a [uniquely negative impact on performance and UX](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Synchronous_and_Asynchronous_Requests#synchronous_request). However, a Web Worker isn't a UI thread though, and there are cases where being able to \"pause\" a worker thread is genuinely useful. One that I'm particularly interested in is imposing resource limitations on modules.\n\nWe can use Synchronous XMLHttpRequest to pause JavaScript execution while waiting on a network resource. Requesting a URL thousands of times isn't ideal though, and since `sleep(t)` accepts a duration in milliseconds it's important to be able to \"unpause\" the thread after that amount of time has passed. One way to \"unpause\" is to set the `.timeout` property of the Synchronous XMLHttpRequest to our delay:\n\n```js\nfunction sleep(t) {\n  const xhr = new XMLHttpRequest();\n  xhr.timeout = Math.max(t, 10);\n  xhr.open('GET', '/some-url-that-loads-forever', false);\n  try {\n    xhr.send();  // ignore the timeout error\n  } catch (e) {}\n}\n```\n\nIf the URL requested above happens to return a response before we reach the timeout though, our `sleep()` function won't sleep long enough. We could use a loop to continually re-request the resource until we reach the specified sleep duration, but this solution would result in a potentially massive number of network requests. Deploying this in production would be a good way to DDoS whichever web server or CDN happens to be the target of those requests - not something I'd recommend! Thankfully, there's a way to intercept requests made by JavaScript - Service Worker.\n\n##### Service Worker to prevent DDoS\n\nA Service Worker could intercept the network requests made from our `sleep()` function's Synchronous XMLHttpRequest calls, preventing them from ever making their way out to the internet. Even more useful, the Service Worker can wait for a specific amount of time before returning an empty response for those network calls, which means we don't have to issue multiple requests in order to reach a given `sleep(t)` delay. Here's a Service Worker that does just that:\n\n```js\n// activate immediately:\naddEventListener('install', () => self.skipWaiting());\naddEventListener('activate', () => self.clients.claim());\n\naddEventListener('fetch', e => {\n  // we only handle requests to a special /SLEEP url:\n  const url = new URL(e.request.url);\n  if (url.pathname !== '/SLEEP') return;\n\n  // wait ?t=X milliseconds, then return a 304:\n  e.respondWith(new Promise(resolve => {\n    const t = new URLSearchParams(u.search).get('t');\n    const response = new Response(null, {status:304});\n    setTimeout(resolve, t, response);\n  }));\n});\n```\n\nOnce registered by calling `navigator.serviceWorker.register('/sw.js')`, the Service Worker will begin intercepting requests to a special `/SLEEP?t=0` URL. All we have to do is modify the `sleep()` function to request that URL with the correct duration:\n\n```js\nfunction sleep(t) {\n  t = Math.max(10, t);\n  const xhr = new XMLHttpRequest();\n  xhr.timeout = t;\n  x.open('GET', `/SLEEP?t=${t}`, false);\n  try{ x.send(); } catch(e) {}\n}\n```\n\n### Even better: `Atomics.wait()`\n\nAs pointed out by my astute co-workers [Derek](https://twitter.com/derekschuff) and [Shu](https://twitter.com/_shu), the somewhat recent JavaScript addition `Atomics.wait()` implements an optimized `sleep()` solution while waiting for a value to be changed within a `SharedArrayBuffer`. We can use this in a Worker thread to implement sleep _extremely_ effectively, without any Synchronous network requests or a Service Worker:\n\n```js\nconst AB = new Int32Array(new SharedArrayBuffer(4));\nfunction sleep(t) {\n  Atomics.wait(AB, 0, 0, Math.max(1, t|0));\n}\n```\n\n### Seeing it work\n\nGreat! Now we can use `sleep(500)` to pause a Web Worker for 500ms, without increased CPU usage:\n\n<video playsinline autoplay controls loop width=\"720\" height=\"562\" style=\"max-width:100%; height:auto; margin:auto; background:#ddd; border:5px solid #ddd; box-sizing:border-box;\">\n<source type=\"video/mp4\" src=\"https://i.imgur.com/vkQ3kC5.mp4\">\n</video>\n\n<center><h4>\n\nInterested? [Try the demo for yourself on Glitch](https://sleep-sw.glitch.me/).\n\n</h4></center>\n\n<br>\n","html":"<p>The JavaScript language is single-threaded, which means that blocking that single thread for any period of time will prevent importing things like input handling and rendering. </p>\n\n<p>...but about blocking the thread when that thread is a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\">Web Worker</a>?</p>\n\n<p>It's possible to implement <a href=\"https://en.wikipedia.org/wiki/Sleep_(system_call)\">sleep()</a> in JavaScript. A naive implementation of sleep() might look like this:</p>\n\n<pre><code class=\"language-js\">function sleep(t) {  \n  const start = Date.now();\n  while (Date.now() - start &lt; t);\n}\n</code></pre>\n\n<p>This solution has an obvious problem: even if we do want to block a thread for a period of time, doing so using a loop will consume all of the CPU time available to the thread. For a Web Worker, that's generally going to be 100% of one of your machine's cores. The goal with <code>sleep()</code> is generally to pause our code for a period of time, but this naive implementation actually causes our code to take as much time as possible - the opposite of what we need!</p>\n\n<h4 id=\"xmlhttprequestoldfriend\">XMLHttpRequest, old friend</h4>\n\n<p>Fortunately, there is another way to block a thread from JavaScript in the browser: synchronous XMLHttpRequest. Like a long-running <code>while()</code> loop, Synchronous XMLHttpRrequest blocks the thread and has a <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Synchronous_and_Asynchronous_Requests#synchronous_request\">uniquely negative impact on performance and UX</a>. However, a Web Worker isn't a UI thread though, and there are cases where being able to \"pause\" a worker thread is genuinely useful. One that I'm particularly interested in is imposing resource limitations on modules.</p>\n\n<p>We can use Synchronous XMLHttpRequest to pause JavaScript execution while waiting on a network resource. Requesting a URL thousands of times isn't ideal though, and since <code>sleep(t)</code> accepts a duration in milliseconds it's important to be able to \"unpause\" the thread after that amount of time has passed. One way to \"unpause\" is to set the <code>.timeout</code> property of the Synchronous XMLHttpRequest to our delay:</p>\n\n<pre><code class=\"language-js\">function sleep(t) {  \n  const xhr = new XMLHttpRequest();\n  xhr.timeout = Math.max(t, 10);\n  xhr.open('GET', '/some-url-that-loads-forever', false);\n  try {\n    xhr.send();  // ignore the timeout error\n  } catch (e) {}\n}\n</code></pre>\n\n<p>If the URL requested above happens to return a response before we reach the timeout though, our <code>sleep()</code> function won't sleep long enough. We could use a loop to continually re-request the resource until we reach the specified sleep duration, but this solution would result in a potentially massive number of network requests. Deploying this in production would be a good way to DDoS whichever web server or CDN happens to be the target of those requests - not something I'd recommend! Thankfully, there's a way to intercept requests made by JavaScript - Service Worker.</p>\n\n<h5 id=\"serviceworkertopreventddos\">Service Worker to prevent DDoS</h5>\n\n<p>A Service Worker could intercept the network requests made from our <code>sleep()</code> function's Synchronous XMLHttpRequest calls, preventing them from ever making their way out to the internet. Even more useful, the Service Worker can wait for a specific amount of time before returning an empty response for those network calls, which means we don't have to issue multiple requests in order to reach a given <code>sleep(t)</code> delay. Here's a Service Worker that does just that:</p>\n\n<pre><code class=\"language-js\">// activate immediately:\naddEventListener('install', () =&gt; self.skipWaiting());  \naddEventListener('activate', () =&gt; self.clients.claim());\n\naddEventListener('fetch', e =&gt; {  \n  // we only handle requests to a special /SLEEP url:\n  const url = new URL(e.request.url);\n  if (url.pathname !== '/SLEEP') return;\n\n  // wait ?t=X milliseconds, then return a 304:\n  e.respondWith(new Promise(resolve =&gt; {\n    const t = new URLSearchParams(u.search).get('t');\n    const response = new Response(null, {status:304});\n    setTimeout(resolve, t, response);\n  }));\n});\n</code></pre>\n\n<p>Once registered by calling <code>navigator.serviceWorker.register('/sw.js')</code>, the Service Worker will begin intercepting requests to a special <code>/SLEEP?t=0</code> URL. All we have to do is modify the <code>sleep()</code> function to request that URL with the correct duration:</p>\n\n<pre><code class=\"language-js\">function sleep(t) {  \n  t = Math.max(10, t);\n  const xhr = new XMLHttpRequest();\n  xhr.timeout = t;\n  x.open('GET', `/SLEEP?t=${t}`, false);\n  try{ x.send(); } catch(e) {}\n}\n</code></pre>\n\n<h3 id=\"evenbetteratomicswait\">Even better: <code>Atomics.wait()</code></h3>\n\n<p>As pointed out by my astute co-workers <a href=\"https://twitter.com/derekschuff\">Derek</a> and <a href=\"https://twitter.com/_shu\">Shu</a>, the somewhat recent JavaScript addition <code>Atomics.wait()</code> implements an optimized <code>sleep()</code> solution while waiting for a value to be changed within a <code>SharedArrayBuffer</code>. We can use this in a Worker thread to implement sleep <em>extremely</em> effectively, without any Synchronous network requests or a Service Worker:</p>\n\n<pre><code class=\"language-js\">const AB = new Int32Array(new SharedArrayBuffer(4));  \nfunction sleep(t) {  \n  Atomics.wait(AB, 0, 0, Math.max(1, t|0));\n}\n</code></pre>\n\n<h3 id=\"seeingitwork\">Seeing it work</h3>\n\n<p>Great! Now we can use <code>sleep(500)</code> to pause a Web Worker for 500ms, without increased CPU usage:</p>\n\n<video playsinline autoplay controls loop width=\"720\" height=\"562\" style=\"max-width:100%; height:auto; margin:auto; background:#ddd; border:5px solid #ddd; box-sizing:border-box;\">  \n<source type=\"video/mp4\" src=\"https://i.imgur.com/vkQ3kC5.mp4\">  \n</video>\n\n<p><center><h4></p>\n\n<p>Interested? <a href=\"https://sleep-sw.glitch.me/\">Try the demo for yourself on Glitch</a>.</p>\n\n<p></h4></center></p>\n\n<p><br></p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2021-01-14T20:49:08.762Z","created_by":1,"updated_at":"2021-01-15T17:26:45.702Z","updated_by":1,"published_at":"2021-01-15T17:22:33.351Z","published_by":1},{"id":11,"uuid":"bd5c88d0-52a3-480a-b250-ef8863af9333","title":"Preact AMA on Sideway","slug":"preact-ama-on-sideway","markdown":"> 🎤 This was originally published as [**\"Preact.js with Jason Miller\"**](https://sideway.com/room/aY) on Sideway.\n\n---\n\n[Preact](https://preactjs.com) is a **fast 3kB** alternative to React with the same API, providing the thinnest possible Virtual DOM abstraction on top of the DOM.\n\nIn this conversation, Preact's author [Jason Miller](https://twitter.com/_developit) discusses the project goals, progress, the relationship with the larger React community, and his plans for the future.\n\n---\n\n> What's the Preact origin story? How did it come to be?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Preact started out as a way for me to learn how React worked internally.  I've always felt a little uncomfortable using things without fully understanding their internals, so I needed to code out a basic version of a DOM diff algorithm in order to grasp how it affected my application development.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** It started out as a Codepen, and actually lived there for quite a bit until a rough 1.0.  I genuinely love starting out libraries (and even apps) that way, since it keeps you on your toes.  Break something and it'll take the whole tab down (unless you turn off autorun, but that's no fun haha).\n\n\n> At what point did it turn into an actual framework? What made you decide to switch over to using that instead of React?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I actually wasn't really a React user prior to building Preact!  I was a Web Components guy.  The platform I used for the 2 years prior to writing Preact was a custom DOM implementation sitting on top of the real DOM, and it had support for Custom Elements and Shadow DOM and all that stuff.  I really liked that development paradigm and the shareability of Web Components, but I didn't like having to use things like innerHTML to get things done.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I'd say Preact turned into a framework (\"became a thing\") around December of 2014 (double check the year on that one).  I used it to build an email client and was thrilled with the performance and how quick it was to work with.  I recall thinking \"how could I ever use a different paradigm now?\".\n\n\n> At the time, was it already tracking the React API?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** The initial versions on Codepen were basically \"inspired by\".  I knew the names and most of the externally visible concepts from React's docs, and I liked them so I used those names and borrowed some concepts.  Until December / 2.x though, it was more of a similarity than any hope of parity.  It took me a while to decide whether that was even something I cared about or not.  In the end I'm happy Preact shares so much of its interface with React because it's wonderful for those familiar with React to be able to re-use their skills in places they might not have been able to before.\n\n\n> If you really are Canadian, does preact stand for Poutine React?\n\n> **- [James Kyle](https://sideway.com/user/thejameskyle)**\n\n> (or, what does the P stand for?)\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Haha.  Everyone asks what it means - I have the worst answer imaginable for that question: it doesn't really mean anything.  I think when I was trying to come up with witty names I ended up getting quite sick of thinking about it and just wanted to buy the domain name so I could be done with it.  I had been sitting on \"preact\" as some sort of combination of \"puny\" or \"petit\" (french for \"small\") \"react\", but the logic there is lost to the sands of time.  It might have been something about \"getting there first\" (referring to small bundle size?) \"re+act\" vs \"pre+act\" - you can tell from my explanation though, it was not rooted in logic.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I'd be willing to invent sufficient backstory to support Kyle's Poutine React naming idea.  That one could stick.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** oh also - if anyone is ever in the Toronto area and wants to drive for an hour (it happens a lot), this is the best poutine place around: http://www.charred.ca\n\n\n> How big is the Preact community? Both in terms of contributors, developers using it, and product deployments.\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** It's actually a little larger than people might realize.  In terms of contributors, most of the activity in preact-compat (the \"full React compatibility\" layer) is coming from people who are not me, and that's awesome.  Developers who have used React extensively often have good insight into issues when they arise in that repo.  Preact's core has seen some awesome contributions too, we've had people rework test harnesses and write lots more tests (much needed), submit PRs not just for bug fixes but to suggest/add entirely new behaviors like Paul Lewis's PR for fully async rendering of siblings.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** On the usage side of things, I'm aware of quite a few companies that now rely on Preact for real-world applications.  There's obviously Housing.com, Tencent, TicTail - those are pretty public about their usage of Preact.  My employer uses it extensively as well, and a few other companies I'm not sure I'm allowed to mention publicly yet!  There are some people making use of Preact for things I hadn't even thought of before - last week the lovely people of Zeit were investigating using Preact to render Hyper (a desktop app!). That's some of the cool things I'm aware of.\n\n\n> Is this still a hobby free-time project for you, or has it turned into a more of a work-time effort?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** ahh - the question of the year for 2016 honestly. Preact is definitely past the point of counting as a hobby project or spare-time-only now.  My employer depends on it, as do lots of other developers and their respective employers.  For me, I think the moment where Preact officially outgrew spare-time status was when I started getting the first major contributions and issues coming in.  Now it's more or less part of my daily job, though indirectly.  When there's a bug in Preact it's often worth stopping and looking into even if it means shelving something else I'm working on.  It could be an issue for Synacor or anyone else using the library, so it gets a fairly high priority on my todo list.\n\n\n> How sacred is the **3Kb** part of the Preact tag line?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** If I'm honest, it's priority #1 and the main metric by which I judge a Preact release.  3kb as a line in the sand isn't the most meaningful number, but I think it's incredibly important to set boundaries on development when taking performance into account in a holistic way.  If Preact added all of the features anyone had ever wanted to its core, it wouldn't be a very modular solution for developers looking to put together their own stack.  It would also make it difficult for people to use just the parts they need (or like!).  One good example of that is createClass and PropTypes not being included in the library - these are things that can really easily be bolted on, the former doesn't even require any hooks from Preact to implement.  So they are available as separate npm modules for people to install when they want that type of functionality.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I think size limits can seem a little arbitrary to people, and I understand why sometimes it could be confusing or even frustrating that a library cuts a line between features and size.  However, Preact's value comes from that size - it's the small way to use Virtual DOM.  Without that 3kb line in the sand, it would just be too tempting to add features without properly weighing their net benefit.\n\n\n> If size wasn't a goal, would you just use React or are there other reasons you prefer to use Preact (other than it's your own framework and everything that allows)?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Awesome question - short answer is probably not.  Part of that is because I'm human, and thus biased towards using things I create.  That's actually something I've been actively working on over the past 2 years, and part of the reason I do so much Open Source work.  If I want to create, I need to create in public and consume equally as much in order to recognize the value in others' work.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** In terms of reasoning, Preact is both a solution for size, and to a much lesser degree a collection of changes I wanted to make to the React API for my own liking.  The first is passing (props, state, context) to component render methods - that was something Preact had on day 1, it just seemed so obvious to me.  There are others, too - dropping PropTypes (since there are so many other ways to accomplish interface typing these days), and automatically passing context through the tree instead of having to declare a need for it.  These are things that got baked into Preact early in its life, and they haven't been removed because they either help with the size aspect, or are just nice to work with.\n\n\n> How should developers determine whether Preact's lack of virtual events is fine for them?\n\n> **- [Owen Campbell-Moore](https://sideway.com/user/owencm)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I love this question, because it's actually not one I've answered publicly yet.  For those not aware, Preact uses the DOM's event system directly instead of abstracting it.  That means things like capturing and bubbling work the way the browser defines, Preact just proxies your event handlers to addEventListener() and friends.  When you consider that I came from Web Components land, I think this makes a lot of sense - I'm quite familiar with DOM events, their nomenclature and semantics make sense to me.  Adding an abstraction that changes any of those meanings, or changes how the events interact with other libraries on a web page actually hurts my ability to understand what's going on.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** So, I would say developers should determine this based on how familiar or comfortable they are with DOM events.  If you came from jQuery and/or Backbone, or use Web Components, etc - you will will very comfortable with Preact's event handling because it's what you've already been using.  If you're a hardcore React developer though, and maybe if that's where you started your in-browser development experience, using Preact means getting better acquainted with the DOM events underpinning your application.  Things like onChange vs onInput - differences between the names and meanings in React and the DOM - those are the differences between React and Preact.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** It's probably also worth noting that preact-compat attempts to smooth over those naming and semantics differences by normalizing events during rendering.\n\n\n> Is preact-compat a custom module or is it just a fork of existing react code?\n\n> **- [Mark Struck](https://sideway.com/user/mark_struck)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Ah this one's less philosophical - it's all custom code.  preact-compat is actually one very long reverse-engineering exercise.  I used to alias it in for React in demos for various React Component libraries like Material UI and just look for problems.  When I found a problem I'd add a fix to preact-compat, and eventually it grew into a layer that paves over most of the differences between the two libraries.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** There is one shared dependency though, and I hope it becomes more directly shared in the future: PropTypes.  preact-compat depends on the `proptypes` module from npm, which is a refactored version of the PropTypes implementation from React I extracted from React 0.14.  I hope at some point the React team chooses to make PropTypes an external module - if they do, I've got the name on npm and I'm happy to give it to them!\n\n\n> Do you have a plan to handle React Fiber's ability to return different types such as arrays in preact-compat?\n\n> **- [Kye Hohenberger](https://sideway.com/user/tkh)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** That's actually much more likely to be implemented in preact itself, rather than preact-compat.  Returning an Array from render() was not something I'd ever had in mind when building Preact, so when I heard that was going to become a thing I started slowly making some of the necessary changes to support that behavior.  It touches a lot of areas of the library, but the worst offender was the implementation of Pure Functional Component diffing.  PFC's are (were?) ephemeral in Preact for a long time.  In Preact 8 (coming soon!), that has been changed and they are diffed using the same codepath as classful Components.  This means dealing with alternative return types from `render()` only affects one spot in the renderer, which makes it a lot easier to deal with.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** The other reason this particular issue is troublesome is that Preact diffs very differently from React - it diffs your Virtual DOM tree against the actual DOM tree.  Instead of diffing the array return value of `render()`, Preact is going to have to store fragments on DOM elements and diff within those.  It's by no means infeasible, but it's a little more difficult because of how the diff is designed.\n\n\n> Do you think there are strong reasons for a team to choose Preact over React, or there use cases better suited to both?\n\n> **- [Jason Quense](https://sideway.com/user/monasticpanic)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I think it's really a decision every team has to make, either when starting out a project (ideal), or when encountering issues along the way (still workable).  React is an excellent library and has a great ecosystem.  There will always be great arguments in favor of choosing React.  Preact caters to some different use-cases than React though, so for a lot of teams there is actually very little choice.  Anecdotally, the team I work on builds widgets that get embedded into other companies' websites - this is a really great use-case for Preact, because of the self-contained nature of the library and obviously because of the size advantage.  You can use Preact to render tiny little parts of a page, and not have to worry about event interoperability or bundle size - those are things Preact actively takes care of for you.\n\n\n> Do you worry optimizing Preact for existing JS engine quirks will prevent the engines from evolving in good directions as it will slow down in benchmarks against frameworks / libs with these optimizations?\n\n> **- [Owen Campbell-Moore](https://sideway.com/user/owencm)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Yes. I definitely optimize *in* Chrome, and I tend to favor V8 because the team has been so supportive of developers and open about how their engine works.  Tools like IRHydra don't really exist for other engines, so it's not practical to optimize for other engines to the same extent.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** That being said, I do run all of my benchmarks in different browsers to make sure a performance optimization for one doesn't have the opposite effect on another.  I'm not sure how common it is to do that, but I think it's valuable.  In the early days of Preact I actually had made the mistake of adding V8-specific optimizations that hurt performance in Firefox.  That as a valuable lesson, and since then I've made sure to track performance metrics across a wider spectrum of engines.  This is especially true for Internet Explorer - old versions of IE are already going to be some of the slowest to run JavaScript, so adding performance optimizations for modern browsers that negatively impact performance in IE9 can really hurt users stuck on that browser.\n\n\n> What's next on your plate for Preact?\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Version 8 is the next big thing.  It's a breaking change, though not the kind that makes you pull your hair out.  One big thing is the rewrite of Pure Functional Component handling - that's done but waiting to be released.  Another is dropping support for Object values in the `class` (/`className`) prop - that was causing issues for styling solutions that rely on Objects with overridden `toString()` methods to serialize classes dynamically during rendering.  The last one, and probably the largest of the changes coming up, is that it looks like we're going to drop DOM element recycling.  That might sound crazy, but it's actually become rather unnecessary since Preact 4 or 5.  Around that time, the way Components are rendered was changed so that their generated DOM is recycled based on component type.  Unless people are building apps entirely without any form of components, it's unlikely the element recycler is even doing much work!  This was only made more true by the PFC changes, since now they're nicely tracked in the Virtual DOM tree for their own recycling.\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Aside from that, I'm working on some things that aren't part of Preact itself.  A CLI for building PWA's with Preact that \"just works\" out-of-the-box is one of those things, though it's really early.  I'm also looking at ways to improve DX.\n\n\n> Is Preacts diffing between Virtual DOM and the real DOM slower than React's diffing algorithm?\n\n> **- [Mark Struck](https://sideway.com/user/mark_struck)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** It would be, except Preact caches data on DOM elements so that it doesn't touch them except to update.  That was one of the optimizations that came out of the Codepen era.  Profiling while running animations made it really obvious that touching the DOM in order to diff was a bad idea ;)\n\n\n> I have another naming suggestion:\nhttps://uploads.sideway.com/r/aY/7W:syfAmu:Advx/full\n\n> **- [James Kyle](https://sideway.com/user/thejameskyle)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Looks like I need to buy react-s.com (it's available!)\n\n> Is there any thing the community can do to help make Preact better!?\n\n> **- [Peter Piekarczyk](https://sideway.com/user/peterpme)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Yes! Help write tests. Build UI frameworks around it. Use Preact and give feedback.  Build tooling that makes your life easier when working with it.  Everyone who uses Preact is helping make it better, because your feedback guides all the development.\n\n\n> Do you think React and Preact will ever converge together down the road?\n\n> **- [Peter Piekarczyk](https://sideway.com/user/peterpme)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Not converge, but I think React will eventually work to address some of the use-cases Preact is advantageous for right now.  That benefits everyone, so it makes me happy.  With Fiber and simplified custom renderers, it might be possible to build a lightweight render (a \"preact react renderer\"!) that brings the two projects closer than they could be today.\n\n\n> Have you built any Preact apps that leveraged Redux? Also, what is your opinion on Redux?\n\n> **- [Mark Struck](https://sideway.com/user/mark_struck)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** I have built some demos, a hackathon project and a few other odds and ends.  I really love the idea of Redux and the code is a joy to read.  However, since I started building Preact apps using regular old Component state, that's still where my brain likes to go when I get down to work.  I think an ideal case for me would be a mix of Redux for holding intentionally centralized state, and component-local state for UI-specific things.  Who knows though, every app is different!\n\n\n> Thanks Jason! This has been great. We (Sideway) have been looking at Preact for a while and I know it's something we would like to use for the obvious size reduction.\n\n\n> **- [Eran Hammer](https://sideway.com/user/eranhammer)**\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Awesome! There's a Slack group by the way, where lots of these types of discussions happen at random throughout the day: https://preact-slack.now.sh\n\n\n**[Eran Hammer](https://sideway.com/user/eranhammer):** And with that, goodbye!\n\n\n**[Jason Miller 🦊⚛](https://sideway.com/user/developit):** Thanks for the opportunity to answer some great questions!\n\n","html":"<blockquote>\n  <p>🎤 This was originally published as <a href=\"https://sideway.com/room/aY\"><strong>\"Preact.js with Jason Miller\"</strong></a> on Sideway.</p>\n</blockquote>\n\n<hr />\n\n<p><a href=\"https://preactjs.com\">Preact</a> is a <strong>fast 3kB</strong> alternative to React with the same API, providing the thinnest possible Virtual DOM abstraction on top of the DOM.</p>\n\n<p>In this conversation, Preact's author <a href=\"https://twitter.com/_developit\">Jason Miller</a> discusses the project goals, progress, the relationship with the larger React community, and his plans for the future.</p>\n\n<hr />\n\n<blockquote>\n  <p>What's the Preact origin story? How did it come to be?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Preact started out as a way for me to learn how React worked internally.  I've always felt a little uncomfortable using things without fully understanding their internals, so I needed to code out a basic version of a DOM diff algorithm in order to grasp how it affected my application development.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> It started out as a Codepen, and actually lived there for quite a bit until a rough 1.0.  I genuinely love starting out libraries (and even apps) that way, since it keeps you on your toes.  Break something and it'll take the whole tab down (unless you turn off autorun, but that's no fun haha).</p>\n\n<blockquote>\n  <p>At what point did it turn into an actual framework? What made you decide to switch over to using that instead of React?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I actually wasn't really a React user prior to building Preact!  I was a Web Components guy.  The platform I used for the 2 years prior to writing Preact was a custom DOM implementation sitting on top of the real DOM, and it had support for Custom Elements and Shadow DOM and all that stuff.  I really liked that development paradigm and the shareability of Web Components, but I didn't like having to use things like innerHTML to get things done.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I'd say Preact turned into a framework (\"became a thing\") around December of 2014 (double check the year on that one).  I used it to build an email client and was thrilled with the performance and how quick it was to work with.  I recall thinking \"how could I ever use a different paradigm now?\".</p>\n\n<blockquote>\n  <p>At the time, was it already tracking the React API?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> The initial versions on Codepen were basically \"inspired by\".  I knew the names and most of the externally visible concepts from React's docs, and I liked them so I used those names and borrowed some concepts.  Until December / 2.x though, it was more of a similarity than any hope of parity.  It took me a while to decide whether that was even something I cared about or not.  In the end I'm happy Preact shares so much of its interface with React because it's wonderful for those familiar with React to be able to re-use their skills in places they might not have been able to before.</p>\n\n<blockquote>\n  <p>If you really are Canadian, does preact stand for Poutine React?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/thejameskyle\">James Kyle</a></strong></p>\n  \n  <p>(or, what does the P stand for?)</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Haha.  Everyone asks what it means - I have the worst answer imaginable for that question: it doesn't really mean anything.  I think when I was trying to come up with witty names I ended up getting quite sick of thinking about it and just wanted to buy the domain name so I could be done with it.  I had been sitting on \"preact\" as some sort of combination of \"puny\" or \"petit\" (french for \"small\") \"react\", but the logic there is lost to the sands of time.  It might have been something about \"getting there first\" (referring to small bundle size?) \"re+act\" vs \"pre+act\" - you can tell from my explanation though, it was not rooted in logic.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I'd be willing to invent sufficient backstory to support Kyle's Poutine React naming idea.  That one could stick.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> oh also - if anyone is ever in the Toronto area and wants to drive for an hour (it happens a lot), this is the best poutine place around: <a href=\"http://www.charred.ca\">http://www.charred.ca</a></p>\n\n<blockquote>\n  <p>How big is the Preact community? Both in terms of contributors, developers using it, and product deployments.</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> It's actually a little larger than people might realize.  In terms of contributors, most of the activity in preact-compat (the \"full React compatibility\" layer) is coming from people who are not me, and that's awesome.  Developers who have used React extensively often have good insight into issues when they arise in that repo.  Preact's core has seen some awesome contributions too, we've had people rework test harnesses and write lots more tests (much needed), submit PRs not just for bug fixes but to suggest/add entirely new behaviors like Paul Lewis's PR for fully async rendering of siblings.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> On the usage side of things, I'm aware of quite a few companies that now rely on Preact for real-world applications.  There's obviously Housing.com, Tencent, TicTail - those are pretty public about their usage of Preact.  My employer uses it extensively as well, and a few other companies I'm not sure I'm allowed to mention publicly yet!  There are some people making use of Preact for things I hadn't even thought of before - last week the lovely people of Zeit were investigating using Preact to render Hyper (a desktop app!). That's some of the cool things I'm aware of.</p>\n\n<blockquote>\n  <p>Is this still a hobby free-time project for you, or has it turned into a more of a work-time effort?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> ahh - the question of the year for 2016 honestly. Preact is definitely past the point of counting as a hobby project or spare-time-only now.  My employer depends on it, as do lots of other developers and their respective employers.  For me, I think the moment where Preact officially outgrew spare-time status was when I started getting the first major contributions and issues coming in.  Now it's more or less part of my daily job, though indirectly.  When there's a bug in Preact it's often worth stopping and looking into even if it means shelving something else I'm working on.  It could be an issue for Synacor or anyone else using the library, so it gets a fairly high priority on my todo list.</p>\n\n<blockquote>\n  <p>How sacred is the <strong>3Kb</strong> part of the Preact tag line?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> If I'm honest, it's priority #1 and the main metric by which I judge a Preact release.  3kb as a line in the sand isn't the most meaningful number, but I think it's incredibly important to set boundaries on development when taking performance into account in a holistic way.  If Preact added all of the features anyone had ever wanted to its core, it wouldn't be a very modular solution for developers looking to put together their own stack.  It would also make it difficult for people to use just the parts they need (or like!).  One good example of that is createClass and PropTypes not being included in the library - these are things that can really easily be bolted on, the former doesn't even require any hooks from Preact to implement.  So they are available as separate npm modules for people to install when they want that type of functionality.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I think size limits can seem a little arbitrary to people, and I understand why sometimes it could be confusing or even frustrating that a library cuts a line between features and size.  However, Preact's value comes from that size - it's the small way to use Virtual DOM.  Without that 3kb line in the sand, it would just be too tempting to add features without properly weighing their net benefit.</p>\n\n<blockquote>\n  <p>If size wasn't a goal, would you just use React or are there other reasons you prefer to use Preact (other than it's your own framework and everything that allows)?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Awesome question - short answer is probably not.  Part of that is because I'm human, and thus biased towards using things I create.  That's actually something I've been actively working on over the past 2 years, and part of the reason I do so much Open Source work.  If I want to create, I need to create in public and consume equally as much in order to recognize the value in others' work.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> In terms of reasoning, Preact is both a solution for size, and to a much lesser degree a collection of changes I wanted to make to the React API for my own liking.  The first is passing (props, state, context) to component render methods - that was something Preact had on day 1, it just seemed so obvious to me.  There are others, too - dropping PropTypes (since there are so many other ways to accomplish interface typing these days), and automatically passing context through the tree instead of having to declare a need for it.  These are things that got baked into Preact early in its life, and they haven't been removed because they either help with the size aspect, or are just nice to work with.</p>\n\n<blockquote>\n  <p>How should developers determine whether Preact's lack of virtual events is fine for them?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/owencm\">Owen Campbell-Moore</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I love this question, because it's actually not one I've answered publicly yet.  For those not aware, Preact uses the DOM's event system directly instead of abstracting it.  That means things like capturing and bubbling work the way the browser defines, Preact just proxies your event handlers to addEventListener() and friends.  When you consider that I came from Web Components land, I think this makes a lot of sense - I'm quite familiar with DOM events, their nomenclature and semantics make sense to me.  Adding an abstraction that changes any of those meanings, or changes how the events interact with other libraries on a web page actually hurts my ability to understand what's going on.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> So, I would say developers should determine this based on how familiar or comfortable they are with DOM events.  If you came from jQuery and/or Backbone, or use Web Components, etc - you will will very comfortable with Preact's event handling because it's what you've already been using.  If you're a hardcore React developer though, and maybe if that's where you started your in-browser development experience, using Preact means getting better acquainted with the DOM events underpinning your application.  Things like onChange vs onInput - differences between the names and meanings in React and the DOM - those are the differences between React and Preact.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> It's probably also worth noting that preact-compat attempts to smooth over those naming and semantics differences by normalizing events during rendering.</p>\n\n<blockquote>\n  <p>Is preact-compat a custom module or is it just a fork of existing react code?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/mark_struck\">Mark Struck</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Ah this one's less philosophical - it's all custom code.  preact-compat is actually one very long reverse-engineering exercise.  I used to alias it in for React in demos for various React Component libraries like Material UI and just look for problems.  When I found a problem I'd add a fix to preact-compat, and eventually it grew into a layer that paves over most of the differences between the two libraries.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> There is one shared dependency though, and I hope it becomes more directly shared in the future: PropTypes.  preact-compat depends on the <code>proptypes</code> module from npm, which is a refactored version of the PropTypes implementation from React I extracted from React 0.14.  I hope at some point the React team chooses to make PropTypes an external module - if they do, I've got the name on npm and I'm happy to give it to them!</p>\n\n<blockquote>\n  <p>Do you have a plan to handle React Fiber's ability to return different types such as arrays in preact-compat?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/tkh\">Kye Hohenberger</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> That's actually much more likely to be implemented in preact itself, rather than preact-compat.  Returning an Array from render() was not something I'd ever had in mind when building Preact, so when I heard that was going to become a thing I started slowly making some of the necessary changes to support that behavior.  It touches a lot of areas of the library, but the worst offender was the implementation of Pure Functional Component diffing.  PFC's are (were?) ephemeral in Preact for a long time.  In Preact 8 (coming soon!), that has been changed and they are diffed using the same codepath as classful Components.  This means dealing with alternative return types from <code>render()</code> only affects one spot in the renderer, which makes it a lot easier to deal with.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> The other reason this particular issue is troublesome is that Preact diffs very differently from React - it diffs your Virtual DOM tree against the actual DOM tree.  Instead of diffing the array return value of <code>render()</code>, Preact is going to have to store fragments on DOM elements and diff within those.  It's by no means infeasible, but it's a little more difficult because of how the diff is designed.</p>\n\n<blockquote>\n  <p>Do you think there are strong reasons for a team to choose Preact over React, or there use cases better suited to both?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/monasticpanic\">Jason Quense</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I think it's really a decision every team has to make, either when starting out a project (ideal), or when encountering issues along the way (still workable).  React is an excellent library and has a great ecosystem.  There will always be great arguments in favor of choosing React.  Preact caters to some different use-cases than React though, so for a lot of teams there is actually very little choice.  Anecdotally, the team I work on builds widgets that get embedded into other companies' websites - this is a really great use-case for Preact, because of the self-contained nature of the library and obviously because of the size advantage.  You can use Preact to render tiny little parts of a page, and not have to worry about event interoperability or bundle size - those are things Preact actively takes care of for you.</p>\n\n<blockquote>\n  <p>Do you worry optimizing Preact for existing JS engine quirks will prevent the engines from evolving in good directions as it will slow down in benchmarks against frameworks / libs with these optimizations?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/owencm\">Owen Campbell-Moore</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Yes. I definitely optimize <em>in</em> Chrome, and I tend to favor V8 because the team has been so supportive of developers and open about how their engine works.  Tools like IRHydra don't really exist for other engines, so it's not practical to optimize for other engines to the same extent.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> That being said, I do run all of my benchmarks in different browsers to make sure a performance optimization for one doesn't have the opposite effect on another.  I'm not sure how common it is to do that, but I think it's valuable.  In the early days of Preact I actually had made the mistake of adding V8-specific optimizations that hurt performance in Firefox.  That as a valuable lesson, and since then I've made sure to track performance metrics across a wider spectrum of engines.  This is especially true for Internet Explorer - old versions of IE are already going to be some of the slowest to run JavaScript, so adding performance optimizations for modern browsers that negatively impact performance in IE9 can really hurt users stuck on that browser.</p>\n\n<blockquote>\n  <p>What's next on your plate for Preact?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Version 8 is the next big thing.  It's a breaking change, though not the kind that makes you pull your hair out.  One big thing is the rewrite of Pure Functional Component handling - that's done but waiting to be released.  Another is dropping support for Object values in the <code>class</code> (/<code>className</code>) prop - that was causing issues for styling solutions that rely on Objects with overridden <code>toString()</code> methods to serialize classes dynamically during rendering.  The last one, and probably the largest of the changes coming up, is that it looks like we're going to drop DOM element recycling.  That might sound crazy, but it's actually become rather unnecessary since Preact 4 or 5.  Around that time, the way Components are rendered was changed so that their generated DOM is recycled based on component type.  Unless people are building apps entirely without any form of components, it's unlikely the element recycler is even doing much work!  This was only made more true by the PFC changes, since now they're nicely tracked in the Virtual DOM tree for their own recycling.</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Aside from that, I'm working on some things that aren't part of Preact itself.  A CLI for building PWA's with Preact that \"just works\" out-of-the-box is one of those things, though it's really early.  I'm also looking at ways to improve DX.</p>\n\n<blockquote>\n  <p>Is Preacts diffing between Virtual DOM and the real DOM slower than React's diffing algorithm?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/mark_struck\">Mark Struck</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> It would be, except Preact caches data on DOM elements so that it doesn't touch them except to update.  That was one of the optimizations that came out of the Codepen era.  Profiling while running animations made it really obvious that touching the DOM in order to diff was a bad idea ;)</p>\n\n<blockquote>\n  <p>I have another naming suggestion:\n  <a href=\"https://uploads.sideway.com/r/aY/7W:syfAmu:Advx/full\">https://uploads.sideway.com/r/aY/7W:syfAmu:Advx/full</a></p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/thejameskyle\">James Kyle</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Looks like I need to buy react-s.com (it's available!)</p>\n\n<blockquote>\n  <p>Is there any thing the community can do to help make Preact better!?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/peterpme\">Peter Piekarczyk</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Yes! Help write tests. Build UI frameworks around it. Use Preact and give feedback.  Build tooling that makes your life easier when working with it.  Everyone who uses Preact is helping make it better, because your feedback guides all the development.</p>\n\n<blockquote>\n  <p>Do you think React and Preact will ever converge together down the road?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/peterpme\">Peter Piekarczyk</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Not converge, but I think React will eventually work to address some of the use-cases Preact is advantageous for right now.  That benefits everyone, so it makes me happy.  With Fiber and simplified custom renderers, it might be possible to build a lightweight render (a \"preact react renderer\"!) that brings the two projects closer than they could be today.</p>\n\n<blockquote>\n  <p>Have you built any Preact apps that leveraged Redux? Also, what is your opinion on Redux?</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/mark_struck\">Mark Struck</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> I have built some demos, a hackathon project and a few other odds and ends.  I really love the idea of Redux and the code is a joy to read.  However, since I started building Preact apps using regular old Component state, that's still where my brain likes to go when I get down to work.  I think an ideal case for me would be a mix of Redux for holding intentionally centralized state, and component-local state for UI-specific things.  Who knows though, every app is different!</p>\n\n<blockquote>\n  <p>Thanks Jason! This has been great. We (Sideway) have been looking at Preact for a while and I know it's something we would like to use for the obvious size reduction.</p>\n  \n  <p><strong>- <a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a></strong></p>\n</blockquote>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Awesome! There's a Slack group by the way, where lots of these types of discussions happen at random throughout the day: <a href=\"https://preact-slack.now.sh\">https://preact-slack.now.sh</a></p>\n\n<p><strong><a href=\"https://sideway.com/user/eranhammer\">Eran Hammer</a>:</strong> And with that, goodbye!</p>\n\n<p><strong><a href=\"https://sideway.com/user/developit\">Jason Miller 🦊⚛</a>:</strong> Thanks for the opportunity to answer some great questions!</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-07-07T16:34:36.260Z","created_by":1,"updated_at":"2017-07-07T16:39:27.810Z","updated_by":1,"published_at":"2017-07-07T16:38:24.765Z","published_by":1},{"id":10,"uuid":"0fb41672-5985-473d-9327-654204023036","title":"Universal VDOM Components with factory-loader","slug":"universal-vdom-components-with-factory-loader","markdown":"There is a commonly known issue in the React/etc community that we haven't been able to piece together a solution for yet.  I think I might have stumbled onto a decent way to solve the problem, in the form of a 5-line Webpack loader I'm tentatively calling `factory-loader`.\n\nHere's the gist: we know Dependency Injection is a reasonable solution to the problem, it's just not something anyone would want to adopt because it's verbose.\n\nHere's an example of a component written in the \"ideal\" style - a factory that allows us to inject the Virtual DOM library of our choosing when we consume the module:\n\n```js\n// foo.js\nexport default vdom => {\n  return class Foo extends vdom.Component {\n    render() {\n      return <div />\n      //     ^ produces vdom.createElement('div')\n    }\n  }\n}\n```\n\nThis is pretty workable on the component authoring side of things - instead of importing a specific Virtual DOM library, we export a function that lets the consumer of the module pass it to us. This removes the tight coupling a component normally has to one specific VDOM implementation.\n\nOn the consuming side though, this can get pretty out of hand:\n\n```js\nimport preact from 'preact';\nimport createFoo from './foo';  // from above\n\n// now we have to create a preact-bound Foo ourselves:\nconst Foo = createFoo(preact);\n\nrender(<Foo />)  // as you would have before\n```\n\nIt seems alright to do this for one component, but if you've worked in a sufficiently complex codebase, things would not scale well. In a module with 10 or 20 component imports, that's a whole lot of boilerplate. That's a barrier to adoption of the technique, and the likely reason why I've never even seen a component authored this way - it's unprecedented and causes extra work for the consumer, and there aren't convenient shortcuts to make things easier.\n\nSo, maybe we can solve this and figure out a clean way to use these library-agnostic VDOM Components without things getting ugly...  enter `factory-loader`.\n\n---\n\n## Factory Loader\n\n`factory-loader` is a tiny Webpack loader that invokes the module it is applied to, passing it another module as an argument.  What's that useful for?  Dependency Injection!  Maybe this is how we can solve the VDOM fragmentation issue.\n\n```js\n// invoke the result of require(./foo)\n// .. with require(preact) as an argument.\nimport foo from 'factory-loader?module=preact!./foo';\n\n// in other words, do this:\nvar foo = require('./foo')( require('preact') );\n```\n\n---\n\n#### How does it work?\n\nIn essence, factory loader creates a proxy module that does this:\n\n```js\nvar factory = require('some-module')\nmodule.exports = factory(require('module-to-inject'));\n```\n\nThe actual implementation is very small - 5 lines:\n\n```js\n(module.exports = function() {}).pitch = function(req) {\n  var m = require(\"loader-utils\").parseQuery(this.query).module\n  this.cacheable && this.cacheable()\n  return \"var f=require(\"+JSON.stringify(\"!!\"+req)+\");\"+\n    \"module.exports=(f.default||f)(require(\"+JSON.stringify(m)+\"))\"\n}\n```\n\nFor the purposes of this post, let's assume this is an npm module called `factory-loader`.\n\n---\n\n#### Example\n\nHere's a library-agnostic VDOM component. Notice that it doesn't import React or any Virtual DOM library. It simply takes the VDOM library as an argument:\n\n**awesome-list.js:**\n\n```js\n/** @jsx createElement */\nexport default ({ createElement, Component }) => {\n  // Example pure functional Component:\n  const Item = props => (\n    <li>{props.item}</li>\n  );\n\n  // Example stateful/classful Component:\n  return class AwesomeList extends Component {\n    render() {\n      return (\n        <ul>\n          { this.props.items.map( item =>\n            <Item item={item} />\n          ) }\n        </ul>\n      );\n    }\n  }\n}\n```\n\nNormally the JSX pragma there would be in a babelrc or similar, I've just left it inline to make it obvious that JSX is being transpiled to a function call we've accepted as an argument (`createElement()`).\n\nSo, with the above library-agnostic VDOM Component, let's use `factory-loader` to import it without any boilerplate. This essentially is a \"late binding\" of the component to (in this case) Preact:\n\n**app.js:**\n\n```js\n// import Preact for use in our module:\nimport { h, render } from 'preact';\n\n// Import awesome-list, invoke it with preact and grab the result:\nimport AwesomeList from 'factory-loader?module=preact!./awesome-list';\n\n// AwesomeList is now a Preact component!\n\nrender(\n  <AwesomeList items={['a', 'b', 'c']} />\n, document.body);\n```\n\n---\n\n#### Recap\n\nTo recap - `factory-loader` is extremely simple. It just does this:\n\n```js\nvar factory = require('whatever-you-called-it-on.js')\nmodule.exports = factory(require('value-of-module-parameter.js'));\n```\n\nIn the `AwesomeList` example we just walked through, the loader creates this little proxy module for us behind-the-scenes:\n\n```js\nvar f = require('./awesome-list');\nmodule.exports = (f.default || f)(require('preact'));\n```\n\n_(the `factory.default || factory` bit there accounts for ES Module default exports in Webpack 2)_\n\n\nI think this is fairly easy to follow, and solves the DI problem we've been avoiding for quite some time.  What do you think?","html":"<p>There is a commonly known issue in the React/etc community that we haven't been able to piece together a solution for yet.  I think I might have stumbled onto a decent way to solve the problem, in the form of a 5-line Webpack loader I'm tentatively calling <code>factory-loader</code>.</p>\n\n<p>Here's the gist: we know Dependency Injection is a reasonable solution to the problem, it's just not something anyone would want to adopt because it's verbose.</p>\n\n<p>Here's an example of a component written in the \"ideal\" style - a factory that allows us to inject the Virtual DOM library of our choosing when we consume the module:</p>\n\n<pre><code class=\"language-js\">// foo.js\nexport default vdom =&gt; {  \n  return class Foo extends vdom.Component {\n    render() {\n      return &lt;div /&gt;\n      //     ^ produces vdom.createElement('div')\n    }\n  }\n}\n</code></pre>\n\n<p>This is pretty workable on the component authoring side of things - instead of importing a specific Virtual DOM library, we export a function that lets the consumer of the module pass it to us. This removes the tight coupling a component normally has to one specific VDOM implementation.</p>\n\n<p>On the consuming side though, this can get pretty out of hand:</p>\n\n<pre><code class=\"language-js\">import preact from 'preact';  \nimport createFoo from './foo';  // from above\n\n// now we have to create a preact-bound Foo ourselves:\nconst Foo = createFoo(preact);\n\nrender(&lt;Foo /&gt;)  // as you would have before  \n</code></pre>\n\n<p>It seems alright to do this for one component, but if you've worked in a sufficiently complex codebase, things would not scale well. In a module with 10 or 20 component imports, that's a whole lot of boilerplate. That's a barrier to adoption of the technique, and the likely reason why I've never even seen a component authored this way - it's unprecedented and causes extra work for the consumer, and there aren't convenient shortcuts to make things easier.</p>\n\n<p>So, maybe we can solve this and figure out a clean way to use these library-agnostic VDOM Components without things getting ugly...  enter <code>factory-loader</code>.</p>\n\n<hr />\n\n<h2 id=\"factoryloader\">Factory Loader</h2>\n\n<p><code>factory-loader</code> is a tiny Webpack loader that invokes the module it is applied to, passing it another module as an argument.  What's that useful for?  Dependency Injection!  Maybe this is how we can solve the VDOM fragmentation issue.</p>\n\n<pre><code class=\"language-js\">// invoke the result of require(./foo)\n// .. with require(preact) as an argument.\nimport foo from 'factory-loader?module=preact!./foo';\n\n// in other words, do this:\nvar foo = require('./foo')( require('preact') );  \n</code></pre>\n\n<hr />\n\n<h4 id=\"howdoesitwork\">How does it work?</h4>\n\n<p>In essence, factory loader creates a proxy module that does this:</p>\n\n<pre><code class=\"language-js\">var factory = require('some-module')  \nmodule.exports = factory(require('module-to-inject'));  \n</code></pre>\n\n<p>The actual implementation is very small - 5 lines:</p>\n\n<pre><code class=\"language-js\">(module.exports = function() {}).pitch = function(req) {\n  var m = require(\"loader-utils\").parseQuery(this.query).module\n  this.cacheable &amp;&amp; this.cacheable()\n  return \"var f=require(\"+JSON.stringify(\"!!\"+req)+\");\"+\n    \"module.exports=(f.default||f)(require(\"+JSON.stringify(m)+\"))\"\n}\n</code></pre>\n\n<p>For the purposes of this post, let's assume this is an npm module called <code>factory-loader</code>.</p>\n\n<hr />\n\n<h4 id=\"example\">Example</h4>\n\n<p>Here's a library-agnostic VDOM component. Notice that it doesn't import React or any Virtual DOM library. It simply takes the VDOM library as an argument:</p>\n\n<p><strong>awesome-list.js:</strong></p>\n\n<pre><code class=\"language-js\">/** @jsx createElement */\nexport default ({ createElement, Component }) =&gt; {  \n  // Example pure functional Component:\n  const Item = props =&gt; (\n    &lt;li&gt;{props.item}&lt;/li&gt;\n  );\n\n  // Example stateful/classful Component:\n  return class AwesomeList extends Component {\n    render() {\n      return (\n        &lt;ul&gt;\n          { this.props.items.map( item =&gt;\n            &lt;Item item={item} /&gt;\n          ) }\n        &lt;/ul&gt;\n      );\n    }\n  }\n}\n</code></pre>\n\n<p>Normally the JSX pragma there would be in a babelrc or similar, I've just left it inline to make it obvious that JSX is being transpiled to a function call we've accepted as an argument (<code>createElement()</code>).</p>\n\n<p>So, with the above library-agnostic VDOM Component, let's use <code>factory-loader</code> to import it without any boilerplate. This essentially is a \"late binding\" of the component to (in this case) Preact:</p>\n\n<p><strong>app.js:</strong></p>\n\n<pre><code class=\"language-js\">// import Preact for use in our module:\nimport { h, render } from 'preact';\n\n// Import awesome-list, invoke it with preact and grab the result:\nimport AwesomeList from 'factory-loader?module=preact!./awesome-list';\n\n// AwesomeList is now a Preact component!\n\nrender(  \n  &lt;AwesomeList items={['a', 'b', 'c']} /&gt;\n, document.body);\n</code></pre>\n\n<hr />\n\n<h4 id=\"recap\">Recap</h4>\n\n<p>To recap - <code>factory-loader</code> is extremely simple. It just does this:</p>\n\n<pre><code class=\"language-js\">var factory = require('whatever-you-called-it-on.js')  \nmodule.exports = factory(require('value-of-module-parameter.js'));  \n</code></pre>\n\n<p>In the <code>AwesomeList</code> example we just walked through, the loader creates this little proxy module for us behind-the-scenes:</p>\n\n<pre><code class=\"language-js\">var f = require('./awesome-list');  \nmodule.exports = (f.default || f)(require('preact'));  \n</code></pre>\n\n<p><em>(the <code>factory.default || factory</code> bit there accounts for ES Module default exports in Webpack 2)</em></p>\n\n<p>I think this is fairly easy to follow, and solves the DI problem we've been avoiding for quite some time.  What do you think?</p>","image":null,"featured":false,"page":false,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-03-25T18:25:38.791Z","created_by":1,"updated_at":"2019-02-17T20:11:10.727Z","updated_by":1,"published_at":"2017-03-25T18:49:35.351Z","published_by":1},{"id":13,"uuid":"987a2e5f-3d20-4ab6-adce-1b43a4f2bc69","title":"SSR and Caching","slug":"asdf","markdown":"I've been thinking a lot about [Server-Side Rendering](), particularly in the context of modern SSR with Hydration techniques and their impact on page load performance.\n\n## A Thought Experiment\n\nIf we were to build an ideal full-stack web application framework today without basing it on popular frameworks or techniques, what decisions would we make, and what approaches would be considered intuitive?\n\nI find myself wondering if we would begin by rendering the same codebase on the client that we run on the server. Would we apply the same rendering approach to pieces of UI driven by static content, personalized content, and real-time content? These are decisions we don't often make these days, since universal rendering is so common. However, would we make these same decisions for ourselves if we hadn't started with tooling that made it possible?\n\nComparing modern rendering architectures to those that came before, I would like to assert that the fundamental concepts and assumptions are unchanged: deliver pages quickly and using as little could+network as possible. The differences afforded by any given library are mostly limited to authoring formats (components), conveniences (JSX, diffing) and base JavaScript cost.\n\n## Effects of Caching on SSR\n\nWithout caching, Server rendering of any kind increases TTFB (Time to First Byte) compared to static deployment. This isn't just the first byte either - it increases the time clients must wait before receiving the *content* for a request. The reason is simple: executing logic in response to every request takes more time than not doing so.\n\nThese effects can be mitigated to some extent through the effective use of caching. In the best case, a good caching strategy avoids the rendering step for most requests, and allows navigation requests to be cached by a CDN and handled at the edge.\n\n### Caching is Hard\n\nUnfortunately, caching isn't just a simple bandaid fix. The viability and efficacy of caching depends on the nature of the content being server-rendered. While server rendering is beneficial for reducing the impact of JavaScript on performance, it presents a challenge for caching since response validity must account for the various lifetimes of everything required to compose each page. This means accounting for changes to source code (git push!), the TTLs of data dependencies (CMS updated!), varying request context like user sessions (logged out!), and other factors.\n\nSome examples of the effect these have on server rendered applications include:\n\nPage with **user data:**  Not cacheable to any useful degree.  \n Cacheability is extremely limited because the key space is theoretically infinite (users × urls × session length).\n\nPage with **dynamic content:** Cacheable.  \nThe cache lifetime for a request is determined by the content source with the shortest TTL.\n\nPage with **rolling static content:** Highly cacheable, but likely unnecessary. An argument could be made that colocation of content and source would be better served by a static site generator. Static site generators fall into the \"Static SSR\" category defined earlier, and as a result they offer improved uncached TTFB and reduced infrastructure complexity.\n\n**Fully static app:**  Highly cacheable, but highly unnecessary. Documentation, marketing and brochure sites can often have a completely static corpus of URLs. Given that there is no runtime variability, there are very few reasons to allow for dynamic rendering at all. For fully static applications \nlike this, techniques like prerendering and static site generation are often a better choice. These offer the same performance characteristics as already-cached server-rendered applications, without the cold load drawback and infrastructure complexity.  A rule of thumb: if the content and/or URLs for an application change less often than its source, it might be a static app.\n\n## Partially Static Rendering\n\nBuilding a server-rendered application doesn't necessarily mean never rendering on the client. Similar to partial hydration, it's possible to have parts of a page rendered on the server, then fill in other parts on the client. This can be a clever way to constrain the caching implications of server rendering while still allowing highly dynamic content.\n\nTo illustrate, imagine the article read page on a fictitious news website. The article content has a fairly long cache validity dictated by the content source (author, AP, etc). Most of the site's \"shell\" - the header, footer, etc - also has a long cache lifetime.","html":"<p>I've been thinking a lot about <a href=\"\">Server-Side Rendering</a>, particularly in the context of modern SSR with Hydration techniques and their impact on page load performance.</p>\n\n<h2 id=\"athoughtexperiment\">A Thought Experiment</h2>\n\n<p>If we were to build an ideal full-stack web application framework today without basing it on popular frameworks or techniques, what decisions would we make, and what approaches would be considered intuitive?</p>\n\n<p>I find myself wondering if we would begin by rendering the same codebase on the client that we run on the server. Would we apply the same rendering approach to pieces of UI driven by static content, personalized content, and real-time content? These are decisions we don't often make these days, since universal rendering is so common. However, would we make these same decisions for ourselves if we hadn't started with tooling that made it possible?</p>\n\n<p>Comparing modern rendering architectures to those that came before, I would like to assert that the fundamental concepts and assumptions are unchanged: deliver pages quickly and using as little could+network as possible. The differences afforded by any given library are mostly limited to authoring formats (components), conveniences (JSX, diffing) and base JavaScript cost.</p>\n\n<h2 id=\"effectsofcachingonssr\">Effects of Caching on SSR</h2>\n\n<p>Without caching, Server rendering of any kind increases TTFB (Time to First Byte) compared to static deployment. This isn't just the first byte either - it increases the time clients must wait before receiving the <em>content</em> for a request. The reason is simple: executing logic in response to every request takes more time than not doing so.</p>\n\n<p>These effects can be mitigated to some extent through the effective use of caching. In the best case, a good caching strategy avoids the rendering step for most requests, and allows navigation requests to be cached by a CDN and handled at the edge.</p>\n\n<h3 id=\"cachingishard\">Caching is Hard</h3>\n\n<p>Unfortunately, caching isn't just a simple bandaid fix. The viability and efficacy of caching depends on the nature of the content being server-rendered. While server rendering is beneficial for reducing the impact of JavaScript on performance, it presents a challenge for caching since response validity must account for the various lifetimes of everything required to compose each page. This means accounting for changes to source code (git push!), the TTLs of data dependencies (CMS updated!), varying request context like user sessions (logged out!), and other factors.</p>\n\n<p>Some examples of the effect these have on server rendered applications include:</p>\n\n<p>Page with <strong>user data:</strong>  Not cacheable to any useful degree. <br />\n Cacheability is extremely limited because the key space is theoretically infinite (users × urls × session length).</p>\n\n<p>Page with <strong>dynamic content:</strong> Cacheable. <br />\nThe cache lifetime for a request is determined by the content source with the shortest TTL.</p>\n\n<p>Page with <strong>rolling static content:</strong> Highly cacheable, but likely unnecessary. An argument could be made that colocation of content and source would be better served by a static site generator. Static site generators fall into the \"Static SSR\" category defined earlier, and as a result they offer improved uncached TTFB and reduced infrastructure complexity.</p>\n\n<p><strong>Fully static app:</strong>  Highly cacheable, but highly unnecessary. Documentation, marketing and brochure sites can often have a completely static corpus of URLs. Given that there is no runtime variability, there are very few reasons to allow for dynamic rendering at all. For fully static applications \nlike this, techniques like prerendering and static site generation are often a better choice. These offer the same performance characteristics as already-cached server-rendered applications, without the cold load drawback and infrastructure complexity.  A rule of thumb: if the content and/or URLs for an application change less often than its source, it might be a static app.</p>\n\n<h2 id=\"partiallystaticrendering\">Partially Static Rendering</h2>\n\n<p>Building a server-rendered application doesn't necessarily mean never rendering on the client. Similar to partial hydration, it's possible to have parts of a page rendered on the server, then fill in other parts on the client. This can be a clever way to constrain the caching implications of server rendering while still allowing highly dynamic content.</p>\n\n<p>To illustrate, imagine the article read page on a fictitious news website. The article content has a fairly long cache validity dictated by the content source (author, AP, etc). Most of the site's \"shell\" - the header, footer, etc - also has a long cache lifetime.</p>","image":null,"featured":false,"page":false,"status":"draft","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2019-02-13T18:03:01.566Z","created_by":1,"updated_at":"2019-02-22T23:49:31.540Z","updated_by":1,"published_at":null,"published_by":null}],"roles":[{"id":1,"uuid":"19b32a82-797b-4caa-b451-26593a2eb86a","name":"Administrator","description":"Administrators","created_at":"2015-07-07T13:12:45.185Z","created_by":1,"updated_at":"2015-07-07T13:12:45.185Z","updated_by":1},{"id":2,"uuid":"f14bc156-0734-4aa3-b5f1-1627e57cb728","name":"Editor","description":"Editors","created_at":"2015-07-07T13:12:45.185Z","created_by":1,"updated_at":"2015-07-07T13:12:45.185Z","updated_by":1},{"id":3,"uuid":"f725a598-dd6c-4584-aab0-7d92887af50c","name":"Author","description":"Authors","created_at":"2015-07-07T13:12:45.185Z","created_by":1,"updated_at":"2015-07-07T13:12:45.185Z","updated_by":1},{"id":4,"uuid":"42491364-178d-47be-a853-47304ad7827e","name":"Owner","description":"Blog Owner","created_at":"2015-07-07T13:12:45.186Z","created_by":1,"updated_at":"2015-07-07T13:12:45.186Z","updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1}],"settings":[{"id":18,"uuid":"a446c4b4-57e1-4990-8804-1f90b1120a72","key":"activeApps","value":"[]","type":"app","created_at":"2015-07-07T13:12:46.130Z","created_by":1,"updated_at":"2015-07-07T13:12:46.130Z","updated_by":1},{"id":3,"uuid":"640cf6c1-549a-40f0-8c77-0e53461702ab","key":"dbHash","value":"b8b78b59-e29e-4fc9-bb4e-ada19fd716d2","type":"core","created_at":"2015-07-07T13:12:46.124Z","created_by":1,"updated_at":"2015-07-07T13:12:46.211Z","updated_by":1},{"id":1,"uuid":"e7611686-e713-4e62-93b5-688054ec79e5","key":"databaseVersion","value":"004","type":"core","created_at":"2015-07-07T13:12:46.114Z","created_by":1,"updated_at":"2015-07-07T13:12:46.114Z","updated_by":1},{"id":7,"uuid":"10a19b4c-1f69-41fe-92a8-7b79149b6367","key":"email","value":"jason@developit.ca","type":"blog","created_at":"2015-07-07T13:12:46.126Z","created_by":1,"updated_at":"2015-07-13T20:04:58.853Z","updated_by":1},{"id":16,"uuid":"d28a03cc-963f-4662-9502-056e56811b95","key":"labs","value":"{}","type":"blog","created_at":"2015-07-07T13:12:46.128Z","created_by":1,"updated_at":"2021-01-19T21:42:37.994Z","updated_by":1},{"id":2,"uuid":"0b8b0174-d8cc-40c0-8753-388a52cd1491","key":"nextUpdateCheck","value":"1616217839","type":"core","created_at":"2015-07-07T13:12:46.125Z","created_by":1,"updated_at":"2021-03-19T05:24:00.799Z","updated_by":1},{"id":4,"uuid":"92294519-9a7c-41a9-b776-43f473cbaf7f","key":"displayUpdateNotification","value":"0.11.14","type":"core","created_at":"2015-07-07T13:12:46.125Z","created_by":1,"updated_at":"2021-03-19T05:24:00.800Z","updated_by":1},{"id":17,"uuid":"dfed8953-5265-41cb-8288-06da79166da1","key":"navigation","value":"[{\"label\":\"Home\",\"url\":\"https://jasonformat.com/\"},{\"label\":\"Preact\",\"url\":\"https://jasonformat.com/tag/preact/\"},{\"label\":\"Architecture\",\"url\":\"https://jasonformat.com/tag/architecture/\"},{\"label\":\"Ecosystem\",\"url\":\"https://jasonformat.com/tag/ecosystem/\"},{\"label\":\"DOM\",\"url\":\"https://jasonformat.com/tag/dom/\"}]","type":"blog","created_at":"2015-07-07T13:12:46.129Z","created_by":1,"updated_at":"2021-01-19T21:42:37.994Z","updated_by":1},{"id":13,"uuid":"6715b6d1-00b8-4dbe-a170-0f02940f5208","key":"permalinks","value":"/:slug/","type":"blog","created_at":"2015-07-07T13:12:46.127Z","created_by":1,"updated_at":"2021-01-19T21:42:37.969Z","updated_by":1},{"id":14,"uuid":"4d2b957a-93a3-45d5-ace7-505f2ca0f636","key":"ghost_head","value":"<style type=\"text/css\">\n    pre > code {\n        line-height: 1.2;\n        background: none !important;\n    }\n</style>","type":"blog","created_at":"2015-07-07T13:12:46.128Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":5,"uuid":"08818071-0c1f-4d65-9be0-f62e4ba91745","key":"title","value":"JASON Format","type":"blog","created_at":"2015-07-07T13:12:46.126Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":21,"uuid":"d01add80-175e-4ff9-8f96-65ddba65fc03","key":"isPrivate","value":"false","type":"private","created_at":"2015-09-07T17:03:11.539Z","created_by":1,"updated_at":"2021-01-19T21:42:37.994Z","updated_by":1},{"id":6,"uuid":"27f2f849-9805-4449-b193-640c50adf4bd","key":"description","value":"Practical JavaScript and the occasional accidental module.","type":"blog","created_at":"2015-07-07T13:12:46.126Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":9,"uuid":"4b7a3fad-230c-4a85-8cb7-2760454f88dd","key":"logo","value":"https://i.imgur.com/5NZs32D.png","type":"blog","created_at":"2015-07-07T13:12:46.126Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":22,"uuid":"38ae31db-5a2e-4696-b105-a1243fcb7dec","key":"password","value":"null","type":"private","created_at":"2015-09-07T17:03:11.541Z","created_by":1,"updated_at":"2021-01-19T21:42:37.994Z","updated_by":1},{"id":19,"uuid":"277dd90d-be97-4494-a107-982fbc2a8e2a","key":"installedApps","value":"[]","type":"app","created_at":"2015-07-07T13:12:46.131Z","created_by":1,"updated_at":"2021-03-19T16:11:42.999Z","updated_by":1},{"id":8,"uuid":"a2324798-43b5-4181-bfed-3525172512f0","key":"cover","value":"https://farm3.staticflickr.com/2903/14642847567_eeef81964e_k_d.jpg","type":"blog","created_at":"2015-07-07T13:12:46.126Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":10,"uuid":"0f24821b-4797-4252-85bc-a3d7092e8552","key":"defaultLang","value":"en_US","type":"blog","created_at":"2015-07-07T13:12:46.127Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":11,"uuid":"f85353e2-fe36-4c59-8025-f30214076766","key":"postsPerPage","value":"5","type":"blog","created_at":"2015-07-07T13:12:46.127Z","created_by":1,"updated_at":"2021-01-19T21:42:37.970Z","updated_by":1},{"id":12,"uuid":"b4c42bfb-07fa-48c2-863f-761fcbb27729","key":"forceI18n","value":"true","type":"blog","created_at":"2015-07-07T13:12:46.127Z","created_by":1,"updated_at":"2021-01-19T21:42:37.971Z","updated_by":1},{"id":20,"uuid":"bc38bcf2-fe19-4cd7-af69-3b4d0a072c6d","key":"activeTheme","value":"casper","type":"theme","created_at":"2015-07-07T13:12:46.130Z","created_by":1,"updated_at":"2021-01-19T21:42:37.969Z","updated_by":1},{"id":15,"uuid":"abacf62d-9780-41a1-b0b3-a88e9485e740","key":"ghost_foot","value":"<!-- You can safely delete this line if your theme does not require jQuery -->\n<!--<script type=\"text/javascript\" src=\"https://code.jquery.com/jquery-1.11.3.min.js\"></script>-->\n\n<link rel=\"stylesheet\" href=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/styles/github.min.css\">\n<script src=\"//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/highlight.min.js\" async></script>\n<script>(function(done, timer) {\n    function check() {\n        var hljs = window.hljs;\n        if (!hljs || !hljs.configure || done) return;\n        done = true;\n        clearInterval(timer);\n        hljs.configure({\n            tabReplace: '    '\n        });\n        [].forEach.call(document.querySelectorAll('[class^=\"language-\"]'), function(n) {\n            n.className += ' ' + n.className.match(/language-(\\w+)/i)[1];\n        });\n        hljs.initHighlighting();\n    }\n    timer = setInterval(check, 50);\n    addEventListener('domcontentloaded', check);\n    addEventListener('load', check);\n    check();\n}());</script>\n\n\n<script>\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\n\n  ga('create', 'UA-6031694-16', 'auto');\n  ga('send', 'pageview');\n</script>","type":"blog","created_at":"2015-07-07T13:12:46.128Z","created_by":1,"updated_at":"2021-01-19T21:42:37.993Z","updated_by":1}],"app_fields":[],"apps":[],"app_settings":[],"client_trusted_domains":[],"tags":[{"id":6,"uuid":"a5a203f9-7297-4c3f-a775-e2fead2cb004","name":"Knowledge is Power","slug":"knowledgeispower","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-07-07T17:19:13.781Z","created_by":1,"updated_at":"2016-02-20T17:34:38.115Z","updated_by":1},{"id":2,"uuid":"dd1189b4-3660-4276-888c-6d0f287e8a22","name":"JSX","slug":"jsx","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-07-07T17:19:13.719Z","created_by":1,"updated_at":"2016-02-20T17:34:56.378Z","updated_by":1},{"id":4,"uuid":"87930916-7473-4c85-a691-69f1915cff14","name":"Transpilers","slug":"transpilers","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-07-07T17:19:13.758Z","created_by":1,"updated_at":"2016-02-20T17:35:01.569Z","updated_by":1},{"id":5,"uuid":"acb545e5-c337-4f71-b635-eae0f5506e96","name":"Babel","slug":"babel","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-07-07T17:19:13.768Z","created_by":1,"updated_at":"2016-02-20T17:35:05.446Z","updated_by":1},{"id":3,"uuid":"ae8dd7d1-8803-46de-b402-b74becc11e16","name":"React","slug":"react","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":"Posts about React","meta_description":"","created_at":"2015-07-07T17:19:13.740Z","created_by":1,"updated_at":"2016-02-20T17:35:10.625Z","updated_by":1},{"id":7,"uuid":"57fc31b2-b2f2-4a06-9a39-128ad2ae9141","name":"Webpack","slug":"webpack","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-10-29T03:02:47.869Z","created_by":1,"updated_at":"2016-02-20T17:35:14.817Z","updated_by":1},{"id":8,"uuid":"72400764-10ad-48f2-aa1f-141b9a184d5d","name":"CSS","slug":"css","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2016-01-10T21:59:07.167Z","created_by":1,"updated_at":"2016-02-20T17:35:18.767Z","updated_by":1},{"id":9,"uuid":"2bc9892c-83c0-49b2-b517-1e3956c102f0","name":"Modules","slug":"modules","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2016-01-10T21:59:07.191Z","created_by":1,"updated_at":"2016-02-20T17:35:22.160Z","updated_by":1},{"id":10,"uuid":"96660d42-1ac4-431d-8848-b6c467ae4952","name":"Preact","slug":"preact","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2016-02-20T17:52:03.983Z","created_by":1,"updated_at":"2016-02-20T17:52:03.983Z","updated_by":1},{"id":11,"uuid":"e3dba28c-77f5-45bd-9819-d6f310a4177e","name":"redux","slug":"redux","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2017-01-20T17:58:37.535Z","created_by":1,"updated_at":"2017-01-20T17:58:37.535Z","updated_by":1},{"id":12,"uuid":"431fa8a2-d9b9-49e3-a35b-fd32b1ae4255","name":"Architecture","slug":"architecture","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2019-02-14T02:11:27.399Z","created_by":1,"updated_at":"2019-02-14T02:11:27.399Z","updated_by":1},{"id":13,"uuid":"4a6a63bc-e59a-4e1b-a293-f8ae121f4306","name":"SSR","slug":"ssr","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2019-02-14T02:11:27.412Z","created_by":1,"updated_at":"2019-02-14T02:11:27.412Z","updated_by":1},{"id":14,"uuid":"2b37195f-d919-44d8-a0c9-4106b48c72b1","name":"Virtual DOM","slug":"virtual-dom","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2019-02-17T20:11:31.986Z","created_by":1,"updated_at":"2019-02-17T20:11:31.986Z","updated_by":1},{"id":15,"uuid":"d1826580-aca9-4ed5-97a1-1651657c1a16","name":"npm","slug":"npm","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2019-05-30T16:13:20.036Z","created_by":1,"updated_at":"2019-05-30T16:13:20.036Z","updated_by":1},{"id":16,"uuid":"ca5c0539-d7fc-4715-86d8-92a096bdacf0","name":"Ecosystem","slug":"ecosystem","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2019-05-31T14:37:00.484Z","created_by":1,"updated_at":"2019-05-31T14:37:00.484Z","updated_by":1},{"id":17,"uuid":"db3a9f30-3b6f-456e-a6f0-064d9438eada","name":"Bundlers","slug":"bundlers","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2020-02-28T17:28:11.645Z","created_by":1,"updated_at":"2020-02-28T17:28:11.645Z","updated_by":1},{"id":18,"uuid":"ec502904-9264-401e-888d-658583c5e4f7","name":"JavaScript","slug":"javascript","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2020-08-28T14:39:50.300Z","created_by":1,"updated_at":"2020-08-28T14:39:50.300Z","updated_by":1},{"id":19,"uuid":"5f19c8be-42d9-44dd-a14a-14ab578c6a37","name":"Multi-threading","slug":"multi-threading","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2021-01-14T23:04:33.925Z","created_by":1,"updated_at":"2021-01-14T23:04:33.925Z","updated_by":1},{"id":20,"uuid":"8ca1f7d1-7d06-4aea-a654-afba7f01a251","name":"DOM","slug":"dom","description":null,"image":null,"hidden":false,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2021-01-15T22:53:51.324Z","created_by":1,"updated_at":"2021-01-15T22:53:51.324Z","updated_by":1}],"posts_tags":[{"id":52,"post_id":4,"tag_id":7,"sort_order":0},{"id":61,"post_id":11,"tag_id":10,"sort_order":0},{"id":62,"post_id":11,"tag_id":3,"sort_order":1},{"id":63,"post_id":14,"tag_id":3,"sort_order":0},{"id":64,"post_id":14,"tag_id":12,"sort_order":1},{"id":65,"post_id":14,"tag_id":13,"sort_order":2},{"id":66,"post_id":15,"tag_id":12,"sort_order":0},{"id":67,"post_id":15,"tag_id":13,"sort_order":1},{"id":69,"post_id":10,"tag_id":10,"sort_order":0},{"id":70,"post_id":10,"tag_id":3,"sort_order":1},{"id":71,"post_id":10,"tag_id":2,"sort_order":2},{"id":72,"post_id":10,"tag_id":7,"sort_order":3},{"id":57,"post_id":6,"tag_id":10,"sort_order":0},{"id":73,"post_id":6,"tag_id":3,"sort_order":1},{"id":74,"post_id":6,"tag_id":2,"sort_order":2},{"id":75,"post_id":6,"tag_id":14,"sort_order":3},{"id":53,"post_id":5,"tag_id":8,"sort_order":0},{"id":54,"post_id":5,"tag_id":9,"sort_order":1},{"id":55,"post_id":5,"tag_id":7,"sort_order":2},{"id":76,"post_id":9,"tag_id":7,"sort_order":0},{"id":77,"post_id":9,"tag_id":9,"sort_order":1},{"id":58,"post_id":8,"tag_id":11,"sort_order":0},{"id":59,"post_id":8,"tag_id":10,"sort_order":1},{"id":60,"post_id":8,"tag_id":7,"sort_order":2},{"id":78,"post_id":8,"tag_id":12,"sort_order":3},{"id":47,"post_id":2,"tag_id":2,"sort_order":0},{"id":48,"post_id":2,"tag_id":4,"sort_order":1},{"id":49,"post_id":2,"tag_id":5,"sort_order":2},{"id":51,"post_id":2,"tag_id":3,"sort_order":3},{"id":68,"post_id":2,"tag_id":10,"sort_order":4},{"id":79,"post_id":2,"tag_id":14,"sort_order":5},{"id":80,"post_id":16,"tag_id":9,"sort_order":0},{"id":81,"post_id":16,"tag_id":4,"sort_order":1},{"id":82,"post_id":16,"tag_id":7,"sort_order":2},{"id":83,"post_id":16,"tag_id":15,"sort_order":3},{"id":84,"post_id":16,"tag_id":16,"sort_order":4},{"id":85,"post_id":17,"tag_id":9,"sort_order":0},{"id":86,"post_id":17,"tag_id":16,"sort_order":1},{"id":87,"post_id":18,"tag_id":17,"sort_order":0},{"id":88,"post_id":18,"tag_id":4,"sort_order":1},{"id":89,"post_id":18,"tag_id":16,"sort_order":2},{"id":90,"post_id":19,"tag_id":12,"sort_order":0},{"id":91,"post_id":19,"tag_id":13,"sort_order":1},{"id":92,"post_id":20,"tag_id":12,"sort_order":0},{"id":93,"post_id":20,"tag_id":18,"sort_order":1},{"id":94,"post_id":21,"tag_id":18,"sort_order":0},{"id":95,"post_id":21,"tag_id":19,"sort_order":1},{"id":96,"post_id":22,"tag_id":18,"sort_order":0},{"id":97,"post_id":22,"tag_id":19,"sort_order":1},{"id":98,"post_id":22,"tag_id":12,"sort_order":2},{"id":99,"post_id":22,"tag_id":20,"sort_order":3}],"users":[{"id":1,"uuid":"28c79c0f-2e6f-4cb8-9c46-6d5219dcd5ec","name":"Jason Miller","slug":"developit","password":"$2a$10$zdoGq/WbpxaRo2ftvuRKIeli.kGmLpu1hRzmWLE0KMvagO9mohTne","email":"jason@developit.ca","image":"//www.gravatar.com/avatar/85ed8e6da2fbf39abeb4995189be324c?s=250&d=mm&r=x","cover":"https://pbs.twimg.com/profile_banners/16495353/1523385837/1500x500","bio":null,"website":"https://twitter.com/_developit","location":"Cambridge, MA","accessibility":null,"status":"active","language":"en_US","meta_title":null,"meta_description":null,"last_login":"2021-03-19T21:06:53.202Z","created_at":"2015-07-07T13:12:46.088Z","created_by":1,"updated_at":"2021-03-19T21:06:53.203Z","updated_by":1,"tour":null}]}}]}